--- a/source/blender/blenlib/BLI_bit_span_to_index_ranges.hh.orig	2025-07-10 02:43:07.000000000 -0700
+++ b/source/blender/blenlib/BLI_bit_span_to_index_ranges.hh	2025-10-10 12:51:32.241338438 -0700
@@ -106,7 +106,7 @@ inline void bits_to_index_ranges(const B
     int64_t int_i = 0;
 
 /* Checking for chunks of 0 bits can be speedup using intrinsics quite significantly. */
-#if BLI_HAVE_SSE2
+#if BLI_HAVE_SSE2 && defined(__SSE4_1__)
     for (; int_i + 1 < ints_to_check; int_i += 2) {
       /* Loads the next 128 bit. */
       const __m128i group = _mm_loadu_si128(reinterpret_cast<const __m128i *>(start + int_i));
--- a/intern/cycles/kernel/device/cpu/kernel.cpp.orig	2025-07-10 02:43:06.000000000 -0700
+++ b/intern/cycles/kernel/device/cpu/kernel.cpp	2025-10-11 11:02:21.482226967 -0700
@@ -8,11 +8,13 @@
  * one with SSE4.2 intrinsics.
  */
 #if defined(__x86_64__) || defined(_M_X64)
-#  define __KERNEL_SSE__
-#  define __KERNEL_SSE2__
-#  define __KERNEL_SSE3__
-#  define __KERNEL_SSSE3__
-#  define __KERNEL_SSE42__
+#  if defined(__SSE__) && defined(__SSE2__) && defined(__SSE3__) && defined(__SSSE3__) && defined(__SSE4_2__)
+#    define __KERNEL_SSE__
+#    define __KERNEL_SSE2__
+#    define __KERNEL_SSE3__
+#    define __KERNEL_SSSE3__
+#    define __KERNEL_SSE42__
+#  endif
 #endif
 
 /* When building kernel for native machine detect kernel features from the flags
