<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pkgmetadata SYSTEM "https://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
  <maintainer type="person">
    <!-- Ebuild originators -->
    <email>tupone@gentoo.org</email>
    <name>Tupone Alfredo</name>
  </maintainer>
  <maintainer type="person" proxied="yes">
    <!-- Ebuild originators -->
    <email>telans@posteo.de</email>
    <name>James Beddek</name>
  </maintainer>
  <use>
cuda +distributed +fbgemm +flash-attention +gloo +kineto +magma -mimalloc mkl +mpi +nnpack +numpy
onednn openblas -opencl +openmp +qnnpack rccl rocm roctracer system-libs test
+xnnpack

    <flag name="cuda">
      Add support for CUDA processing
    </flag>
    <flag name="distributed">
      Support distributed applications
    </flag>
    <flag name="eigen">
      Use Eigen as the fallback for BLAS.  Otherwise, it fallback to the generic
      implementation.
    </flag>
    <flag name="fbgemm">
      Use FBGEMM
    </flag>
    <flag name="ffmpeg">
      Add support for video processing operators
    </flag>
    <flag name="flash-attention">
      Add support for flash-attention
    </flag>
    <flag name="gloo">
      Use sci-libs/gloo
    </flag>
    <flag name="mimalloc">
      Use the performance based memory allocator.
    </flag>
    <flag name="mkl">
      Use MKL as the BLAS provider
    </flag>
    <flag name="nnpack">
      Use NNPACK
    </flag>
    <flag name="numpy">
      Add support for math operations through numpy
    </flag>
    <flag name="onednn">
      Optimize deep learning primitives on CPUs and/or IntelÂ® GPUs.
    </flag>
    <flag name="opencl">
      Use OpenCL
    </flag>
    <flag name="opencv">
      Add support for image processing operators
    </flag>
    <flag name="openmp">
      Use OpenMP for parallel code
    </flag>
    <flag name="system-libs">
      Use system libs; otherwise, use vendored/bundled packages.
      This USE flag is the same as the vanilla USE flag.

      For correctness and performance, disable this USE flag.
      For security improvement, enable this USE flag.
    </flag>
    <flag name="qnnpack">
      Use QNNPACK
    </flag>
    <flag name="xnnpack">
      Use XNNPACK
    </flag>
  </use>
  <upstream>
    <remote-id type="github">pytorch/pytorch</remote-id>
  </upstream>
</pkgmetadata>
