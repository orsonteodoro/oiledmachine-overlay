# Split patch of original patch
Original patch:  https://gist.githubusercontent.com/raw/ed891528aacf0c5baf3a789e5e9aaead
Context:  https://bugs.gentoo.org/705712#c29

diff -urp tensorflow-2.13.0.orig/tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc tensorflow-2.13.0/tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc
--- tensorflow-2.13.0.orig/tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc	2023-06-28 11:38:35.000000000 -0700
+++ tensorflow-2.13.0/tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc	2023-08-16 02:05:14.318561029 -0700
@@ -229,7 +229,8 @@ class GpuKernelToBlobPass
           "compute_)");
     }
     int arch;
-    if (!absl::SimpleAtoi(consumable_arch, &arch)) {
+    absl::SimpleAtoi(consumable_arch, &arch);
+    if (arch <= 0) {
       return tensorflow::errors::Internal(
           "Could not parse cuda architecture number");
     }
diff -urp tensorflow-2.13.0.orig/tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc tensorflow-2.13.0/tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc
--- tensorflow-2.13.0.orig/tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc	2023-06-28 11:38:35.000000000 -0700
+++ tensorflow-2.13.0/tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc	2023-08-15 20:19:49.911226701 -0700
@@ -785,7 +785,7 @@ StatusOr<std::vector<uint8_t>> EmitModul
   // Locate lld.
   // TODO(whchung@gmail.com): change to tensorflow::ROCmRoot() after
   // ROCm-Device-Libs PR.
-  std::string lld_path = tsl::io::JoinPath("/opt/rocm", "llvm/bin");
+  std::string lld_path = "@ESYSROOT_LLVM_PATH@/bin";
   auto lld_program = llvm::sys::findProgramByName("ld.lld", {lld_path});
   if (!lld_program) {
     return xla::InternalError("unable to find ld.lld in PATH: %s",
diff -urp tensorflow-2.13.0.orig/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc tensorflow-2.13.0/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc
--- tensorflow-2.13.0.orig/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc	2023-06-28 11:38:35.000000000 -0700
+++ tensorflow-2.13.0/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc	2023-08-15 20:25:28.775215817 -0700
@@ -436,7 +436,7 @@ static std::string findRocmExecutable(co
 tsl::StatusOr<std::vector<uint8_t>> BundleGpuAsm(
     std::vector<HsacoImage> images, const std::string rocm_root_dir) {
   std::string clang_offload_bundler_path =
-      findRocmExecutable("llvm/bin/clang-offload-bundler", rocm_root_dir);
+      "@ESYSROOT_LLVM_PATH@/bin/clang-offload-bundler";
 
   // Initialise the "--inputs" / "--targets" arguments for the
   // clang-offload-bundler with a dummy file / host target triple...
diff -urp tensorflow-2.13.0.orig/tensorflow/tsl/platform/default/rocm_rocdl_path.cc tensorflow-2.13.0/tensorflow/tsl/platform/default/rocm_rocdl_path.cc
--- tensorflow-2.13.0.orig/tensorflow/tsl/platform/default/rocm_rocdl_path.cc	2023-06-28 11:38:35.000000000 -0700
+++ tensorflow-2.13.0/tensorflow/tsl/platform/default/rocm_rocdl_path.cc	2023-08-15 20:22:32.887221466 -0700
@@ -35,6 +35,6 @@ string RocmRoot() {
 #endif
 }
 
-string RocdlRoot() { return io::JoinPath(RocmRoot(), "amdgcn/bitcode"); }
+string RocdlRoot() { return io::JoinPath(RocmRoot(), "@ROCM_LIBDIR@/amdgcn/bitcode"); }
 
 }  // namespace tsl
