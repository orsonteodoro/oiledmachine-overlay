<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
  <maintainer type="person">
    <!-- Ebuild on the oiledmachine-overlay -->
    <email>orsonteodoro@hotmail.com</email>
    <name>Orson Teodoro</name>
  </maintainer>
  <!--

    Build time environment variables:

    LOCAL_AI_HOSTNAME - hostname
    Default:  127.0.0.1

    LOCAL_AI_PORT - port to connect to the web interface
    Default:  8080

    LOCAL_AI_URI - hostname to use
    Default:  http://127.0.0.1:8080

    Sample /etc/portage/env/local-ai.conf:

    LOCAL_AI_HOSTNAME="127.0.0.1"
    LOCAL_AI_PORT=8080
    LOCAL_AI_URI="http://127.0.0.1:8080"

    Sample /etc/portage/package.env:
    dev-python/local-ai local-ai.conf

    Inference support

    | Backend              | Text inference      | Image inference            | Vision | CPU | GPU | GPU SDK                            | P2P |
    | ---                  | ---                 | ---                        | ---    | --- | --- | ---                                | --- |
    | diffusers            | N                   | Y (Image/video generation) | A      | Y   | Y   | CUDA, ROCm, Intel, Metal           | F   |
    | exllama2             | Y                   | N                          |        | N   | Y   | CUDA                               | F   |
    | huggingface          | Y (Embeddings)      | N                          |        | Y   | Y   |                                    | F   |
    | llama.cpp            | Y                   | N                          | U      | Y   | Y   | CUDA, ROCm, SYCL, Vulkan, Metal    | FW  |
    | MLX                  | Y                   | N                          |        | N   | Y   | Metal - Apple Silicon              | F   |
    | MLX-VLM              | Y (Vision-Language) | Y (Image understanding)    | U      | N   | Y   | Metal - Apple Silicon              | F   |
    | RF-DETR              | N                   | Y (Object detection)       | U      | Y   | Y   | CUDA                               | F   |
    | stablediffusion-ggml | N                   | Y (Image generation)       |        | Y   | Y   | CUDA, SYCL, Vulkan                 | F   |
    | transformers         | Y                   | N                          | U      | Y   | Y   | CUDA, ROCm, Intel                  | F   |
    | vLLM                 | Y                   | N                          |        | N   | Y   | CUDA, ROCm, Intel                  | F   |


    A = From image to image artwork
    U = From image understanding to textual/audio analysis
    F = Federated (Load balancing)
    W = Worker (Sharded split weights to do collaborative work)

    See also

    https://localai.io/model-compatibility/

  -->
  <upstream>
    <bugs-to>https://github.com/mudler/LocalAI/issues</bugs-to>
    <remote-id type="github">mudler/LocalAI</remote-id>
  </upstream>
  <use>
    <flag name="ci">
      For upstream development only.  (DO NOT USE)
    </flag>
    <flag name="clblas">
      Support AMD/Intel GPU acceleration
    </flag>
    <flag name="cuda">
      Support NVIDIA GPU accelerated BLAS.
    </flag>
    <flag name="cpu_flags_riscv_v">
      Support RISC-V Vector extension
    </flag>
    <flag name="cpu_flags_riscv_xthreadvector">
      Support T-head vector extension
    </flag>
    <flag name="cpu_flags_riscv_zfh">
      Support RISC-V half-precision floating point extension
    </flag>
    <flag name="cpu_flags_riscv_zicbop">
      Support RISC-V cache-block prefetch extension
    </flag>
    <flag name="cpu_flags_riscv_zvfh">
      Support RISC-V vector half-precision floating-point extension
    </flag>
    <flag name="devcontainer">
      For upstream development only.  (DO NOT USE)
    </flag>
    <flag name="docker">
      Support post-install Docker based backend options.
    </flag>
    <flag name="native">
      Build with -march=native.  Disabling requires SSE4.2 for ARCH=amd64.
    </flag>
    <flag name="openblas">
      Support CPU accelerated BLAS.
    </flag>
    <flag name="p2p">
      Support peer-to-peer inference.
    </flag>
    <flag name="rag">
      Support basic RAG (Retrieval-Augmented Generation).
    </flag>
    <flag name="rocm">
      Support AMD GPU accelerated BLAS.
    </flag>
    <flag name="stt">
      Support speech to text or microphone support.
    </flag>
    <flag name="sycl-f16">
      Support Intel GPU acceleration with 16 bit floats for speed.
    </flag>
    <flag name="sycl-f32">
      Support Intel GPU acceleration with 32 bit floats for accuracy.
    </flag>
    <flag name="tts">
      Support text to speech or artificial voice audio out support.
    </flag>
  </use>
</pkgmetadata>
