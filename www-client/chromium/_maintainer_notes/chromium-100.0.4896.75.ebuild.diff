--- chromium-100.0.4896.75.ebuild.orig	2022-04-07 16:09:58.000000000 -0700
+++ chromium-100.0.4896.75.ebuild	2022-04-10 18:57:09.536246868 -0700
@@ -1,6 +1,11 @@
 # Copyright 2009-2022 Gentoo Authors
 # Distributed under the terms of the GNU General Public License v2
 
+# Monitor
+#   https://chromereleases.googleblog.com/search/label/Dev%20updates
+# for security updates.  They are announced faster than NVD.
+# See https://omahaproxy.appspot.com/ for the latest linux version
+
 EAPI=8
 PYTHON_COMPAT=( python3_{8..10} )
 PYTHON_REQ_USE="xml"
@@ -9,107 +14,872 @@ CHROMIUM_LANGS="am ar bg bn ca cs da de
 	hi hr hu id it ja kn ko lt lv ml mr ms nb nl pl pt-BR pt-PT ro ru sk sl sr
 	sv sw ta te th tr uk vi zh-CN zh-TW"
 
+LLVM_MAX_SLOT=15
+LLVM_MIN_SLOT=13
+CR_CLANG_SLOT_OFFICIAL=15
+LLVM_SLOTS=(${LLVM_MAX_SLOT} 14 ${LLVM_MIN_SLOT}) # [inclusive, inclusive] high to low
 inherit check-reqs chromium-2 desktop flag-o-matic ninja-utils pax-utils python-any-r1 readme.gentoo-r1 toolchain-funcs xdg-utils
+inherit llvm multilib multilib-minimal
 
 DESCRIPTION="Open-source version of Google Chrome web browser"
 HOMEPAGE="https://chromium.org/"
-PATCHSET="4"
+PATCHSET="3"
 PATCHSET_NAME="chromium-$(ver_cut 1)-patchset-${PATCHSET}"
 PATCHSET_PPC64="1"
 PATCHSET_NAME_PPC64="chromium-$(ver_cut 1)-patchset-ppc64le-${PATCHSET_PPC64}"
-SRC_URI="https://commondatastorage.googleapis.com/chromium-browser-official/${P}.tar.xz
+CIPD_V="8e9b0c80860d00dfe951f7ea37d74e210d376c13" # in \
+# third_party/depot_tools/cipd_client_version
+MTD_V="${PV}"
+CTDM_V="${PV}"
+# a4de986 - ozone/x11: fix VA-API.
+SRC_URI="
+	https://commondatastorage.googleapis.com/chromium-browser-official/${P}.tar.xz
 	https://github.com/stha09/chromium-patches/releases/download/${PATCHSET_NAME}/${PATCHSET_NAME}.tar.xz
-	ppc64? ( https://dev.gentoo.org/~sultan/distfiles/www-client/chromium/${PATCHSET_NAME_PPC64}.tar.xz )"
+	pgo-full? (
+		amd64? ( https://chrome-infra-packages.appspot.com/client?platform=linux-amd64&version=git_revision:${CIPD_V} -> .cipd_client-amd64-${CIPD_V} )
+		arm64? ( https://chrome-infra-packages.appspot.com/client?platform=linux-arm64&version=git_revision:${CIPD_V} -> .cipd_client-arm64-${CIPD_V} )
+		ppc64? ( https://chrome-infra-packages.appspot.com/client?platform=linux-ppc64&version=git_revision:${CIPD_V} -> .cipd_client-ppc64-${CIPD_V} )
+		x86? ( https://chrome-infra-packages.appspot.com/client?platform=linux-386&version=git_revision:${CIPD_V} -> .cipd_client-x86-${CIPD_V} )
+		cr_pgo_trainers_memory_desktop? (
+			https://chromium.googlesource.com/chromium/src.git/+archive/refs/tags/${CTDM_V}/chrome/test/data/media.tar.gz -> ${PN}-${CTDM_V}-chrome-test-data-media.tar.gz
+			https://chromium.googlesource.com/chromium/src.git/+archive/refs/tags/${MTD_V}/media/test/data.tar.gz -> ${PN}-${MTD_V}-media-test-data.tar.gz
+		)
+		cr_pgo_trainers_media_desktop? (
+			https://chromium.googlesource.com/chromium/src.git/+archive/refs/tags/${CTDM_V}/chrome/test/data/media.tar.gz -> ${PN}-${CTDM_V}-chrome-test-data-media.tar.gz
+			https://chromium.googlesource.com/chromium/src.git/+archive/refs/tags/${MTD_V}/media/test/data.tar.gz -> ${PN}-${MTD_V}-media-test-data.tar.gz
+		)
+		cr_pgo_trainers_media_mobile? (
+			https://chromium.googlesource.com/chromium/src.git/+archive/refs/tags/${CTDM_V}/chrome/test/data/media.tar.gz -> ${PN}-${CTDM_V}-chrome-test-data-media.tar.gz
+			https://chromium.googlesource.com/chromium/src.git/+archive/refs/tags/${MTD_V}/media/test/data.tar.gz -> ${PN}-${MTD_V}-media-test-data.tar.gz
+		)
+	)
+	ppc64? ( https://dev.gentoo.org/~sultan/distfiles/www-client/chromium/${PATCHSET_NAME_PPC64}.tar.xz )
+"
 
-LICENSE="BSD"
+# Some assets encoded by proprietary-codecs (mp3, aac, h264) are found in both
+#   ${PN}-${CTDM_V}-chrome-test-data-media.tar.gz
+#   ${PN}-${MTD_V}-media-test-data.tar.gz
+# but shouldn't be necessary to use the USE flag.
+
+#RESTRICT="mirror"
+#PROPERTIES="interactive" # For interactive login in social networks for PGO profile generation. \
+# See _init_cr_pgo_trainers_rasterize_and_record_micro_top_25() function below. \
+# Disabled until the inner workings is understood.
+
+# all-rights-reserved is for unfree websites or content from them.
+LICENSE_BENCHMARK_WEBSITES="
+	cr_pgo_trainers_desktop_ui? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_loading_desktop? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_loading_mobile? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_power_mobile? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_rasterize_and_record_micro_top_25? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_rendering_desktop? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_rendering_mobile? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_tab_switching_typical_25? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_unscheduled_loading_mbi? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_unscheduled_v8_loading_desktop? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_v8_runtime_stats_top_25? (
+		all-rights-reserved
+	)
+	cr_pgo_trainers_dromaeo? (
+		( all-rights-reserved || ( MPL-1.1 GPL-2.0+ LGPL-2.1+ ) )
+		( all-rights-reserved MIT )
+		( ( all-rights-reserved || ( MIT AFL-2.1 ) ) ( MIT GPL-2 ) || ( AFL-2.1 BSD ) MIT )
+		( all-rights-reserved GPL-2+ )
+		( MIT GPL-2 )
+		( MIT BSD GPL )
+		BSD
+		BSD-2
+		LGPL-2.1
+	)
+	cr_pgo_trainers_jetstream? (
+		( all-rights-reserved || ( MPL-1.1 GPL-2+ LGPL-2.1+ ) )
+		( all-rights-reserved Apache-2.0 )
+		( all-rights-reserved GPL-2+ )
+		( all-rights-reserved MIT )
+		Apache-2.0
+		BSD-2
+		BSD
+		GPL-2
+		GPL-2+
+		LGPL-2.1
+		MIT
+		UoI-NCSA
+		ZLIB
+	)
+	cr_pgo_trainers_jetstream2? (
+		|| ( BSD GPL-2+ )
+		( all-rights-reserved || ( MPL-1.1 GPL-2+ LGPL-2+ ) )
+		( all-rights-reserved Apache-2.0 )
+		( all-rights-reserved GPL-2+ )
+		( all-rights-reserved MIT )
+		all-rights-reserved
+		Apache-2.0
+		BSD-2
+		BSD
+		FPL
+		GPL-2
+		LGPL-2+
+		LGPL-2.1
+		MIT
+		ZLIB
+	)
+	cr_pgo_trainers_kraken? (
+		( ( all-rights-reserved || ( MIT AFL-2.1 ) ) (MIT GPL) BSD MIT )
+		( all-rights-reserved || ( MPL-1.1 GPL-2+ LGPL-2.1+ ) )
+		( all-rights-reserved GPL-3+ )
+		|| ( BSD GPL-2 )
+		BSD
+		BSD-2
+		LGPL-2.1
+		MPL-1.1
+	)
+	cr_pgo_trainers_media_desktop? (
+		CC-BY-3.0
+		CC-BY-4.0
+	)
+	cr_pgo_trainers_media_mobile? (
+		CC-BY-3.0
+		CC-BY-4.0
+	)
+	cr_pgo_trainers_memory_desktop? (
+		CC-BY-3.0
+	)
+	cr_pgo_trainers_octane? (
+		BSD
+	)
+	cr_pgo_trainers_speedometer2? (
+		|| ( MIT BSD )
+		( all-rights-reserved GPL-2 )
+		( all-rights-reserved MIT )
+		( MIT CC0-1.0 )
+		Apache-2.0
+		BSD
+		CC-BY-4.0
+		MIT
+	)
+" # emerge does not understand ^^ in the LICENSE variable and have been replaced
+# with ||.  You should choose at most one at some instances.
+# GEN_ABOUT_CREDITS=1 # Uncomment to generate about_credits.html including bundled.
+# SHA512 about_credits.html fingerprint:
+LICENSE_FINGERPRINT="\
+ef868096a01f120aa61d10c1ad6b0f136f72bb8c107f64db55bbe90f3b2492c6\
+10fbbf60bc9b3025c292af2909c902d04b9e41bd74ce711d8c9755ed2b371e8a"
+LICENSE="BSD
+	chromium-10.0.4896.x
+	APSL-2
+	Apache-2.0
+	Apache-2.0-with-LLVM-exceptions
+	( all-rights-reserved MIT )
+	BSD-2
+	BSD-4
+	base64
+	CC0-1.0
+	CC-BY-3.0
+	CC-BY-4.0
+	CC-BY-ND-2.5
+	FTL
+	fft2d
+	GPL-2+
+	g711
+	g722
+	IJG
+	ILA-OpenCV
+	ISC
+	( ISC CC-BY-SA-4.0 )
+	Khronos-CLHPP
+	LGPL-2
+	LGPL-2+
+	LGPL-2.1+
+	libpng2
+	libwebrtc-PATENTS
+	MIT
+	( MIT CC0-1.0 )
+	MPL-1.1
+	MPL-2.0
+	neon_2_sse
+	OFL-1.1
+	ooura
+	openssl
+	PSF-2
+	QU-fft
+	Unlicense
+	UoI-NCSA
+	unRAR
+	unicode
+	SGI-B-2.0
+	sigslot
+	SunPro
+	svgo
+	WTFPL-2
+	x11proto
+	ZLIB
+	widevine? ( widevine )
+	${LICENSE_BENCHMARK_WEBSITES}"
+# Benchmark website licenses:
+# See the webkit-gtk ebuild
+#
+# BSD-2 BSD LGPL-2.1 - Kraken benchmark
+#   ( ( all-rights-reserved || ( MIT AFL-2.1 ) ) (MIT GPL) BSD MIT )
+#   ( all-rights-reserved ^^ ( MPL-1.1 GPL-2+ LGPL-2.1+ ) )
+#   ( all-rights-reserved GPL-3+ ) tests/kraken-1.0/audio-beat-detection-data.js
+#   || ( BSD GPL-2 ) ; for SJCL
+#   MPL-1.1 tests/kraken-1.0/imaging-desaturate.js
+#   public-domain hosted/json2.js
+
+# Third Party Licenses:
+#
+# TODO:  The rows marked custom need to have or be placed a license file or
+#        reevaluated.
+# TODO:  scan all font files for embedded licenses
+#
+# ^^ ( FTL GPL-2 ) ZLIB public-domain - third_party/freetype/src/LICENSE.TXT
+# ^^ ( GPL-2+ LGPL-2.1+ MPL-1.1 ) - chrome/utility/importer/nss_decryptor.cc
+# ^^ ( GPL-2+ LGPL-2.1+ MPL-1.1 ) BSD BSD-2 - third_party/libgifcodec/LICENSE.md
+# || ( WTFPL-2 Apache-2.0 ) - \
+#   third_party/catapult/third_party/polymer2/bower_components/sinon-chai/LICENSE.txt ; \
+#   the WTFPL is the better choice because Apache-2.0 has more restrictions
+# || ( MIT GPL-3 ) third_party/catapult/tracing/third_party/jszip/LICENSE.markdown ; \
+#   upstream has more MIT than GPL3 copyright notices, so MIT is assumed
+# APSL-2 - third_party/apple_apsl/LICENSE
+# APSL-2 Apache-2.0 BSD MIT - third_party/breakpad/LICENSE
+# Apache-2.0 - CIPD - https://chromium.googlesource.com/infra/luci/luci-go/+/refs/heads/main/cipd
+# Apache-2.0 - third_party/node/node_modules/typescript/LICENSE.txt
+# Apache-2.0-with-LLVM-exceptions UoI-NCSA - \
+#   third_party/llvm/debuginfo-tests/dexter/LICENSE.txt
+# Apache-2.0-with-LLVM-exceptions UoI-NCSA MIT - third_party/llvm/libclc/LICENSE.TXT
+# all-rights-reserved MIT - third_party/xcbproto/LICENSE ; the plain MIT \
+#   license doesn't come with all rights reserved in the license template
+# BSD - third_party/vulkan-deps/glslang/src/LICENSE.txt
+# BSD ^^ ( MPL-1.1 GPL-2+ LGPL-2+ ) - \
+#   third_party/openscreen/src/third_party/mozilla/LICENSE.txt
+# BSD CC-BY-3.0 CC-BY-4.0 MIT public-domain - third_party/snappy/src/COPYING
+# BSD ISC MIT openssl - third_party/boringssl/src/LICENSE
+# BSD MPL-1.1 - url/third_party/mozilla/LICENSE.txt
+# BSD-2 - third_party/node/node_modules/eslint-scope/LICENSE
+# BSD-2 IJG MIT - third_party/libavif/src/LICENSE
+# base64 - third_party/webrtc/rtc_base/third_party/base64/LICENSE
+# custom - third_party/llvm/clang-tools-extra/clang-tidy/cert/LICENSE.TXT
+# custom - third_party/llvm/clang-tools-extra/clang-tidy/hicpp/LICENSE.TXT
+# custom ^^ ( BSD-2 BSD ) - third_party/blink/LICENSE_FOR_ABOUT_CREDITS
+# custom Apache-2.0-with-LLVM-exceptions UoI-NCSA third_party/llvm/openmp/LICENSE.TXT
+# custom CC-BY-ND-2.5 LGPL-2.1+ GPL-2+ public-domain - \
+#   third_party/blink/perf_tests/svg/resources/LICENSES
+# custom BSD APSL-2 MIT BSD-4 - third_party/breakpad/breakpad/LICENSE
+# custom IJG - third_party/iccjpeg/LICENSE
+# custom MPL-2.0 BSD GPL-3 LGPL-3 Apache-1.1 - \
+#   third_party/tflite/src/third_party/eigen3/LICENSE ; Only MPL-2.0 files are \
+#   found
+# custom UoI-NCSA - third_party/llvm/llvm/include/llvm/Support/LICENSE.TXT
+# custom public-domain - third_party/sqlite/LICENSE
+# CC-BY-3.0 https://peach.blender.org/download/ # avi is mp4 and h264 is mov
+#   (c) copyright 2008, Blender Foundation / www.bigbuckbunny.org
+# CC-BY-4.0 - third_party/devtools-frontend/src/node_modules/caniuse-lite/LICENSE
+# CC0-1.0 - tools/perf/page_sets/trivial_sites/trivial_fullscreen_video.html
+# fft2d - third_party/tflite/src/third_party/fft2d/LICENSE
+# g711 - third_party/webrtc/modules/third_party/g711/LICENSE
+# g722 - third_party/webrtc/modules/third_party/g722/LICENSE
+# GPL-2 - third_party/freetype-testing/LICENSE
+# GPL-2+ - third_party/devscripts/licensecheck.pl.vanilla
+# ILA-OpenCV (BSD with additional clauses) - third_party/opencv/src/LICENSE
+# ISC - third_party/node/node_modules/rimraf/LICENSE
+# ISC - third_party/libaom/source/libaom/third_party/x86inc/LICENSE
+# ISC CC-BY-SA-4.0 - third_party/node/node_modules/glob/LICENSE ; no logo \
+#   image file found
+# ISC MIT - third_party/devtools-frontend/src/node_modules/rollup/LICENSE.md
+# Khronos-CLHPP - third_party/vulkan-deps/spirv-headers/src/LICENSE
+# LGPL-2 - third_party/blink/renderer/core/LICENSE-LGPL-2
+#   third_party/blink/renderer/core/layout/table_layout_algorithm.h
+# LGPL-2+ - third_party/blink/renderer/core/svg/svg_set_element.h
+# LGPL-2.1 - third_party/blink/renderer/core/LICENSE-LGPL-2.1 ; cannot find a \
+#   file that is 2.1 only
+# LGPL-2.1+ - third_party/blink/renderer/core/paint/paint_layer.h
+# LGPL-2.1+ - third_party/libsecret/LICENSE
+# LGPL-2.1+ - third_party/ffmpeg/libavcodec/x86/xvididct.asm
+# libpng2 - third_party/pdfium/third_party/libpng16/LICENSE
+# MIT CC0-1.0 - third_party/node/node_modules/eslint/node_modules/lodash/LICENSE
+# MIT SGI-B-2.0 - third_party/khronos/LICENSE
+# MIT unicode - third_party/node/node_modules/typescript/ThirdPartyNoticeText.txt
+# MPL-2.0 - third_party/node/node_modules/mdn-data/LICENSE
+# neon_2_sse - third_party/neon_2_sse/LICENSE
+# OFL-1.1 - third_party/freetype-testing/src/fuzzing/corpora/cff-render-ftengine/bungeman/HangingS.otf
+# ooura - third_party/webrtc/common_audio/third_party/ooura/LICENSE
+# public-domain - third_party/lzma_sdk/LICENSE
+# public-domain with no warranty - third_party/pdfium/third_party/bigint/LICENSE
+# public-domain - \
+#   third_party/webrtc/common_audio/third_party/spl_sqrt_floor/LICENSE
+# PSF-2 - third_party/devtools-frontend/src/node_modules/mocha/node_modules/argparse/LICENSE
+# QU-fft - third_party/webrtc/modules/third_party/fft/LICENSE
+# sigslot - third_party/webrtc/rtc_base/third_party/sigslot/LICENSE
+# SunPro - third_party/fdlibm/LICENSE
+# svgo (with russian MIT license translation) - \
+#   third_party/node/node_modules/svgo/LICENSE
+# Unlicense Apache-2.0 - \
+#   third_party/devtools-frontend/src/node_modules/@sinonjs/text-encoding/LICENSE.md
+# UoI-NCSA - third_party/swiftshader/third_party/llvm-subzero/LICENSE.TXT
+# unRAR - third_party/unrar/LICENSE
+# widevine - third_party/widevine/LICENSE
+# WTFPL BSD-2 - third_party/catapult/third_party/polymer2/bower_components/sinon-chai/LICENSE.txt
+# x11proto - third_party/x11proto/LICENSE
+# * The public-domain entry was not added to the LICENSE ebuild variable to not
+#   give the wrong impression that the entire software was released in public
+#   domain.
 SLOT="0/stable"
-KEYWORDS="amd64 ~arm64 ~x86"
-IUSE="component-build cups cpu_flags_arm_neon debug gtk4 +hangouts headless +js-type-check kerberos libcxx +official pic +proprietary-codecs pulseaudio screencast selinux +suid +system-ffmpeg +system-harfbuzz +system-icu +system-png vaapi wayland widevine"
-REQUIRED_USE="
-	component-build? ( !suid !libcxx )
+KEYWORDS="amd64 arm64 ~x86"
+# vaapi is enabled by default upstream for some arches \
+# See https://github.com/chromium/chromium/blob/100.0.4896.75/media/gpu/args.gni#L24
+# Using the system-ffmpeg or system-icu breaks cfi-icall or cfi-cast which is
+#   incompatible as a shared lib.
+# The suid is built by default upstream but not necessarily used:  \
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/sandbox/linux/BUILD.gn
+CPU_FLAGS_ARM=( neon )
+CPU_FLAGS_X86=( ssse3 sse4_2 )
+# CFI Basic (.a) mode requires all third party modules built as static.
+IUSE="${CPU_FLAGS_ARM[@]/#/cpu_flags_arm_} ${CPU_FLAGS_X86[@]/#/cpu_flags_x86_}
+component-build cups -debug gtk4 +hangouts headless +js-type-check kerberos +official
+pic +proprietary-codecs pulseaudio screencast selinux +suid -system-ffmpeg
+-system-icu -system-harfbuzz -system-png +vaapi wayland widevine"
+IUSE+=" weston r0"
+# What is considered a proprietary codec can be found at:
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/media/filters/BUILD.gn#L160
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/media/media_options.gni#L38
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/media/base/supported_types.cc#L203
+#     Upstream doesn't consider MP3 proprietary, but this ebuild does.
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/media/base/supported_types.cc#L284
+# Codec upstream default: https://github.com/chromium/chromium/blob/100.0.4896.75/tools/mb/mb_config_expectations/chromium.linux.json#L89
+IUSE+=" video_cards_amdgpu video_cards_intel video_cards_iris
+video_cards_i965 video_cards_nouveau video_cards_nvidia
+video_cards_r600 video_cards_radeonsi" # For VA-API
+IUSE+=" +partitionalloc libcmalloc"
+# For cfi-vcall, cfi-icall defaults status, see \
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/build/config/sanitizers/sanitizers.gni
+# For cfi-cast default status, see \
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/build/config/sanitizers/sanitizers.gni#L123
+# For pgo default status, see \
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/build/config/compiler/pgo/pgo.gni#L15
+# For libcxx default, see \
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/build/config/c++/c++.gni#L14
+# For cdm availability see third_party/widevine/cdm/widevine.gni#L28
+IUSE_LIBCXX=( bundled-libcxx system-libstdcxx )
+IUSE+=" ${IUSE_LIBCXX[@]} +bundled-libcxx branch-protection-standard +cfi-vcall
+cfi-cast +cfi-icall +clang +pre-check-llvm +pre-check-vaapi lto-opt +pgo
+-pgo-full shadowcallstack"
+# perf-opt
+_ABIS=( abi_x86_32
+	abi_x86_64
+	abi_x86_x32
+	abi_mips_n32
+	abi_mips_n64
+	abi_mips_o32
+	abi_ppc_32
+	abi_ppc_64
+	abi_s390_32
+	abi_s390_64 )
+IUSE+=" ${_ABIS[@]}"
+BENCHMARKS_DESKTOP=(
+	desktop_ui
+	loading.desktop
+	media.desktop
+	memory.desktop
+	power.desktop
+	rendering.desktop
+	system_health.common_desktop
+	system_health.memory_desktop
+	UNSCHEDULED_v8.loading_desktop
+	v8.browsing_desktop
+	v8.browsing_desktop-future
+)
+BENCHMARKS_MOBILE=(
+	loading.mobile
+	media.mobile
+	power.mobile
+	rendering.mobile
+	startup.mobile
+	system_health.common_mobile
+	system_health.memory_mobile
+	UNSCHEDULED_v8.loading_mobile
+	v8.browsing_mobile
+	v8.browsing_mobile-future
+)
+
+# Official except for UNSCHEDULED_*
+OFFICIAL_BENCHMARKS=(
+	blink_perf.accessibility
+	blink_perf.bindings
+	blink_perf.css
+	blink_perf.display_locking
+	blink_perf.dom
+	blink_perf.events
+	blink_perf.image_decoder
+	blink_perf.layout
+	blink_perf.owp_storage
+	blink_perf.paint
+	blink_perf.parser
+	blink_perf.sanitizer-api
+	blink_perf.shadow_dom
+	blink_perf.svg
+	blink_perf.webaudio
+	blink_perf.webgl
+	blink_perf.webgl_fast_call
+	blink_perf.webgpu
+	blink_perf.webgpu_fast_call
+	custom
+	desktop_ui
+	dromaeo
+	dummy_benchmark.noisy_benchmark_1
+	dummy_benchmark.stable_benchmark_1
+	jetstream
+	jetstream2
+	kraken
+	loading.desktop
+	loading.mobile
+	media.desktop
+	media.mobile
+	memory.desktop
+	octane
+	power.desktop
+	power.mobile
+	rasterize_and_record_micro
+	rasterize_and_record_micro.top_25
+	rendering.desktop
+	rendering.mobile
+	speedometer
+	speedometer-future
+	speedometer2
+	speedometer2-future
+	speedometer2-pcscan
+	startup.mobile
+	system_health.common_desktop
+	system_health.common_mobile
+	system_health.memory_desktop
+	system_health.memory_mobile
+	system_health.pcscan
+	system_health.weblayer_startup
+	system_health.webview_startup
+	tab_switching.typical_25
+	tracing.tracing_with_background_memory_infra
+	UNSCHEDULED_blink_perf.performance_apis
+	UNSCHEDULED_blink_perf.service_worker
+	UNSCHEDULED_loading.mbi
+	UNSCHEDULED_v8.loading_desktop
+	UNSCHEDULED_v8.loading_mobile
+	v8.browsing_desktop
+	v8.browsing_desktop-future
+	v8.browsing_mobile
+	v8.browsing_mobile-future
+	v8.runtime_stats.top_25
+	wasmpspdfkit
+	webrtc
+)
+
+CONTRIB_BENCHMARKS_DISABLED=(
+	ad_tagging.cluster_telemetry
+	blink_perf
+	blink_perf.layout_ng
+	blink_perf.paint_layout_ng
+	blink_perf.parser_layout_ng
+	blink_perf.privacy_budget
+	download.mobile
+	generic_trace_ct
+	generic_trace.top25
+	layout_shift.cluster_telemetry
+	leak_detection.cluster_telemetry
+	loading.cluster_telemetry
+	loading.desktop_layout_ng
+	loading.mobile_layout_ng
+	media_router.cpu_memory
+	media_router.cpu_memory.no_media_router
+	memory.cluster_telemetry
+	memory.leak_detection
+	memory.long_running_desktop_sites
+	multipage_skpicture_printer
+	multipage_skpicture_printer_ct
+	orderfile_generation.debugging
+	orderfile_generation.testing
+	orderfile_generation.training
+	orderfile_generation.variation.testing0
+	orderfile_generation.variation.testing1
+	orderfile_generation.variation.testing2
+	orderfile_generation.variation.training
+	orderfile.memory_mobile
+	rasterize_and_record_micro_ct
+	rendering.cluster_telemetry
+	repaint_ct
+	screenshot_ct
+	skpicture_printer
+	skpicture_printer_ct
+	system_health.scroll_jank_mobile
+	tracing.tracing_with_debug_overhead
+	v8.loading.cluster_telemetry
+	v8.loading_runtime_stats.cluster_telemetry
+)
+
+CONTRIB_BENCHMARKS=(
+	xr.webxr.static
+)
+
+gen_pgo_profile_use() {
+	for x in ${OFFICIAL_BENCHMARKS[@]} ${CONTRIB_BENCHMARKS[@]} ; do
+		t="${x}"
+		t="${t//-/_}"
+		t="${t//./_}"
+		t="${t,,}"
+		echo " cr_pgo_trainers_${t}"
+	done
+}
+gen_pgo_profile_required_use() {
+	for d in ${BENCHMARK_DESKTOP[@]} ; do
+		a="${d}"
+		a="${a//-/_}"
+		a="${a//./_}"
+		a="${a,,}"
+		for m in ${BENCHMARK_MOBILE[@]} ; do
+			b="${m}"
+			b="${b//-/_}"
+			b="${b//./_}"
+			b="${b,,}"
+			echo "
+				cr_pgo_trainers_${a}? ( pgo-full !cr_pgo_trainers_${b} )
+				cr_pgo_trainers_${b}? ( pgo-full !cr_pgo_trainers_${a} )
+			"
+		done
+	done
+	for x in ${OFFICIAL_BENCHMARKS[@]} ${CONTRIB_BENCHMARKS[@]} ; do
+		t="${x}"
+		t="${t//-/_}"
+		t="${t//./_}"
+		t="${t,,}"
+		echo " cr_pgo_trainers_${t}? ( pgo-full )"
+	done
+}
+
+# There is 2 official (perflab) platforms for linux:  linux and linux_rel.
+# ~50 benchmarks used.
+gen_required_use_pgo_profile_linux() { # For CI
+	# See
+# https://github.com/chromium/chromium/blob/100.0.4896.75/tools/perf/core/bot_platforms.py#L311
+# https://github.com/chromium/chromium/blob/100.0.4896.75/tools/perf/core/bot_platforms.py#L226
+# https://github.com/chromium/chromium/blob/100.0.4896.75/tools/perf/core/shard_maps/linux-perf_map.json
+	local exclude=(
+		blink_perf.display_locking
+		power.mobile
+		v8.runtime_stats.top_25
+	)
+	for x in ${OFFICIAL_BENCHMARKS[@]} ; do
+		t="${x}"
+		t_raw="${x}"
+		t="${t//-/_}"
+		t="${t//./_}"
+		t="${t,,}"
+		local excluded=0
+		for ex in ${exclude[@]} ; do
+			if [[ "${t_raw}" == "${ex}" ]] ; then
+				excluded=1
+			fi
+		done
+		if [[ "${t_raw}" =~ ^"UNSCHEDULED" \
+			|| "${t_raw}" == "custom" \
+			|| "${t_raw}" == ".mobile"$ \
+			]] ; then
+			excluded=1
+		fi
+		if (( excluded == 1 )) ; then
+			echo " !cr_pgo_trainers_${t}"
+		else
+			echo " cr_pgo_trainers_${t}"
+		fi
+	done
+	for x in ${CONTRIB_BENCHMARKS[@]} ; do
+		t="${x}"
+		t="${t//-/_}"
+		t="${t//./_}"
+		t="${t,,}"
+		echo " !cr_pgo_trainers_${t}"
+	done
+}
+
+# Only 1 benchmark used.
+gen_required_use_pgo_profile_linux_rel() { # For CI release
+	# See
+# https://github.com/chromium/chromium/blob/100.0.4896.75/tools/perf/core/bot_platforms.py#L307
+# https://github.com/chromium/chromium/blob/100.0.4896.75/tools/perf/core/shard_maps/linux-perf-rel_map.json
+	local whitelist=(
+		system_health.common_desktop
+	)
+	for x in ${OFFICIAL_BENCHMARKS[@]} ; do
+		t="${x}"
+		t_raw="${x}"
+		t="${t//-/_}"
+		t="${t//./_}"
+		t="${t,,}"
+		local included=0
+		for wl in ${whitelist[@]} ; do
+			if [[ "${t_raw}" == "${wl}" ]] ; then
+				included=1
+			fi
+		done
+		if (( included == 1 )) ; then
+			echo " cr_pgo_trainers_${t}"
+		else
+			echo " !cr_pgo_trainers_${t}"
+		fi
+	done
+	for x in ${CONTRIB_BENCHMARKS[@]} ; do
+		t="${x}"
+		t="${t//-/_}"
+		t="${t//./_}"
+		t="${t,,}"
+		echo " !cr_pgo_trainers_${t}"
+	done
+}
+
+PGO_PROFILE_LINUX_SET=$(gen_required_use_pgo_profile_linux)
+PGO_PROFILE_LINUX_SET_REL=$(gen_required_use_pgo_profile_linux_rel)
+IUSE+=" "$(gen_pgo_profile_use)
+REQUIRED_USE+=" $(gen_pgo_profile_required_use)"
+REQUIRED_USE+=" pgo-full? ( || ( $(gen_pgo_profile_use) ) )"
+# TODO:  Update pgo-full with complete (or near complete) PGO set
+# when official USE selected.
+# The cr_pgo_trainers_custom is disallowed for security reasons
+# when the official USE is set.
+# vaapi is not conditioned on proprietary-codecs upstream, but should
+# be or by case-by-case (i.e. h264_vaapi, vp9_vaapi, av1_vaapi)
+# with additional USE flags.
+# The system-ffmpeg comes with aac which is unavoidable.  This is why
+# there is a block with !proprietary-codecs.
+# cfi-icall, cfi-cast requires static linking.  See
+#   https://clang.llvm.org/docs/ControlFlowIntegrity.html#indirect-function-call-checking
+#   https://clang.llvm.org/docs/ControlFlowIntegrity.html#bad-cast-checking
+REQUIRED_USE+="
+	^^ ( ${IUSE_LIBCXX[@]} )
+	^^ ( partitionalloc libcmalloc )
+	!clang? ( !cfi-cast !cfi-icall !cfi-vcall !shadowcallstack )
+	!proprietary-codecs? ( !system-ffmpeg !vaapi )
+	amd64? ( !shadowcallstack )
+	bundled-libcxx? ( clang )
+	branch-protection-standard? ( arm64 )
+	cfi-cast? ( cfi-vcall !system-ffmpeg !system-harfbuzz !system-icu !system-libstdcxx )
+	cfi-icall? ( cfi-vcall !system-ffmpeg !system-harfbuzz !system-icu !system-libstdcxx )
+	cfi-vcall? ( clang !system-ffmpeg !system-harfbuzz !system-icu !system-libstdcxx )
+	component-build? ( !bundled-libcxx !suid )
+	lto-opt? ( clang )
+	official? (
+		^^ ( pgo pgo-full )
+		!debug
+		!system-ffmpeg
+		!system-harfbuzz
+		!system-icu
+		!system-libstdcxx
+		bundled-libcxx
+		partitionalloc
+		amd64? ( cfi-icall cfi-vcall )
+		pgo-full? ( ${PGO_PROFILE_LINUX_SET_REL} )
+	)
+	partitionalloc? ( !component-build )
+	pgo? ( clang !pgo-full )
+	pgo-full? ( clang !pgo )
+	ppc64? ( !shadowcallstack )
+	pre-check-llvm? ( clang )
+	pre-check-vaapi? ( vaapi )
 	screencast? ( wayland )
+	shadowcallstack? ( clang )
+	system-libstdcxx? ( !cfi-cast )
+	system-libstdcxx? ( !cfi-icall )
+	system-libstdcxx? ( !cfi-vcall )
+	vaapi? ( proprietary-codecs )
+	video_cards_amdgpu? (
+		!video_cards_r600
+		!video_cards_radeonsi
+	)
+	video_cards_r600? (
+		!video_cards_amdgpu
+		!video_cards_radeonsi
+	)
+	video_cards_radeonsi? (
+		!video_cards_amdgpu
+		!video_cards_r600
+	)
+	widevine? ( !arm64 !ppc64 )
+	x86? ( !shadowcallstack )
 "
 
+LIBVA_V="2.7"
+FFMPEG_V="4.3"
+
+LIBVA_DEPEND="
+	vaapi? (
+		|| (
+			video_cards_amdgpu? (
+				media-libs/mesa:=[gallium,vaapi,video_cards_radeonsi,${MULTILIB_USEDEP}]
+			)
+			video_cards_i965? (
+				|| (
+					x11-libs/libva-intel-media-driver
+					x11-libs/libva-intel-driver[${MULTILIB_USEDEP}]
+				)
+			)
+			video_cards_intel? (
+				|| (
+					x11-libs/libva-intel-media-driver
+					x11-libs/libva-intel-driver[${MULTILIB_USEDEP}]
+				)
+			)
+			video_cards_iris? (
+				x11-libs/libva-intel-media-driver
+			)
+			video_cards_nouveau? (
+				media-libs/mesa:=[gallium,video_cards_nouveau,${MULTILIB_USEDEP}]
+				|| (
+					media-libs/mesa:=[gallium,vaapi,video_cards_nouveau,${MULTILIB_USEDEP}]
+					>=x11-libs/libva-vdpau-driver-0.7.4-r3[${MULTILIB_USEDEP}]
+				)
+			)
+			video_cards_nvidia? (
+				>=x11-libs/libva-vdpau-driver-0.7.4-r1[${MULTILIB_USEDEP}]
+				x11-drivers/nvidia-drivers
+			)
+			video_cards_r600? (
+				media-libs/mesa:=[gallium,vaapi,video_cards_r600,${MULTILIB_USEDEP}]
+			)
+			video_cards_radeonsi? (
+				media-libs/mesa:=[gallium,vaapi,video_cards_radeonsi,${MULTILIB_USEDEP}]
+			)
+		)
+		>=x11-libs/libva-${LIBVA_V}:=[${MULTILIB_USEDEP}]
+		system-ffmpeg? ( >=media-video/ffmpeg-${FFMPEG_V}[vaapi,${MULTILIB_USEDEP}] )
+	)
+"
+
+gen_bdepend_llvm() {
+	local o_all=""
+	local t=""
+	local o_official=""
+	for s in ${LLVM_SLOTS[@]} ; do
+		t="
+			sys-devel/clang:${s}[${MULTILIB_USEDEP}]
+			sys-devel/llvm:${s}[${MULTILIB_USEDEP}]
+			=sys-devel/clang-runtime-${s}*[${MULTILIB_USEDEP},compiler-rt,sanitize]
+			>=sys-devel/lld-${s}
+			=sys-libs/compiler-rt-${s}*
+			=sys-libs/compiler-rt-sanitizers-${s}*:=[shadowcallstack?]
+			cfi-cast? ( =sys-libs/compiler-rt-sanitizers-${s}*:=[cfi] )
+			cfi-icall? ( =sys-libs/compiler-rt-sanitizers-${s}*:=[cfi] )
+			cfi-vcall? ( =sys-libs/compiler-rt-sanitizers-${s}*:=[cfi] )
+		"
+		o_all+=" ( ${t} ) "
+		(( ${s} == ${CR_CLANG_SLOT_OFFICIAL} )) && o_official=" ${t} "
+	done
+	echo -e "
+		|| ( ${o_all} )
+		official? ( ${o_official} )
+	"
+}
+
 COMMON_X_DEPEND="
-	x11-libs/gdk-pixbuf:2
-	x11-libs/libXcomposite:=
-	x11-libs/libXcursor:=
-	x11-libs/libXdamage:=
-	x11-libs/libXfixes:=
-	>=x11-libs/libXi-1.6.0:=
-	x11-libs/libXrandr:=
-	x11-libs/libXrender:=
-	x11-libs/libXtst:=
-	x11-libs/libxshmfence:=
-	virtual/opengl
+	x11-libs/gdk-pixbuf:2[${MULTILIB_USEDEP}]
+	x11-libs/libXcomposite:=[${MULTILIB_USEDEP}]
+	x11-libs/libXcursor:=[${MULTILIB_USEDEP}]
+	x11-libs/libXdamage:=[${MULTILIB_USEDEP}]
+	x11-libs/libXfixes:=[${MULTILIB_USEDEP}]
+	>=x11-libs/libXi-1.6.0:=[${MULTILIB_USEDEP}]
+	x11-libs/libXrandr:=[${MULTILIB_USEDEP}]
+	x11-libs/libXrender:=[${MULTILIB_USEDEP}]
+	x11-libs/libXtst:=[${MULTILIB_USEDEP}]
+	x11-libs/libxshmfence:=[${MULTILIB_USEDEP}]
+	virtual/opengl[${MULTILIB_USEDEP}]
 "
 
 COMMON_SNAPSHOT_DEPEND="
-	system-icu? ( >=dev-libs/icu-69.1:= )
-	>=dev-libs/libxml2-2.9.4-r3:=[icu]
-	dev-libs/nspr:=
-	>=dev-libs/nss-3.26:=
-	!libcxx? ( >=dev-libs/re2-0.2019.08.01:= )
-	dev-libs/libxslt:=
-	media-libs/fontconfig:=
-	>=media-libs/freetype-2.11.0-r1:=
-	system-harfbuzz? ( >=media-libs/harfbuzz-3:0=[icu(-)] )
-	media-libs/libjpeg-turbo:=
-	system-png? ( media-libs/libpng:=[-apng] )
-	>=media-libs/libwebp-0.4.0:=
-	media-libs/mesa:=[gbm(+)]
-	>=media-libs/openh264-1.6.0:=
-	sys-libs/zlib:=
-	x11-libs/libdrm:=
+	system-icu? ( >=dev-libs/icu-69.1:=[${MULTILIB_USEDEP}] )
+	>=dev-libs/libxml2-2.9.4-r3:=[icu,${MULTILIB_USEDEP}]
+	dev-libs/nspr:=[${MULTILIB_USEDEP}]
+	>=dev-libs/nss-3.26:=[${MULTILIB_USEDEP}]
+	system-libstdcxx? ( >=dev-libs/re2-0.2019.08.01:=[${MULTILIB_USEDEP}] )
+	dev-libs/libxslt:=[${MULTILIB_USEDEP}]
+	media-libs/fontconfig:=[${MULTILIB_USEDEP}]
+	>=media-libs/freetype-2.11.0-r1:=[${MULTILIB_USEDEP}]
+	system-harfbuzz? ( >=media-libs/harfbuzz-3:0=[icu(-),${MULTILIB_USEDEP}] )
+	media-libs/libjpeg-turbo:=[${MULTILIB_USEDEP}]
+	system-png? ( media-libs/libpng:=[-apng,${MULTILIB_USEDEP}] )
+	>=media-libs/libwebp-0.4.0:=[${MULTILIB_USEDEP}]
+	media-libs/mesa:=[gbm(+),${MULTILIB_USEDEP}]
+	proprietary-codecs? ( >=media-libs/openh264-1.6.0:=[${MULTILIB_USEDEP}] )
+	sys-libs/zlib:=[${MULTILIB_USEDEP}]
+	x11-libs/libdrm:=[${MULTILIB_USEDEP}]
 	!headless? (
-		dev-libs/glib:2
-		>=media-libs/alsa-lib-1.0.19:=
-		pulseaudio? ( media-sound/pulseaudio:= )
-		kerberos? ( virtual/krb5 )
-		vaapi? ( >=x11-libs/libva-2.7:=[X] )
-		x11-libs/libX11:=
-		x11-libs/libXext:=
-		x11-libs/libxcb:=
-		x11-libs/libxkbcommon:=
+		dev-libs/glib:2[${MULTILIB_USEDEP}]
+		>=media-libs/alsa-lib-1.0.19:=[${MULTILIB_USEDEP}]
+		pulseaudio? ( media-sound/pulseaudio:=[${MULTILIB_USEDEP}] )
+		kerberos? ( virtual/krb5[${MULTILIB_USEDEP}] )
+		vaapi? ( >=x11-libs/libva-${LIBVA_V}:=[X,drm,${MULTILIB_USEDEP}] )
+		x11-libs/libX11:=[${MULTILIB_USEDEP}]
+		x11-libs/libXext:=[${MULTILIB_USEDEP}]
+		x11-libs/libxcb:=[${MULTILIB_USEDEP}]
+		x11-libs/libxkbcommon:=[${MULTILIB_USEDEP}]
 		wayland? (
-			dev-libs/wayland:=
-			screencast? ( media-video/pipewire:= )
+			dev-libs/wayland:=[${MULTILIB_USEDEP}]
+			screencast? ( media-video/pipewire:=[${MULTILIB_USEDEP}] )
 		)
 	)
 "
 
 COMMON_DEPEND="
 	${COMMON_SNAPSHOT_DEPEND}
-	app-arch/bzip2:=
-	dev-libs/expat:=
+	${LIBVA_DEPEND}
+	app-arch/bzip2:=[${MULTILIB_USEDEP}]
+	dev-libs/expat:=[${MULTILIB_USEDEP}]
 	system-ffmpeg? (
-		>=media-video/ffmpeg-4.3:=
+		>=media-video/ffmpeg-${FFMPEG_V}:=[${MULTILIB_USEDEP}]
 		|| (
-			media-video/ffmpeg[-samba]
-			>=net-fs/samba-4.5.10-r1[-debug(-)]
+			>=media-video/ffmpeg-${FFMPEG_V}[-samba,${MULTILIB_USEDEP}]
+			>=net-fs/samba-4.5.10-r1[-debug(-),${MULTILIB_USEDEP}]
 		)
-		>=media-libs/opus-1.3.1:=
+		>=media-libs/opus-1.3.1:=[${MULTILIB_USEDEP}]
 	)
-	net-misc/curl[ssl]
-	sys-apps/dbus:=
-	media-libs/flac:=
-	sys-libs/zlib:=[minizip]
+	net-misc/curl[ssl,${MULTILIB_USEDEP}]
+	sys-apps/dbus:=[${MULTILIB_USEDEP}]
+	media-libs/flac:=[${MULTILIB_USEDEP}]
+	sys-libs/zlib:=[minizip,${MULTILIB_USEDEP}]
 	!headless? (
 		${COMMON_X_DEPEND}
-		>=app-accessibility/at-spi2-atk-2.26:2
-		>=app-accessibility/at-spi2-core-2.26:2
-		>=dev-libs/atk-2.26
-		cups? ( >=net-print/cups-1.3.11:= )
-		sys-apps/pciutils:=
-		virtual/udev
-		x11-libs/cairo:=
-		x11-libs/pango:=
+		>=app-accessibility/at-spi2-atk-2.26:2[${MULTILIB_USEDEP}]
+		>=app-accessibility/at-spi2-core-2.26:2[${MULTILIB_USEDEP}]
+		>=dev-libs/atk-2.26[${MULTILIB_USEDEP}]
+		cups? ( >=net-print/cups-1.3.11:=[${MULTILIB_USEDEP}] )
+		sys-apps/pciutils:=[${MULTILIB_USEDEP}]
+		|| (
+			>=sys-fs/udev-217[${MULTILIB_USEDEP}]
+			>=sys-fs/eudev-2.1.1[${MULTILIB_USEDEP}]
+			>=sys-apps/systemd-217[${MULTILIB_USEDEP}]
+		)
+		x11-libs/cairo:=[${MULTILIB_USEDEP}]
+		x11-libs/pango:=[${MULTILIB_USEDEP}]
 	)
 "
 RDEPEND="${COMMON_DEPEND}
 	!headless? (
 		|| (
-			x11-libs/gtk+:3[X,wayland?]
+			x11-libs/gtk+:3[X,wayland?,${MULTILIB_USEDEP}]
 			gui-libs/gtk:4[X,wayland?]
 		)
 	)
@@ -119,7 +889,7 @@ RDEPEND="${COMMON_DEPEND}
 "
 DEPEND="${COMMON_DEPEND}
 	!headless? (
-		gtk4? ( gui-libs/gtk:4[X,wayland?] )
+		gtk4? ( gui-libs/gtk:4[X,wayland?,${MULTILIB_USEDEP}] )
 		!gtk4? ( x11-libs/gtk+:3[X,wayland?] )
 	)
 "
@@ -130,26 +900,84 @@ BDEPEND="
 		dev-python/setuptools[${PYTHON_USEDEP}]
 	')
 	>=app-arch/gzip-1.7
-	libcxx? ( >=sys-devel/clang-12 )
 	dev-lang/perl
 	>=dev-util/gn-0.1807
 	>=dev-util/gperf-3.0.3
 	>=dev-util/ninja-1.7.2
 	>=net-libs/nodejs-7.6.0[inspector]
 	>=sys-devel/bison-2.4.3
-	sys-devel/flex
-	virtual/pkgconfig
+	sys-devel/flex[${MULTILIB_USEDEP}]
+	>=dev-util/pkgconf-1.3.7[${MULTILIB_USEDEP},pkg-config(+)]
+	clang? ( $(gen_bdepend_llvm) )
 	js-type-check? ( virtual/jre )
+	pgo-full? (
+		sys-apps/dbus:=[${MULTILIB_USEDEP}]
+		sys-apps/grep[pcre]
+		!headless? (
+			!weston? (
+				x11-base/xorg-server[xvfb]
+				x11-misc/xcompmgr
+				x11-wm/openbox
+			)
+			weston? ( dev-libs/weston )
+		)
+		cr_pgo_trainers_memory_desktop? (
+			media-video/ffmpeg[encode]
+		)
+		cr_pgo_trainers_media_desktop? (
+			proprietary-codecs? (
+				media-video/ffmpeg[encode,openh264]
+				media-video/ffmpeg[encode,mp3]
+			)
+			media-video/ffmpeg[encode,libaom]
+			media-video/ffmpeg[opus,vorbis,vpx]
+		)
+		cr_pgo_trainers_media_mobile? (
+			proprietary-codecs? (
+				media-video/ffmpeg[encode,openh264]
+				media-video/ffmpeg[encode,mp3]
+			)
+			media-video/ffmpeg[opus,vorbis,vpx]
+		)
+	)
+	vaapi? ( media-video/libva-utils )
 "
 
-# These are intended for ebuild maintainer use to force clang if GCC is broken.
-: ${CHROMIUM_FORCE_CLANG=no}
+# pgo related:  dev-python/requests is python3 but testing/scripts/run_performance_tests.py is python2
 
-if [[ ${CHROMIUM_FORCE_CLANG} == yes ]]; then
-	BDEPEND+=" >=sys-devel/clang-12"
-fi
+# Upstream uses llvm:13
+# When CFI + PGO + official was tested, it didn't work well with LLVM12.  Error noted in
+# https://github.com/orsonteodoro/oiledmachine-overlay/blob/f0c13049dc89f068370511b4664f7fb111df2d3a/www-client/chromium/bug_notes
+# This is why LLVM13 was set as the minimum and did fix the problem.
+
+# For the current llvm for this project, see
+#   https://github.com/chromium/chromium/blob/100.0.4896.75/tools/clang/scripts/update.py#L42
+# Use the same clang for official USE flag because of older llvm bugs which
+#   could result in security weaknesses (explained in the llvm:12 note below).
+# Used llvm >= 12 for arm64 for the same reason in the Linux kernel CFI comment.
+#   Links below from https://github.com/torvalds/linux/commit/cf68fffb66d60d96209446bfc4a15291dc5a5d41
+#     https://bugs.llvm.org/show_bug.cgi?id=46258
+#     https://bugs.llvm.org/show_bug.cgi?id=47479
+# To confirm the hash version match for the reported by CR_CLANG_REVISION, see
+#   https://github.com/llvm/llvm-project/blob/98033fdc/llvm/CMakeLists.txt
+
+# The preference now is CFI Cross-DSO if one prefers unbundled libs.
+# CFI Cross-DSO is preferred to reduce duplicate pages at the cost of some
+# security usually cfi-icall.  This is why CFI Basic mode (.a) is preferred
+# and better security quality because cfi-icall is less buggy.  Using
+# CFI Basic mode require more ebuild modding to isolate both .so/.a
+# builds for -fvisibility changes.  Most ebuilds combine both, so for now
+# only CFI Cross-DSO is the only practical recourse.
+
+# Some libs here cannot be CFIed in @system due to IR incompatibility because
+# gcc cannot use LLVM bitcode in .a files.  This is why the internal zlib is
+# preferred over systemwide zlib in systems without CFI hardware implementation.
+
+# Some require CFI flags because they support both CFI Cross-DSO mode (.so) and
+# CFI Basic mode (.a).  Some should have the CFI flag so that CFI packages
+# are properly prioritized in *DEPENDs to avoid missing symbols problems.
 
-if ! has chromium_pkg_die ${EBUILD_DEATH_HOOKS}; then
+if ! has chromium_pkg_die ${EBUILD_DEATH_HOOKS} ; then
 	EBUILD_DEATH_HOOKS+=" chromium_pkg_die";
 fi
 
@@ -187,32 +1015,91 @@ python_check_deps() {
 }
 
 pre_build_checks() {
-	if [[ ${MERGE_TYPE} != binary ]]; then
+	if [[ ${MERGE_TYPE} != binary ]] ; then
 		local -x CPP="$(tc-getCXX) -E"
-		if tc-is-gcc && ! ver_test "$(gcc-version)" -ge 9.2; then
+		if tc-is-gcc && ! ver_test "$(gcc-version)" -ge 9.2 ; then
 			die "At least gcc 9.2 is required"
 		fi
-		if [[ ${CHROMIUM_FORCE_CLANG} == yes ]] || tc-is-clang || use libcxx; then
+		if use clang || tc-is-clang ; then
 			tc-is-cross-compiler && CPP=${CBUILD}-clang++ || CPP=${CHOST}-clang++
 			CPP+=" -E"
-			if ! ver_test "$(clang-major-version)" -ge 12; then
-				die "At least clang 12 is required"
+			local clang_min
+			if use official ; then
+				clang_min=${CR_CLANG_SLOT_OFFICIAL}
+			else
+				clang_min=${LLVM_MIN_SLOT}
+			fi
+			if ! ver_test "$(clang-major-version)" -ge ${clang_min} ; then
+				die "At least clang ${clang_min} is required"
 			fi
 		fi
 	fi
 
+	# https://github.com/chromium/chromium/blob/100.0.4896.75/docs/linux/build_instructions.md#system-requirements
 	# Check build requirements, bug #541816 and bug #471810 .
 	CHECKREQS_MEMORY="4G"
 	CHECKREQS_DISK_BUILD="9G"
 	tc-is-cross-compiler && CHECKREQS_DISK_BUILD="12G"
-	if ( shopt -s extglob; is-flagq '-g?(gdb)?([1-9])' ); then
-		if use custom-cflags || use component-build; then
+	if ( shopt -s extglob; is-flagq '-g?(gdb)?([1-9])' ) ; then
+		if use custom-cflags || use component-build ; then
 			CHECKREQS_DISK_BUILD="25G"
 		fi
-		if ! use component-build; then
+		if ! use component-build ; then
 			CHECKREQS_MEMORY="16G"
 		fi
 	fi
+
+	# Assumes 2.1875 ratio (as the uncompressed:compressed ratio)
+	local has_compressed_memory=0
+	local required_total_memory=27
+	local required_total_memory_lto=16
+	if grep -q -e "Y" "/sys/module/zswap/parameters/enabled" ; then
+		has_compressed_memory=1
+		required_total_memory=12 # Done with zswap
+		required_total_memory_lto=8
+	fi
+
+	local total_memory_sources=$(free --giga | tail -n +2 \
+		| sed -r -e "s|[ ]+| |g" | cut -f 2 -d " ")
+	local total_memory=0
+	for total_memory_source in ${total_memory_sources[@]} ; do
+		total_memory=$((${total_memory} + ${total_memory_source}))
+	done
+	if (( ${total_memory} < ${required_total_memory} )) ; then
+# It randomly fails and a success observed with 8 GiB of total memory
+# (ram + swap) when multitasking.  It works with 16 GiB of total memory when
+# multitasking, but peak virtual memory (used + reserved) is ~10.2 GiB for
+# ld.lld.
+# [43742.787803] oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=/,mems_allowed=0,global_oom,task_memcg=/,task=ld.lld,pid=27154,uid=250
+# [43742.787817] Out of memory: Killed process 27154 (ld.lld) total-vm:10471016kB, anon-rss:2440396kB, file-rss:3180kB, shmem-rss:0kB, UID:250 pgtables:20168kB oom_score_adj:0
+# [43744.101600] oom_reaper: reaped process 27154 (ld.lld), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
+ewarn
+ewarn "You may need >= ${required_total_memory} GiB of total memory to link"
+ewarn "${PN}.  Please add more swap space or enable swap compression.  You"
+ewarn "currently have ${total_memory} GiB of total memory."
+ewarn
+	else
+einfo
+einfo "Total memory is sufficient (>= ${required_total_memory} GiB met)."
+einfo
+	fi
+
+	if use lto-opt && (( ${total_memory} <= ${required_total_memory_lto} )) ; then
+eerror
+eerror "lto-opt requires >= ${required_total_memory_lto} of total memory.  Add"
+eerror "more swap space or enable swap compression."
+eerror
+		die
+	fi
+
+	if has_version "x11-libs/libva-intel-driver" ; then
+ewarn
+ewarn "x11-libs/libva-intel-driver is the older vaapi driver but intended for"
+ewarn "select hardware.  See also x11-libs/libva-intel-media-driver package"
+ewarn "to access more vaapi accelerated encoders if driver support overlaps."
+ewarn
+	fi
+
 	check-reqs_pkg_setup
 }
 
@@ -227,26 +1114,2036 @@ pkg_pretend() {
 	fi
 }
 
+# The answer to the profdata compatibility is answered in
+# https://clang.llvm.org/docs/SourceBasedCodeCoverage.html#format-compatibility-guarantees
+
+# The profdata (aka indexed profile) version is 7 corresponding from >= llvm 12
+# up to main branch (llvm 15) and is after the magic (lprofi - i for index) in the
+# profdata file located in chrome/build/pgo_profiles/*.profdata.
+
+# PGO version compatibility
+
+# Profdata versioning:
+# https://github.com/llvm/llvm-project/blob/5bec1ea7a74895895e7831fd951dd8130d4f3d01/llvm/include/llvm/ProfileData/InstrProf.h#L991
+# LLVM version:
+# https://github.com/llvm/llvm-project/blob/5bec1ea7a74895895e7831fd951dd8130d4f3d01/llvm/CMakeLists.txt#L14
+# The 37fbf238 is from the CR_CLANG_USED below.
+
+# Breaks PGO with non Linux platforms
+CF_CLANG_USED_13="98033fdc50e61273b1d5c77ba5f0f75afe3965c1" # LLVM 13 / 93.X
+CR_CLANG_USED_UNIX_TIMESTAMP_13="1626129557"
+
+# LLVM 15
+CR_CLANG_USED="5bec1ea7a74895895e7831fd951dd8130d4f3d01" # Obtained from \
+# https://github.com/chromium/chromium/blob/100.0.4896.75/tools/clang/scripts/update.py#L42
+CR_CLANG_USED_UNIX_TIMESTAMP="1645073650" # Cached.  Use below to obtain this. \
+# TIMESTAMP=$(wget -q -O - https://github.com/llvm/llvm-project/commit/${CR_CLANG_USED}.patch \
+#	| grep -F -e "Date:" | sed -e "s|Date: ||") ; date -u -d "${TIMESTAMP}" +%s
+# Change also CR_CLANG_SLOT_OFFICIAL
+
+contains_slotted_major_version() {
+	# For sys-devel/llvm:x slot style
+	local live_pkgs_=(
+		sys-devel/llvm
+		sys-devel/clang
+	)
+	local x="${1}"
+	local p
+	for p in ${live_pkgs_[@]} ; do
+		[[ "${x}" == "${p}" ]] && return 0
+	done
+	return 1
+}
+
+contains_slotted_triple_version() {
+	# For sys-libs/compiler-rt-sanitizers:x.y.z slot style
+	local live_pkgs_=(
+		sys-libs/compiler-rt
+		sys-libs/compiler-rt-sanitizers
+	)
+	local x="${1}"
+	local p
+	for p in ${live_pkgs_[@]} ; do
+		[[ "${x}" == "${p}" ]] && return 0
+	done
+	return 1
+}
+
+contains_slotted_zero() {
+	# For sys-devel/llvm:0 slot style
+	local live_pkgs_=(
+		sys-libs/libomp
+		sys-devel/lld
+	)
+	local x="${1}"
+	local p
+	for p in ${live_pkgs_[@]} ; do
+		[[ "${x}" == "${p}" ]] && return 0
+	done
+	return 1
+}
+
+_print_timestamps() {
+	if [[ -n "${emerged_llvm_timestamp}" ]] ; then
+		einfo "System's ${p} timestamp:  "$(date -d "@${emerged_llvm_timestamp}")
+		if [[ "${p}" == "sys-devel/llvm" ]] ; then
+			einfo "${PN^}'s LLVM timestamp:  "$(date -d "@${cr_clang_used_unix_timestamp}")
+		else
+			einfo "System's sys-devel/llvm timestamp:  "$(date -d "@${LLVM_TIMESTAMP}")
+		fi
+	fi
+}
+
+_get_release_hash() {
+	local v="${1}"
+	if [[ -z "${cached_release_hashes[${v}]}" ]] ; then
+
+		# This doesn't redirect to the tip
+		#local hash=$(git --no-pager ls-remote \
+		#	https://github.com/llvm/llvm-project.git \
+		#	llvmorg-${v} \
+		#	| cut -f 1 -d $'\t')
+
+		# Get the tip
+		local hash=$(
+			wget -q -O - https://github.com/llvm/llvm-project/commits/llvmorg-${v} \
+				| grep "/commit/" \
+				| head -n 1 \
+				| cut -f 2 -d "\"" \
+				| cut -f 5 -d "/"
+		)
+		cached_release_hashes[${v}]="${hash}"
+	fi
+	echo "${cached_release_hashes[${v}]}"
+}
+
+_get_llvm_timestamp() {
+	if [[ -z "${emerged_llvm_commit}" ]] ; then
+		# Should check against the llvm milestone if not live
+		#einfo "v=${v}"
+		#einfo "pv=${pv}"
+		while [[ "${pv:0:1}" =~ [A-Za-z] ]] ; do
+			pv="${pv#*-}"
+		done
+		v=$(ver_cut 1-3 "${pv}")
+		#einfo "v=${v} (2)"
+		local suffix=""
+		if [[ "${pv}" =~ "_rc" ]] ; then
+			suffix=$(echo "${pv}" | grep -E -o -e "_rc[0-9]+")
+			suffix=${suffix//_/-}
+		fi
+		v="${v}${suffix}"
+		#einfo "v=${v} (3)"
+		emerged_llvm_commit=$(_get_release_hash ${v})
+		einfo "emerged_llvm_commit=${emerged_llvm_commit}"
+	fi
+	einfo "emerged_llvm_commit=${emerged_llvm_commit}"
+	if [[ -z "${emerged_llvm_timestamps[${emerged_llvm_commit}]}" ]] ; then
+		einfo "Fetching timestamp for ${emerged_llvm_commit}"
+		# Uncached
+		# Fetched uncached because of potential partial download problems.
+		local emerged_llvm_time_desc=$(wget -q -O - \
+			https://github.com/llvm/llvm-project/commit/${emerged_llvm_commit}.patch)
+		[[ -z "${emerged_llvm_time_desc}" ]] \
+			&& die "${emerged_llvm_commit} didn't download anything."
+		echo "${emerged_llvm_time_desc}" | grep "Not Found" \
+			&& die "The commit ${emerged_llvm_commit} doesn't exist."
+		emerged_llvm_time_desc=$(echo -e "${emerged_llvm_time_desc}" | grep -F -e "Date:" | sed -e "s|Date: ||")
+		emerged_llvm_timestamp=$(date -u -d "${emerged_llvm_time_desc}" +%s)
+		emerged_llvm_timestamps[${emerged_llvm_commit}]=${emerged_llvm_timestamp}
+		einfo "Timestamp comparison for ${p}"
+		_print_timestamps
+	else
+		einfo "Using cached timestamp for ${emerged_llvm_commit}"
+		# Cached
+		emerged_llvm_timestamp=${emerged_llvm_timestamps[${emerged_llvm_commit}]}
+		einfo "Timestamp comparison for ${p}"
+		_print_timestamps
+	fi
+}
+
+_check_llvm_updated() {
+	local root_pkg_timestamp=""
+
+	local timestamp_type=-1
+	if [[ "${p}" == "sys-devel/llvm" ]] ; then
+		if use official ; then
+			#einfo "Using cr_clang_used_unix_timestamp"
+			root_pkg_timestamp="${cr_clang_used_unix_timestamp}"
+		else
+			#einfo "Using LLVM_TIMESTAMP"
+			root_pkg_timestamp="${LLVM_TIMESTAMP}"
+		fi
+		timestamp_type=0
+	else
+		#einfo "Using LLVM_TIMESTAMP"
+		root_pkg_timestamp="${LLVM_TIMESTAMP}"
+		timestamp_type=1
+	fi
+
+	[[ -z "${emerged_llvm_timestamp}" ]] && die
+	[[ -z "${root_pkg_timestamp}" ]] && die
+
+	if (( ${timestamp_type} == 0 )) ; then
+		#einfo "${emerged_llvm_timestamp} < ${root_pkg_timestamp} ? ${p} (1)"
+		if (( ${emerged_llvm_timestamp} < ${root_pkg_timestamp} )) ; then
+			#einfo "needs merge"
+			needs_emerge=1
+			llvm_packages_status[${p_}]="1" # needs emerge
+		else
+			#einfo "no merge needed"
+			llvm_packages_status[${p_}]="0" # package is okay
+		fi
+	else
+		#einfo "${emerged_llvm_timestamp} < ${root_pkg_timestamp} ? ${p} (1)"
+		if (( ${emerged_llvm_timestamp} < ${root_pkg_timestamp} )) ; then
+			#einfo "needs merge"
+			needs_emerge=1
+			llvm_packages_status[${p_}]="1" # needs emerge
+		else
+			#einfo "no merge needed"
+			llvm_packages_status[${p_}]="0" # package is okay
+		fi
+	fi
+}
+
+# For multiple sys-libs/compiler-rt-sanitizers:x.y.z
+_check_llvm_updated_triple() {
+	[[ -z "${emerged_llvm_timestamp}" ]] && die
+	[[ -z "${LLVM_TIMESTAMP}" ]] && die
+
+	#einfo "Using LLVM_TIMESTAMP"
+	#einfo "${emerged_llvm_timestamp} < ${LLVM_TIMESTAMP} ? ${p} (2)"
+	if (( ${emerged_llvm_timestamp} < ${LLVM_TIMESTAMP} )) ; then
+		#einfo "needs merge"
+		needs_emerge=1
+		llvm_packages_status[${p_}]="1" # needs emerge
+		old_triple_slot_packages+=( "${category}/${pn}:"$(cat "${mp}/SLOT") )
+	else
+		#einfo "no merge needed"
+		llvm_packages_status[${p_}]="0" # package is okay
+	fi
+}
+
+print_old_live_llvm_multislot_pkgs() {
+	local arg="${1}"
+	local llvm_slot="${2}"
+	for x in ${old_triple_slot_packages[@]} ; do
+		local slot=${x/:*}
+		if [[ "${arg}" == "${slot}" ]] ; then
+			LLVM_REPORT_CARDS[${llvm_slot}]+="emerge -1vuDN ${x}\n"
+		fi
+	done
+}
+
+verify_llvm_report_card() {
+	local llvm_slot=${1}
+	if (( ${needs_emerge} == 1 )) ; then
+		for p in ${live_pkgs[@]} ; do
+			local p_=${p//-/_}
+			p_=${p_//\//_}
+			if [[ -z "${llvm_packages_status[${p_}]}" ]] || (( ${llvm_packages_status[${p_}]} == 1 )) ; then
+				if contains_slotted_major_version "${p}" ; then
+					LLVM_REPORT_CARDS[${llvm_slot}]+="emerge -1vuDN ${p}:${llvm_slot}\n"
+				elif contains_slotted_triple_version "${p}" ; then
+					print_old_live_llvm_multislot_pkgs "${p}" ${llvm_slot}
+				elif contains_slotted_zero "${p}" ; then
+					LLVM_REPORT_CARDS[${llvm_slot}]+="emerge -1vuDN ${p}:0\n"
+				fi
+			fi
+		done
+	else
+		LLVM_REPORT_CARDS[${llvm_slot}]="pass"
+	fi
+}
+
+LLVM_TIMESTAMP=
+verify_llvm_toolchain() {
+	local llvm_slot=${1}
+	einfo "Inspecting for llvm:${llvm_slot}"
+
+	if use official ; then
+		cr_clang_used_unix_timestamp=${CR_CLANG_USED_UNIX_TIMESTAMP}
+	elif (( ${llvm_slot} == 13 )) ; then
+		cr_clang_used_unix_timestamp=${CR_CLANG_USED_UNIX_TIMESTAMP_13}
+	else
+		cr_clang_used_unix_timestamp=${CR_CLANG_USED_UNIX_TIMESTAMP}
+	fi
+
+	# Everything that inherits the llvm.org must be checked.
+	# sys-devel/clang-runtime doesn't need check
+	# 3 slot types
+	# sys-devel/llvm:x
+	# sys-devel/clang:x
+	# sys-libs/compiler-rt:x.y.z
+	# sys-libs/compiler-rt-sanitizers:x.y.z
+	# sys-libs/libomp:0
+	# sys-devel/lld:0
+	local live_pkgs=(
+		# Do not change the order!
+		sys-devel/llvm
+		sys-libs/libomp
+		sys-devel/lld
+		sys-devel/clang
+		sys-libs/compiler-rt
+		sys-libs/compiler-rt-sanitizers
+	)
+
+	unset emerged_llvm_timestamps
+	declare -A emerged_llvm_timestamps
+
+	unset llvm_packages_status
+	declare -A llvm_packages_status
+
+	unset cached_release_hashes
+	declare -A cached_release_hashes
+
+	local old_triple_slot_packages=()
+
+	[[ -z "${llvm_slot}" ]] && die "llvm_slot is empty"
+
+	local pass=0
+	local needs_emerge=0
+	# The llvm library or llvm-ar doesn't embed the hash info, so scan the /var/db/pkg.
+	if has_version "sys-devel/llvm:${llvm_slot}" ; then
+		for p in ${live_pkgs[@]} ; do
+			# Check each of the live packages that use llvm.org
+			# eclass.  Especially for forgetful types.
+
+			local emerged_llvm_commit
+
+			local p_=${p//-/_}
+			p_=${p_//\//_}
+			if contains_slotted_major_version "${p}" ; then
+				einfo
+				einfo "Checking ${p}:${llvm_slot}"
+				local path=$(realpath "${ESYSROOT}/var/db/pkg/${p}-${llvm_slot}"*"/environment.bz2")
+				if [[ -e "${path}" ]] ; then
+					emerged_llvm_commit=$(bzcat \
+						"${path}" \
+						| grep -F -e "EGIT_VERSION" | head -n 1 | cut -f 2 -d '"')
+					pv=$(cat "${ESYSROOT}/var/db/pkg/${p}-${llvm_slot}"*"/PF" | sed "s|${p}-||")
+					_get_llvm_timestamp
+					[[ "${p}" == "sys-devel/llvm" ]] \
+						&& LLVM_TIMESTAMP=${emerged_llvm_timestamp}
+				else
+					ewarn "Missing ${p}:${llvm_slot}"
+					p="sys-devel/llvm"
+					emerged_llvm_timestamp=$(( ${cr_clang_used_unix_timestamp} -1 ))
+				fi
+				_check_llvm_updated
+			elif contains_slotted_zero "${p}" ; then
+				einfo
+				einfo "Checking ${p}:0"
+				local path=$(realpath "${ESYSROOT}/var/db/pkg/${p}"*"/environment.bz2")
+				if [[ -e "${path}" ]] ; then
+					emerged_llvm_commit=$(bzcat \
+						"${path}" \
+						| grep -F -e "EGIT_VERSION" | head -n 1 | cut -f 2 -d '"')
+					pv=$(cat "${ESYSROOT}/var/db/pkg/${p}"*"/PF" | sed "s|${p}-||")
+					_get_llvm_timestamp
+				else
+					ewarn "Missing ${p}:${llvm_slot}"
+					p="sys-devel/llvm"
+					emerged_llvm_timestamp=$(( ${cr_clang_used_unix_timestamp} -1 ))
+				fi
+				_check_llvm_updated
+			else
+				local category=${p/\/*}
+				local pn=${p/*\/}
+				# Handle multiple slots (i.e multiple sys-libs/compiler-rt-sanitizers:x.y.z)
+				# We shouldn't have to deal with multiple sys-libs/compiler-rt-sanitizers
+				# 13.0.0.9999 13.0.0_rc3 13.0.0_rc2 versions installed at the same time
+				# for just 1 sys-libs/llvm but we have to.
+				for mp in $(find "${ESYSROOT}/var/db/pkg/${category}" \
+					-maxdepth 1 \
+					-type d \
+					-regextype "posix-extended" \
+					-regex ".*${pn}-${llvm_slot}.[0-9.]+") ; do
+					local path=$(realpath "${mp}/environment.bz2")
+					if [[ -e "${path}" ]] ; then
+						emerged_llvm_commit=$(bzcat \
+							"${path}" \
+							| grep -F -e "EGIT_VERSION" \
+							| head -n 1 \
+							| cut -f 2 -d '"')
+						pv=$(cat "${mp}/PF" | sed "s|${p}-||")
+						_get_llvm_timestamp
+					else
+						ewarn "Missing ${p}:${llvm_slot}"
+						emerged_llvm_timestamp=$(( ${cr_clang_used_unix_timestamp} -1 ))
+					fi
+					_check_llvm_updated_triple
+				done
+			fi
+		done
+		verify_llvm_report_card ${llvm_slot}
+	else
+		# For not installed
+		local compiler_rt_sanitizers_args=()
+		[[ "${USE}" =~ "cfi" ]] && compiler_rt_sanitizers_args+=( cfi ubsan )
+		use shadowcallstack && compiler_rt_sanitizers_args+=( shadowcallstack )
+		if (( ${#compiler_rt_sanitizers_args[@]} > 0 )) ; then
+			local args=$(echo "${compiler_rt_sanitizers_args[@]}" | tr " " ",")
+			LLVM_REPORT_CARDS[${llvm_slot}]="emerge -1vuDN clang:${llvm_slot} llvm:${llvm_slot} =clang-runtime-${llvm_slot}*[compiler-rt,sanitize] =sys-libs/compiler-rt-sanitizers-${llvm_slot}*[${args}]\n"
+		else
+			LLVM_REPORT_CARDS[${llvm_slot}]="emerge -1vuDN clang:${llvm_slot} llvm:${llvm_slot}\n"
+		fi
+	fi
+}
+
+find_video0() {
+	if [[ -z "${CR_PGO_VIDEO0}" ]] ; then
+eerror
+eerror "CR_PGO_VIDEO0 is missing the abspath to your vp8/vp9 video as a"
+eerror "per-package envvar.  The video must be 3840x2160 resolution,"
+eerror "60fps, >= 2 minutes."
+eerror
+		die
+	fi
+	if ffprobe "${CR_PGO_VIDEO0}" 2>/dev/null 1>/dev/null ; then
+		einfo "Verifying asset requirements"
+		if ! ( ffprobe "${CR_PGO_VIDEO0}" 2>&1 \
+			| grep -q -e "3840x2160" ) ; then
+eerror
+eerror "The PGO video sample must be 3840x2160."
+eerror
+			die
+		fi
+		if ! ( ffprobe "${CR_PGO_VIDEO0}" 2>&1 \
+			| grep -q -E -e ", (59|60)[.0-9]* fps" ) ; then
+eerror
+eerror "The PGO video sample must be >=59 fps."
+eerror
+			die
+		fi
+
+		local d=$(ffprobe "${CR_PGO_VIDEO0}" 2>&1 \
+			| grep -E -e "Duration" \
+			| cut -f 4 -d " " \
+			| sed -e "s|,||g" \
+			| cut -f 1 -d ".")
+		local h=$(($(echo "${d}" \
+			| cut -f 1 -d ":") * 60 * 60))
+		local m=$(($(echo "${d}" \
+			| cut -f 2 -d ":") * 60))
+		local s=$(($(echo "${d}" \
+			| cut -f 3 -d ":") * 1))
+		local t=$((${h} + ${m} + ${s}))
+		if (( ${t} < 120 )) ; then
+eerror
+eerror "The PGO video sample must be >= 2 minutes."
+eerror
+			die
+		fi
+	else
+eerror
+eerror "${CR_PGO_VIDEO0} is possibly not a valid video file.  Ensure that"
+eerror "the proper codec is supported for that file"
+eerror
+		die
+	fi
+}
+
+get_pregenerated_profdata_version()
+{
+	test -e "${S}/chrome/build/pgo_profiles/chrome-linux-"*".profdata" || die
+	echo $(od -An -j 8 -N 1 -t d1 "${S}/chrome/build/pgo_profiles/chrome-linux-"*".profdata" | grep -E -o -e "[0-7]+")
+}
+
+get_llvm_profdata_version_info()
+{
+	local profdata_v=0
+	local v
+	local ver
+	# The live versions can have different profdata versions over time.
+	for v in "11.1.0" "12.0.1" "13.0.0" "14.0.0_rc1" "14.0.0.9999" "15.0.0.9999" ; do
+		(( $(ver_cut 1 "${v}") != ${LLVM_SLOT} )) && continue
+		(! has_version "~sys-devel/llvm-${v}" ) && continue
+		local llvm_version
+		if [[ "${v}" =~ "9999" ]] ; then
+			local llvm_version=$(bzless \
+				"${ESYSROOT}/var/db/pkg/sys-devel/llvm-${v}"*"/environment.bz2" \
+				| grep -F -e "EGIT_VERSION" | head -n 1 | cut -f 2 -d '"')
+		else
+			llvm_version="llvmorg-${v/_/-}"
+		fi
+		ver=${v}
+		profdata_v=$(wget -q -O - \
+https://raw.githubusercontent.com/llvm/llvm-project/${llvm_version}/llvm/include/llvm/ProfileData/InstrProfData.inc \
+			| grep "INSTR_PROF_INDEX_VERSION" \
+			| head -n 1 \
+			| grep -E -o -e "[0-9]+")
+	done
+	echo "${profdata_v}:${ver}"
+}
+
+is_profdata_compatible() {
+	local a=$(get_pregenerated_profdata_version)
+	local b=${CURRENT_PROFDATA_VERSION}
+	if (( ${a} == ${b} )) ; then
+		return 0
+	else
+		return 1
+	fi
+}
+
+# Check the system for security weaknesses.
+check_deps_cfi_cross_dso() {
+	if ! use cfi-vcall ; then
+		einfo "Skipping CFI Cross-DSO checks"
+		return
+	fi
+	# These are libs required by the prebuilt bin version.
+	# This list was generated from the _maintainer_notes/get_package_libs script.
+	# TODO:  Update list for source build.
+	local pkg_libs=(
+libasound.so.2
+libatk-1.0.so.0
+libatk-bridge-2.0.so.0
+libatspi.so.0
+libblkid.so.1
+libbsd.so.0
+libbz2.so.1
+libcairo.so.2
+libc.so.6
+libcups.so.2
+libdbus-1.so.3
+libdl.so.2
+libdrm.so.2
+libEGL.so.1
+libexpat.so.1
+libffi.so.7
+libfontconfig.so.1
+libfreetype.so.6
+libfribidi.so.0
+libgbm.so.1
+libgcc_s.so.1
+libgio-2.0.so.0
+libGLdispatch.so.0
+libglib-2.0.so.0
+libGL.so.1
+libGLX.so.0
+libgmodule-2.0.so.0
+libgmp.so.10
+libgnutls.so.30
+libgobject-2.0.so.0
+libgraphite2.so.3
+libharfbuzz.so.0
+libhogweed.so.6
+libidn2.so.0
+libmd.so.0
+libmount.so.1
+libm.so.6
+libnettle.so.8
+libnspr4.so
+libnss3.so
+libnssutil3.so
+libp11-kit.so.0
+libpango-1.0.so.0
+libpcre.so.1
+libpixman-1.so.0
+libplc4.so
+libplds4.so
+libpng16.so.16
+libpthread.so.0
+librt.so.1
+libsmime3.so
+libtasn1.so.6
+libunistring.so.2
+libuuid.so.1
+libwayland-server.so.0
+libX11.so.6
+libXau.so.6
+libxcb-render.so.0
+libxcb-shm.so.0
+libxcb.so.1
+libXcomposite.so.1
+libXdamage.so.1
+libXdmcp.so.6
+libXext.so.6
+libXfixes.so.3
+libxkbcommon.so.0
+libXrandr.so.2
+libXrender.so.1
+libz.so.1
+	)
+
+	# TODO: check dependency n levels deep.
+	# We assume CFI Cross-DSO.
+	einfo
+	einfo "Evaluating system for possible weaknesses."
+	einfo "Assuming systemwide CFI Cross-DSO."
+	einfo
+	for f in ${pkg_libs[@]} ; do
+		local paths=($(realpath {/usr/lib/gcc/*-pc-linux-gnu/{,32/},/lib,/usr/lib}*"/${f}" 2>/dev/null))
+		if (( "${#paths[@]}" == 0 )) ; then
+			ewarn "${f} does not exist."
+			continue
+		fi
+		local path
+		path=$(echo "${paths[@]}" | tr " " "\n" | tail -n 1)
+		local real_path=$(realpath "${path}")
+		#einfo "real_path=${real_path}"
+		if readelf -Ws "${real_path}" 2>/dev/null | grep -E -q -e "(cfi_bad_type|cfi_check_fail|__cfi_init)" ; then
+			einfo "${f} is CFI protected."
+		else
+			ewarn "${f} is NOT CFI protected."
+		fi
+	done
+	einfo
+	einfo "The information presented is a draft report that may not"
+	einfo "represent your configuration.  Some libraries listed"
+	einfo "may not be be able to be CFI Cross-DSOed."
+	einfo
+	einfo "An estimated >= 43% (30/69) of the libraries listed should be"
+	einfo "marked CFI protected."
+	einfo
+}
+
+CURRENT_PROFDATA_VERSION=
+CURRENT_PROFDATA_LLVM_VERSION=
+NABIS=0
 pkg_setup() {
+	einfo "The $(ver_cut 1 ${PV}) series is the stable channel."
 	pre_build_checks
 
 	chromium_suid_sandbox_check_kernel_config
 
 	# nvidia-drivers does not work correctly with Wayland due to unsupported EGLStreams
-	if use wayland && ! use headless && has_version "x11-drivers/nvidia-drivers"; then
+	if use wayland && ! use headless && has_version "x11-drivers/nvidia-drivers" ; then
 		ewarn "Proprietary nVidia driver does not work with Wayland. You can disable"
 		ewarn "Wayland by setting DISABLE_OZONE_PLATFORM=true in /etc/chromium/default."
 	fi
+
+	if ! use amd64 && [[ "${USE}" =~ cfi ]] ; then
+ewarn
+ewarn "All variations of the cfi USE flags are not defaults for this platform."
+ewarn "Disable them if problematic."
+ewarn
+	fi
+
+	if use pgo-full ; then
+ewarn
+ewarn "The pgo-full USE flag is a Work In Progress (WIP) and not production ready."
+ewarn "Please only use the pgo USE flag instead.  This notice will be removed when"
+ewarn "it is ready."
+ewarn
+		if has network-sandbox $FEATURES ; then
+eerror
+eerror "The pgo-full USE flag requires FEATURES=\"-network-sandbox\" to be able to"
+eerror "use vpython and other dependencies in order to generate PGO profiles."
+eerror
+			die
+		fi
+		if use wayland && ! use weston ; then
+ewarn
+ewarn "Weston is required for PGO profile generation but mutually exclusive to"
+ewarn "X windowing system PGO profile generation."
+ewarn
+		fi
+	fi
+
+	if use official || ( use clang && use cfi-vcall && use pgo ) ; then
+		# sys-devel/lld-13 was ~20 mins for v8_context_snapshot_generator
+		# sys-devel/lld-12 was ~4 hrs for v8_context_snapshot_generator
+ewarn
+ewarn "Linking times may take longer than usual.  Maybe 1-12+ hour(s)."
+ewarn
+	fi
+
+	# These checks are a maybe required.
+	if use clang ; then
+		# No LLVM multi version bug here.
+		# Cr will still work if Mesa slot is lower and Cr is built with
+		# a higher version.
+		if use pre-check-llvm ; then
+			unset LLVM_REPORT_CARDS
+			for s in ${LLVM_SLOTS[@]} ; do
+				verify_llvm_toolchain ${s}
+			done
+			LLVM_SLOT=
+			local slots
+			if use official ; then
+				slots=${CR_CLANG_SLOT_OFFICIAL}
+			else
+				slots=$(echo "${LLVM_SLOTS[@]}" | tr " " "\n" | tac | tr "\n" " ")
+			fi
+			for s in ${slots} ; do
+				if [[ ${LLVM_REPORT_CARDS[${s}]} == "pass" ]] ; then
+					export LLVM_SLOT=${s}
+					break
+				fi
+			done
+		else
+			if use official ; then
+				LLVM_SLOT=14
+			else
+				LLVM_SLOT=$(ver_cut 1 $(best_version "sys-devel/clang" | sed -e "s|sys-devel/clang-||g"))
+			fi
+		fi
+		if [[ -z "${LLVM_SLOT}" ]] ; then
+eerror
+eerror "You must choose a LLVM slot to update properly:"
+eerror
+			for s in ${slots} ; do
+eerror
+eerror "The LLVM ${s} toolchain needs the following update(s):"
+echo -e "${LLVM_REPORT_CARDS[${s}]}"
+			done
+eerror
+eerror "OR"
+eerror
+eerror "You can remove the official USE flag.  The official USE flag strictly"
+eerror "requires LLVM ${CR_CLANG_SLOT_OFFICIAL} and for related packages.  To"
+eerror "use a different slotted LLVM, disable the official USE flag."
+eerror
+eerror "You must ensure that the timestamps of the installed packages are the"
+eerror "same or newer than the installed LLVM for that slot for missing symbols"
+eerror "avoidance AND the timestamp or commit is the same or newer than the"
+eerror "timestamp of the one used to build the official build if using the"
+eerror "official USE flag.  Some of these issue may be avoided if the official"
+eerror "USE flag is disabled for more relaxed requirement constraints which"
+eerror "requires the commits/version be the same or newer as the LLVM lib"
+eerror "for missing symbols reasons."
+eerror
+eerror "For live ebuilds (*.9999) you might have to replace -1vuDN with -1vO to"
+eerror "force a rebuild if the following message is encountered:"
+eerror
+eerror "  Nothing to merge; quitting."
+eerror
+# One reason is possibly for crash reporting.
+			die
+		else
+			export PATH=$(echo "${PATH}" | tr ":" "\n" | sed -e "s|.*llvm/.*||" | uniq \
+				| sed -e "/^$/d" | tr "\n" ":" | sed -e "s|:$||")
+			# If building without ccache, include in the search path:
+			# 1.  Path to clang/clang++ (/usr/lib/llvm/${LLVM_SLOT}/bin)
+			# 2.  Path to highest LLD (/usr/lib/llvm/${v_major_lld}/bin)
+			# If ccache is installed, this really does nothing because
+			# /usr/lib/ccache/bin has a higher precedence.
+			export PATH+=":/usr/lib/llvm/${LLVM_SLOT}/bin"
+			einfo "Using sys-devel/llvm:${LLVM_SLOT}"
+			local lld_v_maj=$(ver_cut 1 $(best_version "sys-devel/lld" | sed -e "s|sys-devel/lld-||"))
+			v_major_lld=$(ver_cut 1 "${v_major_lld}")
+			export PATH+=":/usr/lib/llvm/${v_major_lld}/bin"
+		fi
+		if use pgo ; then
+			local vi=$(get_llvm_profdata_version_info)
+			CURRENT_PROFDATA_VERSION=$(echo "${vi}" | cut -f 1 -d ":")
+			CURRENT_PROFDATA_LLVM_VERSION=$(echo "${vi}" | cut -f 2 -d ":")
+		fi
+	fi
+	if [[ -n "${CHROMIUM_EBUILD_MAINTAINER}" ]] ; then
+		if [[ -z "${MY_OVERLAY_DIR}" ]] ; then
+eerror
+eerror "You need to set MY_OVERLAY_DIR as a per-package envvar to the base path"
+eerror "of your overlay or local repo.  The base path should contain all the"
+eerror "overlay's categories."
+eerror
+			die
+		fi
+	fi
+
+	if use vaapi && ( use x86 || use amd64 ) ; then
+		:;
+	elif use vaapi ; then
+ewarn
+ewarn "VA-API is not enabled by default for this arch.  Please disable it if"
+ewarn "problems are encountered."
+ewarn
+	fi
+
+	if use vaapi ; then
+		find_vaapi
+	fi
+
+	if use cr_pgo_trainers_media_desktop \
+		|| use cr_pgo_trainers_media_mobile ; then
+		find_video0
+	fi
+
+	if use system-libstdcxx ; then
+ewarn
+ewarn "The system's libstdcxx may weaken the security.  Consider"
+ewarn "using only the bundled-libcxx instead."
+ewarn
+	fi
+
+	for a in $(multilib_get_enabled_abis) ; do
+		NABIS=$((${NABIS} + 1))
+	done
+
+	check_deps_cfi_cross_dso
+}
+
+USED_EAPPLY=0
+ceapply() {
+	USED_EAPPLY=1
+	eapply "${@}"
+}
+
+CIPD_CACHE_DIR="${PORTAGE_ACTUAL_DISTDIR:-${DISTDIR}}/${PN}/cipd-cache"
+init_vpython() {
+	export CIPD_CACHE_DIR
+	export PATH="${S}/third_party/depot_tools:${PATH}"
+	# See https://github.com/chromium/chromium/blob/92.0.4577.42/DEPS#L4489
+	addwrite "${PORTAGE_ACTUAL_DISTDIR:-${DISTDIR}}"
+	mkdir -p "${CIPD_CACHE_DIR}" || die
+	addwrite "${CIPD_CACHE_DIR}"
+	einfo "Downloading VirtualEnvs ( ~287 MiB, ~1 hr wait )"
+	einfo "If build problems, remove the ${CIPD_CACHE_DIR} folder and try again."
+#		tools/perf/fetch_benchmark_deps.py
+	local scripts_to_run=(
+		out/Release/bin/run_performance_test_suite
+	)
+	cd "${S}" || die
+	for s in ${scripts_to_run[@]} ; do
+		einfo "Downloading a VirtualEnv for $(basename ${s})"
+		"${s}" -cache-dir "${CIPD_CACHE_DIR}" --help || die
+	done
+}
+
+fetching_pgo_deps() {
+	einfo "Downloading all benchmark deps used by PGO trainers"
+	cd "${S}" || die
+	vpython -cache-dir "${CIPD_CACHE_DIR}" tools/perf/fetch_benchmark_deps.py || die
+}
+
+src_unpack() {
+	for a in ${A} ; do
+		[[ "${a}" == "${PN}-${MTD_V}-media-test-data.tar.gz" ]] && continue
+		[[ "${a}" == "${PN}-${CTDM_V}-chrome-test-data-media.tar.gz" ]] && continue
+		unpack ${a}
+	done
+	if use pgo-full ; then
+		cp -a $(realpath "${DISTDIR}/.cipd_client-${ABI}-${CIPD_V}") \
+			"${S}/third_party/depot_tools/.cipd_client" || die
+		chmod +x "${S}/third_party/depot_tools/.cipd_client" || die
+		pushd "${S}/media/test/data" || die
+			unpack ${PN}-${MTD_V}-media-test-data.tar.gz
+		popd
+		pushd "${S}/chrome/test/data/media" || die
+			unpack ${PN}-${CTDM_V}-chrome-test-data-media.tar.gz
+		popd
+	fi
+}
+
+# Full list of hw accelerated image processing
+# ffmpeg -filters | grep vaapi
+_is_hw_scaling_supported() {
+	local encoding_format="${1}"
+	if use vaapi && ffmpeg -filters 2>/dev/null \
+		| grep -q -F -e "scale_vaapi" \
+		&& vainfo 2>/dev/null \
+		| grep -q -F -e "VAEntrypointVideoProc" \
+		&& vainfo 2>/dev/null \
+                | grep -q -G -e "${encoding_format}.*VAEntrypointEncSlice" \
+                && ffmpeg -hide_banner -encoders 2>/dev/null \
+                        | grep -q -F -e "${encoding_format,,}_vaapi" ; then
+		return 0
+	else
+		return 1
+	fi
+}
+
+_gen_vaapi_filter() {
+	local encoding_format="${1}"
+	if use vaapi \
+		&& vainfo 2>/dev/null \
+		| grep -q -G -e "${encoding_format}.*VAEntrypointEncSlice" \
+		&& ffmpeg -hide_banner -encoders 2>/dev/null \
+			| grep -q -F -e "${encoding_format,,}_vaapi" ; then
+		echo "format=nv12,hwupload"
+	else
+		echo ""
+	fi
+}
+
+_is_vaapi_allowed() {
+	local encoding_format="${1}"
+	if use vaapi && vainfo 2>/dev/null \
+		| grep -q -G -e "${encoding_format}.*VAEntrypointEncSlice" \
+		&& ffmpeg -hide_banner -encoders 2>/dev/null \
+			| grep -q -F -e "${encoding_format,,}_vaapi" ; then
+		return 0
+	fi
+	return 1
+}
+
+DRM_RENDER_NODE=
+find_vaapi() {
+	use pre-check-vaapi || return
+	if use vaapi && [[ -n "${CR_DRM_RENDER_NODE}" ]] ; then
+		einfo "User VA-API override"
+		# Per-package envvar overridable
+		DRM_RENDER_NODE=${CR_DRM_RENDER_NODE}
+	elif use vaapi ; then
+		einfo "Autodetecting VA-API device"
+		unset LIBVA_DRIVERS_PATH
+		unset LIBVA_DRIVER_NAME
+		unset DRM_RENDER_NODE
+		for d in $(find /dev/dri -name "render*") ; do
+			# Permute
+			for v in $(seq 0 2) ; do # 2 GPU and 1 APU scenario
+				export DRI_PRIME=${v} # \
+				# See xrandr --listproviders for mapping, could be 1=dGPU, 0=APU/IGP
+				if vainfo 2>/dev/null 1>/dev/null ; then
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="iHD" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="iHD"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="i965" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="i965"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="radeonsi" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="radeonsi"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="r600" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="r600"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="r300" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="r300"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/opt/amdgpu/lib64/dri" \
+					LIBVA_DRIVER_NAME="radeonsi" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/opt/amdgpu/lib64/dri"
+					export LIBVA_DRIVER_NAME="radeonsi"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/opt/amdgpu/lib64/dri" \
+					LIBVA_DRIVER_NAME="r600" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/opt/amdgpu/lib64/dri"
+					export LIBVA_DRIVER_NAME="r600"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/opt/amdgpu/lib64/dri" \
+					LIBVA_DRIVER_NAME="r300" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/opt/amdgpu/lib64/dri"
+					export LIBVA_DRIVER_NAME="r300"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/opt/amdgpu/lib/x86_64-linux-gnu/dri" \
+					LIBVA_DRIVER_NAME="radeonsi" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/opt/amdgpu/lib/x86_64-linux-gnu/dri"
+					export LIBVA_DRIVER_NAME="radeonsi"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/opt/amdgpu/lib/x86_64-linux-gnu/dri" \
+					LIBVA_DRIVER_NAME="r600" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/opt/amdgpu/lib/x86_64-linux-gnu/dri"
+					export LIBVA_DRIVER_NAME="r600"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/opt/amdgpu/lib/x86_64-linux-gnu/dri" \
+					LIBVA_DRIVER_NAME="r300" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/opt/amdgpu/lib/x86_64-linux-gnu/dri"
+					export LIBVA_DRIVER_NAME="r300"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib64/dri/" \
+					LIBVA_DRIVER_NAME="nvidia" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib64/dri/"
+					export LIBVA_DRIVER_NAME="nvidia"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="nvidia" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="nvidia"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="vdpau" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="vdpau"
+					export DRM_RENDER_NODE="${d}"
+				elif LIBVA_DRIVERS_PATH="/usr/lib/dri" \
+					LIBVA_DRIVER_NAME="nouveau" \
+					vainfo 2>/dev/null 1>/dev/null ; then
+					export LIBVA_DRIVERS_PATH="/usr/lib/dri"
+					export LIBVA_DRIVER_NAME="nouveau"
+					export DRM_RENDER_NODE="${d}"
+				fi
+			done
+		done
+	fi
+	vaapi_autodetect_failed_msg() {
+eerror
+eerror "VA-API autodetect failed.  Manual setup required."
+eerror
+eerror "Set the CR_DRM_RENDER_NODE per-package envvar to the abspath DRM render"
+eerror "node.  See \`ls /dev/dri\` for a list of possibilities."
+eerror "LIBVA_DRIVERS_PATH, LIBVA_DRIVER_NAME, DRI_PRIME may also need to be"
+eerror "set."
+eerror
+eerror "You may also disable the vaapi USE flag if there is difficulty"
+eerror "installing or configuring the driver."
+eerror
+	}
+	if use vaapi && [[ -n "${CR_DRM_RENDER_NODE}" ]] \
+		&& ! vainfo --display drm --device "${DRM_RENDER_NODE}" ; then
+		eerror "VA-API test failure"
+		vaapi_autodetect_failed_msg
+		die
+	elif use vaapi && [[ -z "${DRM_RENDER_NODE}" ]] ; then
+		vaapi_autodetect_failed_msg
+		die
+	elif use vaapi ; then
+		einfo "Using VA-API device with DRM render node ${DRM_RENDER_NODE}"
+		[[ -n "${LIBVA_DRIVER_NAME}" ]] \
+			&& einfo " LIBVA_DRIVER_NAME=${LIBVA_DRIVER_NAME}"
+		[[ -n "${LIBVA_DRIVERS_PATH}" ]] \
+			&& einfo " LIBVA_DRIVERS_PATH=${LIBVA_DRIVERS_PATH}"
+	fi
+}
+
+is_generating_credits() {
+	if [[ -n "${GEN_ABOUT_CREDITS}" && "${GEN_ABOUT_CREDITS}" == "1" ]] ; then
+		return 0
+	else
+		return 1
+	fi
+}
+
+gen_full_pgo_assets() {
+	#
+	# The function is used primarily for cr_pgo_trainers_memory_desktop PGO
+	# trainer USE flag.
+	#
+	if use pgo-full ; then
+		export ASSET_CACHE_REVISION=6 # Bump on every change of output.
+		ASSET_CACHE="${PORTAGE_ACTUAL_DISTDIR:-${DISTDIR}}/${PN}/asset-cache"
+		addwrite "${ASSET_CACHE}"
+
+		restart_asset_cache() {
+			einfo "Restarting the asset cache"
+			rm -rf "${ASSET_CACHE}"
+			mkdir -p "${ASSET_CACHE}" || die
+			echo "REVISION=${ASSET_CACHE_REVISION}" \
+				> "${ASSET_CACHE}/.cache-control" || die
+		}
+		if [[ ! -f "${ASSET_CACHE}/.cache-control" ]] ; then
+			restart_asset_cache
+		else
+			local x_asset_cache_revision=$(grep -r \
+				-e "REVISION=" "${ASSET_CACHE}/.cache-control" \
+				| cut -f 2 -d "=")
+			einfo "x_asset_cache_revision=${x_asset_cache_revision}"
+			einfo "ASSET_CACHE_REVISION=${ASSET_CACHE_REVISION}"
+			if (( ${x_asset_cache_revision} < ${ASSET_CACHE_REVISION} )) ; then
+				restart_asset_cache
+			else
+				einfo "Reusing the asset-cache"
+			fi
+		fi
+
+		mkdir -p "${ASSET_CACHE}" || die
+		local drm_render_node=()
+		local init_ffmpeg_filter=()
+		if use vaapi ; then
+			if [[ -e ${DRM_RENDER_NODE} ]] ; then
+				export MESA_GLSL_CACHE_DIR="${HOME}/mesa_shader_cache" # \
+				  # Prevent a sandbox violation and isolate between parallel running emerges.
+				drm_render_node=( -init_hw_device vaapi=drm_render_node:${DRM_RENDER_NODE} )
+			else
+				die "Missing VA-API device"
+			fi
+			if use vaapi && ffmpeg -filters 2>/dev/null \
+				| grep -q -F -e "scale_vaapi" ; then
+				init_ffmpeg_filter=( -filter_hw_device drm_render_node )
+			fi
+		fi
+		if use cr_pgo_trainers_memory_desktop ; then
+			einfo "Generating missing assets for the memory.desktop"
+
+			local vp8_decoding=()
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP8.*VAEntrypointVLD" \
+				&& [[ -e /dev/dri/renderD128 ]] ; then
+				vp8_decoding=( -hwaccel vaapi
+					-hwaccel_output_format vaapi
+					-hwaccel_device drm_render_node
+					-filter_hw_device drm_render_node )
+			fi
+
+			if use proprietary-codecs ; then
+				local aac_encoding=( -codec:a aac )
+				local h264_encoding=()
+
+				h264_baseline_profile=()
+				if use vaapi && vainfo 2>/dev/null \
+					| grep -q -G -e "H264.*VAEntrypointEncSlice" \
+					&& ffmpeg -hide_banner -encoders 2>/dev/null \
+						| grep -q -F -e "h264_vaapi" ; then
+					h264_encoding=( -c:v h264_vaapi )
+					h264_baseline_profile=( -profile:v 578 )
+					# For quality see, ffmpeg -h full
+				elif has_version "media-video/ffmpeg[openh264]" ;then
+					h264_encoding=( -c:v libopenh264 )
+					h264_baseline_profile=( -profile:v 578 )
+				fi
+
+				# bigbuck.webm -> buck-480p.mp4
+				einfo "Generating buck-480p.mp4 for the memory.desktop benchmark"
+				# The bunny.gif doesn't actually exist on the website but is converted from the
+				# movie explained in https://codereview.chromium.org/2243403006
+				filter_sw=()
+				filter_hw+=( $(_gen_vaapi_filter "H264") )
+				if _is_hw_scaling_supported "H264" ; then
+					filter_hw+=( "scale_vaapi=w=852:h=-1" )
+				else
+					filter_sw+=( "scale=w=852:h=-1" )
+					filter_sw+=( "crop=852:480:0:0" )
+				fi
+				cmd=( ffmpeg \
+					${drm_render_node[@]} \
+					${vp8_decoding[@]} \
+					-i "${S}/chrome/test/data/media/bigbuck.webm" \
+					${h264_encoding[@]} \
+					$(_is_vaapi_allowed "H264" && echo "${init_ffmpeg_filter[@]}") \
+					-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+						&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+						&& echo " ${filter_hw[@]}") | tr " " ",") \
+					${aac_encoding[@]} \
+					"${S}/tools/perf/page_sets/trivial_sites/buck-480p.mp4" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+				sed -i -e "s|road_trip_640_480.mp4|buck-480p.mp4|g" \
+					"${S}/tools/perf/page_sets/trivial_sites/trivial_fullscreen_video.html" \
+					|| die
+			fi
+
+			# bigbuck.webm -> bunny.gif
+			einfo "Generating bunny.gif (animated gif) for the memory.desktop benchmark"
+			# The bunny.gif doesn't actually exist on the website but is converted from the
+			# movie explained in https://codereview.chromium.org/2243403006
+			filter_sw=( "scale=w=852:h=-1" )
+			filter_sw+=( "crop=852:480:0:0" )
+			cmd=( ffmpeg \
+				${drm_render_node[@]} \
+				${vp8_decoding[@]} \
+				-i "${S}/chrome/test/data/media/bigbuck.webm" \
+				$(_is_vaapi_allowed "GIF" && echo "${init_ffmpeg_filter[@]}") \
+				-vf $(echo "${filter_sw[@]}" | tr " " ",") \
+				-t 60.0 \
+				-f gif \
+				"${S}/tools/perf/page_sets/trivial_sites/bunny.gif" )
+			einfo "${cmd[@]}"
+			"${cmd[@]}" || die "${cmd[@]}"
+			# For animated gif alternatives:
+			#sed -i -e "s|bunny.gif|bunny.gif|g" \
+			#	"${S}/tools/perf/page_sets/trivial_sites/trivial_gif.html"
+		fi
+
+		# See also https://chromium.googlesource.com/chromium/src.git/+/refs/tags/100.0.4896.75/media/test/data/#media-test-data
+		# https://chromium.googlesource.com/chromium/src.git/+/refs/tags/100.0.4896.75/tools/perf/page_sets/media_cases.py
+		if use cr_pgo_trainers_media_desktop \
+			|| use cr_pgo_trainers_media_mobile ; then
+			einfo "Generating missing assets for the media.desktop or media.mobile benchmarks"
+			local opus_encoding=( -c:a libopus )
+			local vorbis_encoding=( -c:a libvorbis )
+			local vp8_decoding=()
+			local vp8_encoding=()
+			local vp9_decoding=()
+			local vp9_encoding=()
+
+			# vp8, vorbis : bigbuck.webm, tulip2.webm
+			# vp9, opus : ${CR_PGO_VIDEO0}
+
+			# tulip2.webm is 1280x720 res, 2104 kb/s bitrate, 29.97 fps.  Audio bitrate is unknown.
+			# ${CR_PGO_VIDEO0} is 3840x2160 res, 24124k bitrate, 59.94 fps.  Audio bitrate is unknown.
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP8.*VAEntrypointVLD" \
+				&& [[ -e /dev/dri/renderD128 ]] ; then
+				vp8_decoding=( -hwaccel vaapi
+					-hwaccel_output_format vaapi
+					-hwaccel_device drm_render_node
+					-filter_hw_device drm_render_node )
+			fi
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP9.*VAEntrypointVLD" \
+				&& [[ -e /dev/dri/renderD128 ]] ; then
+				vp9_decoding=( -hwaccel vaapi
+					-hwaccel_output_format vaapi
+					-hwaccel_device drm_render_node
+					-filter_hw_device drm_render_node )
+			fi
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP8.*VAEntrypointEncSlice" \
+				&& ffmpeg -hide_banner -encoders 2>/dev/null \
+					| grep -q -F -e "vp8_vaapi" ; then
+				vp8_encoding=( -c:v vp8_vaapi )
+			else
+				vp8_encoding=( -c:v libvpx )
+			fi
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP9.*VAEntrypointEncSlice" \
+				&& ffmpeg -hide_banner -encoders 2>/dev/null \
+					| grep -q -F -e "vp9_vaapi" ; then
+				vp9_encoding=( -c:v vp9_vaapi )
+			else
+				vp9_encoding=( -c:v libvpx-vp9 )
+			fi
+
+			if use proprietary-codecs ; then
+				local aac_encoding=( -codec:a aac )
+				local h264_encoding=()
+				local mp3_encoding=( -c:a libmp3lame )
+
+				h264_baseline_profile=()
+				h264_high_profile_4_0=()
+				if use vaapi && vainfo 2>/dev/null \
+					| grep -q -G -e "H264.*VAEntrypointEncSlice" \
+					&& ffmpeg -hide_banner -encoders 2>/dev/null \
+						| grep -q -F -e "h264_vaapi" ; then
+					h264_encoding=( -c:v h264_vaapi )
+					h264_baseline_profile=( -profile:v 578 )
+					h264_high_profile_4_0=( -profile:v 100 -level:v 40 )
+				elif has_version "media-video/ffmpeg[openh264]" ;then
+					h264_encoding=( -c:v libopenh264 )
+					h264_baseline_profile=( -profile:v 578 )
+					h264_high_profile_4_0=( -profile:v 100 ) # no level
+				fi
+
+				# tulip2.webm -> tulip2.m4a
+				cmd=( ffmpeg -i "${S}/media/test/data/tulip2.webm" \
+					-vn \
+					${aac_encoding[@]} \
+					"${S}/tools/perf/page_sets/media_cases/tulip2.m4a" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+
+				# tulip2.webm -> tulip2.mp3
+				cmd=( ffmpeg -i "${S}/media/test/data/tulip2.webm" \
+					-vn \
+					${mp3_encoding[@]} \
+					"${S}/tools/perf/page_sets/media_cases/tulip2.mp3" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+
+				# tulip2.webm -> tulip2.mp4
+				h264_filter_args=( -vf "format=nv12,hwupload" )
+				cmd=( ffmpeg \
+					${drm_render_node[@]} \
+					${vp8_decoding[@]} \
+					-i "${S}/media/test/data/tulip2.webm" \
+					${h264_encoding[@]} \
+					$(_is_vaapi_allowed "H264" && echo "${init_ffmpeg_filter[@]}") \
+					$(_is_vaapi_allowed "H264" && echo "${h264_filter_args[@]}") \
+					${h264_baseline_profile[@]} \
+					${aac_encoding[@]} \
+					"${S}/tools/perf/page_sets/media_cases/tulip2.mp4" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+
+				# tulip2.webm -> aac_audio.mp4
+				# Asset must be AAC-LC.
+				aac_lc=( -profile:a aac_low )
+				cmd=( ffmpeg -i "${S}/media/test/data/tulip2.webm" \
+					-vn \
+					${aac_encoding[@]} \
+					${aac_lc[@]} \
+					"${S}/tools/perf/page_sets/media_cases/aac_audio.mp4" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+
+				# tulip2.webm -> h264_video.mp4
+				# Asset must be h264, level 4, high profile
+				# See tools/perf/page_sets/media_cases/mse.js
+				h264_filter_args=( -vf "format=nv12,hwupload" )
+				cmd=( ffmpeg \
+					${drm_render_node[@]} \
+					-i "${S}/media/test/data/tulip2.webm" \
+					${h264_encoding[@]} \
+					${h264_high_profile_4_0[@]} \
+					$(_is_vaapi_allowed "H264" && echo "${init_ffmpeg_filter[@]}") \
+					$(_is_vaapi_allowed "H264" && echo "${h264_filter_args[@]}") \
+					-an \
+					"${S}/tools/perf/page_sets/media_cases/h264_video.mp4" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+
+				# ${CR_PGO_VIDEO0} -> video0_720p30fps.mp4
+				# 1280 x 720 res ; must be 2 min
+				if [[ -f "${ASSET_CACHE}/video0_720p30fps.mp4" \
+					&& -f "${ASSET_CACHE}/video0_720p30fps.mp4.sha512" \
+					&& $(cat "${ASSET_CACHE}/video0_720p30fps.mp4.sha512") \
+						== $(sha512sum "${ASSET_CACHE}/video0_720p30fps.mp4" \
+							| cut -f 1 -d " ") ]] ; then
+					einfo "Using pregenerated and cached video0_720p30fps.mp4"
+					cp -a "${ASSET_CACHE}/video0_720p30fps.mp4" \
+						"${S}/tools/perf/page_sets/media_cases/video0_720p30fps.mp4" \
+						|| die
+				else
+					filter_sw=()
+					filter_hw=( $(_gen_vaapi_filter "H264") )
+					if _is_hw_scaling_supported "H264" ; then
+						filter_hw+=( "scale_vaapi=w=-1:h=720" )
+					else
+						filter_sw+=( "scale=w=-1:h=720" )
+					fi
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp9_decoding[@]} \
+						-i $(realpath "${CR_PGO_VIDEO0}") \
+						${h264_encoding[@]} \
+						$(_is_vaapi_allowed "H264" && echo "${init_ffmpeg_filter[@]}") \
+						-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+							&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+							&& echo " ${filter_hw[@]}") | tr " " ",") \
+						-maxrate 1485k -minrate 512k -b:v 1024k \
+						-r 30 \
+						${aac_encoding[@]} \
+						-t 120.0 \
+						"${S}/tools/perf/page_sets/media_cases/video0_720p30fps.mp4" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+					einfo "Saving work to ${ASSET_CACHE}/video0_720p30fps.mp4 for faster rebuilds."
+					cp -a "${S}/tools/perf/page_sets/media_cases/video0_720p30fps.mp4" \
+						"${ASSET_CACHE}/video0_720p30fps.mp4" || die
+					sha512sum "${ASSET_CACHE}/video0_720p30fps.mp4" \
+						| cut -f 1 -d " " > "${ASSET_CACHE}/video0_720p30fps.mp4.sha512" || die
+				fi
+				sed -i -e "s|foodmarket_720p30fps.mp4|video0_720p30fps.mp4|g" \
+					"${S}/tools/perf/page_sets/media_cases.py" || die
+			fi
+
+			# tulip2.webm -> tulip2.ogg
+			cmd=( ffmpeg -i "${S}/media/test/data/tulip2.webm" \
+				-vn \
+				${vorbis_encoding[@]} \
+				"${S}/tools/perf/page_sets/media_cases/tulip2.ogg" )
+			einfo "${cmd[@]}"
+			"${cmd[@]}" || die "${cmd[@]}"
+
+			# tulip2.webm -> tulip2.vp9.webm
+			# Must be <= wifi bitrate.  U = 2.8Mbps upload, so A kbps for audio and V = ( U - A ) video max.
+			# For no audio, then V = U for max bitrate.
+			if [[ -f "${ASSET_CACHE}/tulip2.vp9.webm" \
+				&& -f "${ASSET_CACHE}/tulip2.vp9.webm.sha512" \
+				&& $(cat "${ASSET_CACHE}/tulip2.vp9.webm.sha512") \
+					== $(sha512sum "${ASSET_CACHE}/tulip2.vp9.webm" \
+						| cut -f 1 -d " ") ]] ; then
+				einfo "Using pregenerated and cached tulip2.vp9.webm"
+				cp -a "${ASSET_CACHE}/tulip2.vp9.webm" \
+					"${S}/tools/perf/page_sets/media_cases/tulip2.vp9.webm" \
+					|| die
+			else
+				if _is_vaapi_allowed "VP9" ; then
+					# Likely only single pass supported
+					# Quality is auto but based on other args.
+					# https://trac.ffmpeg.org/wiki/Hardware/VAAPI mentions how vp9 quality is handled indirectly.
+					vp9_filter_args=( -vf "format=nv12,hwupload" )
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp8_decoding[@]} \
+						-i "${S}/media/test/data/tulip2.webm" \
+						${vp9_encoding[@]} \
+						$(_is_vaapi_allowed "VP9" && echo "${init_ffmpeg_filter[@]}") \
+						$(_is_vaapi_allowed "VP9" && echo "${vp9_filter_args[@]}") \
+						-maxrate 1485k -minrate 512k -b:v 1024k \
+						${opus_encoding[@]} \
+						"${S}/tools/perf/page_sets/media_cases/tulip2.vp9.webm" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+				else
+					# See https://developers.google.com/media/vp9/settings/vod
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp8_decoding[@]} \
+						-i "${S}/media/test/data/tulip2.webm" \
+						${vp9_encoding[@]} \
+						-maxrate 1485k -minrate 512k -b:v 1024k -crf 31 \
+						${opus_encoding[@]} \
+						"${S}/tools/perf/page_sets/media_cases/tulip2.vp9.webm" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+				fi
+				einfo "Saving work to ${ASSET_CACHE}/tulip2.vp9.webm for faster rebuilds."
+				cp -a "${S}/tools/perf/page_sets/media_cases/tulip2.vp9.webm" \
+					"${ASSET_CACHE}/tulip2.vp9.webm" || die
+				sha512sum "${ASSET_CACHE}/tulip2.vp9.webm" \
+					| cut -f 1 -d " " > "${ASSET_CACHE}/tulip2.vp9.webm.sha512" || die
+			fi
+
+			# ${CR_PGO_VIDEO0} -> video0_1080p60fps_vp9.webm
+			# 1920 x 1080 res ; must be 2 min
+			if [[ -f "${ASSET_CACHE}/video0_1080p60fps_vp9.webm" \
+				&& -f "${ASSET_CACHE}/video0_1080p60fps_vp9.webm.sha512" \
+				&& $(cat "${ASSET_CACHE}/video0_1080p60fps_vp9.webm.sha512") \
+					== $(sha512sum "${ASSET_CACHE}/video0_1080p60fps_vp9.webm" \
+						| cut -f 1 -d " ") ]] ; then
+				einfo "Using pregenerated and cached video0_1080p60fps_vp9.webm"
+				cp -a "${ASSET_CACHE}/video0_1080p60fps_vp9.webm" \
+					"${S}/tools/perf/page_sets/media_cases/video0_1080p60fps_vp9.webm" \
+					|| die
+			else
+				if _is_vaapi_allowed "VP9" ; then
+					# Likely only single pass supported
+					filter_sw=()
+					filter_hw=( $(_gen_vaapi_filter "VP9") )
+					if _is_hw_scaling_supported "VP9" ; then
+						filter_hw+=( "scale_vaapi=w=-1:h=1080" )
+					else
+						filter_sw+=( "scale=w=-1:h=1080" )
+					fi
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp9_decoding[@]} \
+						-i $(realpath "${CR_PGO_VIDEO0}") \
+						${vp9_encoding[@]} \
+						$(_is_vaapi_allowed "VP9" && echo "${init_ffmpeg_filter[@]}") \
+						-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+							&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+							&& echo " ${filter_hw[@]}") | tr " " ",") \
+						-maxrate 4350k -minrate 1500k -b:v 3000k \
+						-r 60 \
+						-t 120.0 \
+						${opus_encoding[@]} \
+						"${S}/tools/perf/page_sets/media_cases/video0_1080p60fps_vp9.webm" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+				else
+					# See https://developers.google.com/media/vp9/settings/vod
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp9_decoding[@]} \
+						-i $(realpath "${CR_PGO_VIDEO0}") \
+						${vp9_encoding[@]} \
+						-vf scale=w=-1:h=1080 \
+						-maxrate 4350k -minrate 1500k -b:v 3000k -crf 31 \
+						-r 60 \
+						-t 120.0 \
+						${opus_encoding[@]} \
+						"${S}/tools/perf/page_sets/media_cases/video0_1080p60fps_vp9.webm" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+				fi
+				einfo "Saving work to ${ASSET_CACHE}/video0_1080p60fps_vp9.webm for faster rebuilds."
+				cp -a "${S}/tools/perf/page_sets/media_cases/video0_1080p60fps_vp9.webm" \
+					"${ASSET_CACHE}/video0_1080p60fps_vp9.webm" || die
+				sha512sum "${ASSET_CACHE}/video0_1080p60fps_vp9.webm" \
+					| cut -f 1 -d " " > "${ASSET_CACHE}/video0_1080p60fps_vp9.webm.sha512" || die
+			fi
+			sed -i -e "s|boat_1080p60fps_vp9.webm|animal_1080p60fps_vp9.webm|g" \
+				"${S}/tools/perf/page_sets/media_cases.py" || die
+		fi
+
+		if use cr_pgo_trainers_media_desktop ; then
+			einfo "Generating missing assets for the media.desktop benchmark"
+			local av1_encoding=()
+			local vp8_decoding=()
+			local vp8_encoding=()
+			local vp9_decoding=()
+			local vp9_encoding=()
+			local vorbis_encoding=( -c:a libvorbis )
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP8.*VAEntrypointVLD" \
+				&& [[ -e /dev/dri/renderD128 ]] ; then
+				vp8_decoding=( -hwaccel vaapi
+					-hwaccel_output_format vaapi
+					-hwaccel_device drm_render_node
+					-filter_hw_device drm_render_node )
+			fi
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP9.*VAEntrypointVLD" \
+				&& [[ -e /dev/dri/renderD128 ]] ; then
+				vp9_decoding=( -hwaccel vaapi
+					-hwaccel_output_format vaapi
+					-hwaccel_device drm_render_node
+					-filter_hw_device drm_render_node )
+			fi
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "AV1.*VAEntrypointEncSlice" \
+				&& ffmpeg -hide_banner -encoders 2>/dev/null \
+					| grep -q -F -e "av1_vaapi" ; then
+				av1_encoding=( -c:v av1_vaapi )
+			elif has_version "media-video/ffmpeg[libaom]" ; then
+				ncpus=$(lscpu \
+					| grep -E -e "^CPU\(s\):.*" \
+					| grep -E -o -e "[0-9]+")
+				nthreads_per_core=$(lscpu \
+					| grep -E -e "^Thread\(s\) per core:.*" \
+					| grep -E -o -e "[0-9]+")
+				# The defaults are slow.  Test?
+				local tot_tpc=$(( ${ncpus} * ${nthreads_per_core} ))
+				if (( ${ncpus} == 1 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 0
+						-tile-rows 0 -threads 1 )
+				elif (( ${ncpus} == 2 && ${nthreads_per_core} > 1 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 0
+						-tile-rows 1 -threads ${tpc}
+						-row-mt 1 )
+				elif (( ${ncpus} == 2 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 0
+						-tile-rows 1 -threads ${ncpus} )
+				elif (( ${ncpus} == 3 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 0
+						-tile-rows 1 -threads ${ncpus}
+						-row-mt 1 )
+				elif (( ${ncpus} == 4 && ${nthreads_per_core} > 1 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 1
+						-tile-rows 1 -threads ${tot_tpc}
+						-row-mt 1 )
+				elif (( ${ncpus} == 4 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 1
+						-tile-rows 1 -threads ${ncpus} )
+				elif (( ${ncpus} == 6 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 1
+						-tile-rows 1 -threads ${ncpus}
+						-row-mt 1 )
+				elif (( ${ncpus} == 8 && ${nthreads_per_core} > 1 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 1
+						-tile-rows 2 -threads ${tot_tpc}
+						-row-mt 1 )
+				elif (( ${ncpus} == 8 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 1
+						-tile-rows 2 -threads ${ncpus} )
+				elif (( ${ncpus} == 16 && ${nthreads_per_core} > 1 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 2
+						-tile-rows 2 -threads ${tot_tpc}
+						-row-mt 1 )
+				elif (( ${ncpus} == 16 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 2
+						-tile-rows 2 -threads ${ncpus} )
+				elif (( ${nthreads_per_core} > 1 )) ; then
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 2
+						-tile-rows 2 -threads ${tot_tpc}
+						-row-mt 1 )
+				else
+					av1_encoding=( -c:v libaom-av1
+						-cpu-used 8 -tile-columns 2
+						-tile-rows 2 -threads ${ncpus}
+						-row-mt 1 )
+				fi
+			fi
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP8.*VAEntrypointEncSlice" \
+				&& ffmpeg -hide_banner -encoders 2>/dev/null \
+					| grep -q -F -e "vp8_vaapi" ; then
+				vp8_encoding=( -c:v vp8_vaapi )
+			else
+				vp8_encoding=( -c:v libvpx )
+			fi
+
+			if use vaapi && vainfo 2>/dev/null \
+				| grep -q -G -e "VP9.*VAEntrypointEncSlice" \
+				&& ffmpeg -hide_banner -encoders 2>/dev/null \
+					| grep -q -F -e "vp9_vaapi" ; then
+				vp9_encoding=( -c:v vp9_vaapi )
+			else
+				vp9_encoding=( -c:v libvpx-vp9 )
+			fi
+
+			if use proprietary-codecs ; then
+				local aac_encoding=( -codec:a aac )
+				local h264_encoding=()
+
+				h264_baseline_profile=()
+				if use vaapi && vainfo 2>/dev/null \
+					| grep -q -G -e "H264.*VAEntrypointEncSlice" \
+					&& ffmpeg -hide_banner -encoders 2>/dev/null \
+						| grep -q -F -e "h264_vaapi" ; then
+					h264_encoding=( -c:v h264_vaapi )
+					h264_baseline_profile=( -profile:v 578 )
+				elif has_version "media-video/ffmpeg[openh264]" ;then
+					h264_encoding=( -c:v libopenh264 )
+					h264_baseline_profile=( -profile:v 578 )
+				fi
+
+				# tulip2.webm -> crowd1080.mp4
+				if [[ -f "${ASSET_CACHE}/crowd1080.mp4" \
+					&& -f "${ASSET_CACHE}/crowd1080.mp4.sha512" \
+					&& $(cat "${ASSET_CACHE}/crowd1080.mp4.sha512") \
+						== $(sha512sum "${ASSET_CACHE}/crowd1080.mp4" \
+							| cut -f 1 -d " ") ]] ; then
+					einfo "Using pregenerated and cached crowd1080.mp4"
+					cp -a "${ASSET_CACHE}/crowd1080.mp4" \
+						"${S}/tools/perf/page_sets/media_cases/crowd1080.mp4" \
+						|| die
+				else
+					filter_sw=( "minterpolate=vsbmc=1" )
+					filter_hw=( $(_gen_vaapi_filter "H264") )
+					if _is_hw_scaling_supported "H264" ; then
+						filter_hw+=( "scale_vaapi=w=-1:h=1080" )
+					else
+						filter_sw+=( "scale=w=-1:h=1080" )
+					fi
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp8_decoding[@]} \
+						-i "${S}/media/test/data/tulip2.webm" \
+						${h264_encoding[@]} \
+						$(_is_vaapi_allowed "H264" && echo "${init_ffmpeg_filter[@]}") \
+						-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+							&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+							&& echo " ${filter_hw[@]}") | tr " " ",") \
+						-maxrate 4350k -minrate 1500k -b:v 3000k \
+						${aac_encoding[@]} \
+						-r 50 \
+						"${S}/tools/perf/page_sets/media_cases/crowd1080.mp4" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+					einfo "Saving work to ${ASSET_CACHE}/crowd1080.mp4 for faster rebuilds."
+					cp -a "${S}/tools/perf/page_sets/media_cases/crowd1080.mp4" \
+						"${ASSET_CACHE}/crowd1080.mp4" || die
+					sha512sum "${ASSET_CACHE}/crowd1080.mp4" \
+						| cut -f 1 -d " " > "${ASSET_CACHE}/crowd1080.mp4.sha512" || die
+				fi
+
+				# ${CR_PGO_VIDEO0} -> garden2_10s.mp4
+				# 3840 x 2160 resolution
+				if [[ -f "${ASSET_CACHE}/video0_10s.mp4" \
+					&& -f "${ASSET_CACHE}/video0_10s.mp4.sha512" \
+					&& $(cat "${ASSET_CACHE}/video0_10s.mp4.sha512") \
+						== $(sha512sum "${ASSET_CACHE}/video0_10s.mp4" \
+							| cut -f 1 -d " ") ]] ; then
+					einfo "Using pregenerated and cached video0_10s.mp4"
+					cp -a "${ASSET_CACHE}/video0_10s.mp4" \
+						"${S}/tools/perf/page_sets/media_cases/video0_10s.mp4" \
+						|| die
+				else
+					filter_sw=()
+					filter_hw=( $(_gen_vaapi_filter "H264") )
+					if _is_hw_scaling_supported "H264" ; then
+						filter_hw+=( "scale_vaapi=w=-1:h=2160" )
+					else
+						filter_sw+=( "scale=w=-1:h=2160" )
+					fi
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp9_decoding[@]} \
+						-i $(realpath "${CR_PGO_VIDEO0}") \
+						${h264_encoding[@]} \
+						$(_is_vaapi_allowed "H264" && echo "${init_ffmpeg_filter[@]}") \
+						-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+							&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+							&& echo " ${filter_hw[@]}") | tr " " ",") \
+						${aac_encoding[@]} \
+						-t 10 \
+						"${S}/tools/perf/page_sets/media_cases/video0_10s.mp4" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+					einfo "Saving work to ${ASSET_CACHE}/video0_10s.mp4 for faster rebuilds."
+					cp -a "${S}/tools/perf/page_sets/media_cases/video0_10s.mp4" \
+						"${ASSET_CACHE}/video0_10s.mp4" || die
+					sha512sum "${ASSET_CACHE}/video0_10s.mp4" \
+						| cut -f 1 -d " " > "${ASSET_CACHE}/video0_10s.mp4.sha512" || die
+				fi
+				sed -i -e "s|garden2_10s.mp4|video0_10s.mp4|g" \
+					"${S}/tools/perf/page_sets/media_cases.py" || die
+			fi
+
+			# tulip2.webm -> crowd1080.webm
+			if [[ -f "${ASSET_CACHE}/crowd1080.webm" \
+				&& -f "${ASSET_CACHE}/crowd1080.webm.sha512" \
+				&& $(cat "${ASSET_CACHE}/crowd1080.webm.sha512") \
+					== $(sha512sum "${ASSET_CACHE}/crowd1080.webm" \
+						| cut -f 1 -d " ") ]] ; then
+				einfo "Using pregenerated and cached crowd1080.webm"
+				cp -a "${ASSET_CACHE}/crowd1080.webm" \
+					"${S}/tools/perf/page_sets/media_cases/crowd1080.webm" \
+					|| die
+			else
+				filter_sw=( "minterpolate=vsbmc=1" )
+				filter_hw=( $(_gen_vaapi_filter "VP8") )
+				if _is_hw_scaling_supported "VP8" ; then
+					filter_hw+=( "scale_vaapi=w=-1:h=1080" )
+				else
+					filter_sw+=( "scale=w=-1:h=1080" )
+				fi
+				cmd=( ffmpeg \
+					${drm_render_node[@]} \
+					${vp8_decoding[@]} \
+					-i "${S}/media/test/data/tulip2.webm" \
+					${vp8_encoding[@]} \
+					$(_is_vaapi_allowed "VP8" && echo "${init_ffmpeg_filter[@]}") \
+					-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+						&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+						&& echo " ${filter_hw[@]}") | tr " " ",") \
+					-maxrate 4350k -minrate 1500k -b:v 3000k -crf 31 \
+					${vorbis_encoding[@]} \
+					-r 50 \
+					"${S}/tools/perf/page_sets/media_cases/crowd1080.webm" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+				einfo "Saving work to ${ASSET_CACHE}/crowd1080.webm for faster rebuilds."
+				cp -a "${S}/tools/perf/page_sets/media_cases/crowd1080.webm" \
+					"${ASSET_CACHE}/crowd1080.webm" || die
+				sha512sum "${ASSET_CACHE}/crowd1080.webm" \
+					| cut -f 1 -d " " > "${ASSET_CACHE}/crowd1080.webm.sha512" || die
+			fi
+
+			# tulip2.webm -> crowd1080_vp9.webm
+			if [[ -f "${ASSET_CACHE}/crowd1080_vp9.webm" \
+				&& -f "${ASSET_CACHE}/crowd1080_vp9.webm.sha512" \
+				&& $(cat "${ASSET_CACHE}/crowd1080_vp9.webm.sha512") \
+					== $(sha512sum "${ASSET_CACHE}/crowd1080_vp9.webm" \
+						| cut -f 1 -d " ") ]] ; then
+				einfo "Using pregenerated and cached crowd1080_vp9.webm"
+				cp -a "${ASSET_CACHE}/crowd1080_vp9.webm" \
+					"${S}/tools/perf/page_sets/media_cases/crowd1080_vp9.webm" \
+					|| die
+			else
+				if _is_vaapi_allowed "VP9" ; then
+					filter_sw=( "minterpolate=vsbmc=1" )
+					filter_hw=( $(_gen_vaapi_filter "VP9") )
+					if _is_hw_scaling_supported "VP9" ; then
+						filter_hw+=( "scale_vaapi=w=-1:h=1080" )
+					else
+						filter_sw+=( "scale=w=-1:h=1080" )
+					fi
+					# Likely only single pass supported
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp8_decoding[@]} \
+						-i "${S}/media/test/data/tulip2.webm" \
+						${vp9_encoding[@]} \
+						$(_is_vaapi_allowed "VP9" && echo "${init_ffmpeg_filter[@]}") \
+						-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+							&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+							&& echo " ${filter_hw[@]}") | tr " " ",") \
+						-maxrate 4350k -minrate 1500k -b:v 3000k \
+						-r 50 \
+						"${S}/tools/perf/page_sets/media_cases/crowd1080_vp9.webm" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+				else
+					# See https://developers.google.com/media/vp9/settings/vod
+					cmd=( ffmpeg \
+						${drm_render_node[@]} \
+						${vp8_decoding[@]} \
+						-i "${S}/media/test/data/tulip2.webm" \
+						${vp9_encoding[@]} \
+						-vf "minterpolate=vsbmc=1" \
+						-maxrate 4350k -minrate 1500k -b:v 3000k -crf 31 \
+						-r 50 \
+						"${S}/tools/perf/page_sets/media_cases/crowd1080_vp9.webm" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+				fi
+				einfo "Saving work to ${ASSET_CACHE}/crowd1080_vp9.webm for faster rebuilds."
+				cp -a "${S}/tools/perf/page_sets/media_cases/crowd1080_vp9.webm" \
+					"${ASSET_CACHE}/crowd1080_vp9.webm" || die
+				sha512sum "${ASSET_CACHE}/crowd1080_vp9.webm" \
+					| cut -f 1 -d " " > "${ASSET_CACHE}/crowd1080_vp9.webm.sha512" || die
+			fi
+
+			# ${CR_PGO_VIDEO0} -> garden2_10s.webm
+			# 3840 x 2160 resolution
+			if [[ -f "${ASSET_CACHE}/video0_10s.webm" \
+				&& -f "${ASSET_CACHE}/video0_10s.webm.sha512" \
+				&& $(cat "${ASSET_CACHE}/video0_10s.webm.sha512") \
+					== $(sha512sum "${ASSET_CACHE}/video0_10s.webm" \
+						| cut -f 1 -d " ") ]] ; then
+				einfo "Using pregenerated and cached video0_10s.webm"
+				cp -a "${ASSET_CACHE}/video0_10s.webm" \
+					"${S}/tools/perf/page_sets/media_cases/video0_10s.webm" \
+					|| die
+			else
+				filter_sw=()
+				filter_hw=( $(_gen_vaapi_filter "VP8") )
+				if _is_hw_scaling_supported "VP8" ; then
+					filter_hw+=( "scale_vaapi=w=-1:h=2160" )
+				else
+					filter_sw+=( "scale=w=-1:h=2160" )
+				fi
+				cmd=( ffmpeg \
+					${drm_render_node[@]} \
+					${vp9_decoding[@]} \
+					-i $(realpath "${CR_PGO_VIDEO0}") \
+					${vp8_encoding[@]} \
+					$(_is_vaapi_allowed "VP8" && echo "${init_ffmpeg_filter[@]}") \
+					-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+						&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+						&& echo " ${filter_hw[@]}") | tr " " ",") \
+					${vorbis_encoding[@]} \
+					-t 10 \
+					"${S}/tools/perf/page_sets/media_cases/video0_10s.webm" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+				einfo "Saving work to ${ASSET_CACHE}/video0_10s.webm for faster rebuilds."
+				cp -a "${S}/tools/perf/page_sets/media_cases/video0_10s.webm" \
+					"${ASSET_CACHE}/video0_10s.webm" || die
+				sha512sum "${ASSET_CACHE}/video0_10s.webm" \
+					| cut -f 1 -d " " > "${ASSET_CACHE}/video0_10s.webm.sha512" || die
+			fi
+			sed -i -e "s|garden2_10s.webm|video0_10s.webm|g" \
+				"${S}/tools/perf/page_sets/media_cases.py" || die
+
+			# ffmpeg -> smpte_3840x2160_60fps_vp9.webm
+			# 3840 x 2160 resolution ; 120s required
+			if [[ -f "${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm" \
+				&& -f "${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm.sha512" \
+				&& $(cat "${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm.sha512") \
+					== $(sha512sum "${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm" \
+						| cut -f 1 -d " ") ]] ; then
+				einfo "Using pregenerated and cached smpte_3840x2160_60fps_vp9.webm"
+				cp -a "${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm" \
+					"${S}/tools/perf/page_sets/media_cases/smpte_3840x2160_60fps_vp9.webm" \
+					|| die
+			else
+				einfo "Generating test video.  Estimated completion time: several min to hour(s)."
+				vp9_filter_args=( -vf "format=nv12,hwupload" )
+				libvpx_vp9_args=( -crf 31 )
+				cmd=( ffmpeg \
+					${drm_render_node[@]} \
+					-f lavfi -i testsrc=duration=120:size=3840x2160:rate=60 \
+					${vp9_encoding[@]} \
+					$(_is_vaapi_allowed "VP9" && echo "${init_ffmpeg_filter[@]}") \
+					$(_is_vaapi_allowed "VP9" && echo "${vp9_filter_args[@]}") \
+					-maxrate 26100k -minrate 9000k -b:v 18000k \
+					$(_is_vaapi_allowed "VP9" || echo "${libvpx_vp9_args[@]}") \
+					-an \
+					"${S}/tools/perf/page_sets/media_cases/smpte_3840x2160_60fps_vp9.webm" )
+				einfo "${cmd[@]}"
+				"${cmd[@]}" || die "${cmd[@]}"
+				einfo "Saving work to ${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm for faster rebuilds."
+				cp -a "${S}/tools/perf/page_sets/media_cases/smpte_3840x2160_60fps_vp9.webm" \
+					"${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm" || die
+				sha512sum "${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm" \
+					| cut -f 1 -d " " > "${ASSET_CACHE}/smpte_3840x2160_60fps_vp9.webm.sha512" || die
+			fi
+
+			# tulip2.webm -> tulip0.av1.mp4
+			# Must be 8 bit AV1
+			# An alternative exist (bear in the media/test/data) folder,
+			# but it was decided to stick to the tulip to match upstream testing.
+			if [[ -f "${ASSET_CACHE}/tulip0.av1.mp4" \
+				&& -f "${ASSET_CACHE}/tulip0.av1.mp4.sha512" \
+				&& $(cat "${ASSET_CACHE}/tulip0.av1.mp4.sha512") \
+					== $(sha512sum "${ASSET_CACHE}/tulip0.av1.mp4" \
+						| cut -f 1 -d " ") ]] ; then
+				einfo "Using pregenerated and cached tulip0.av1.mp4"
+				cp -a "${ASSET_CACHE}/tulip0.av1.mp4" \
+					"${S}/tools/perf/page_sets/media_cases/tulip0.av1.mp4" \
+					|| die
+			else
+				filter_sw=( format=yuv420p )
+				filter_hw=( $(_gen_vaapi_filter "AV1") )
+				cmd=( ffmpeg \
+					${drm_render_node[@]} \
+					${vp8_decoding[@]} \
+					-i "${S}/media/test/data/tulip2.webm" \
+					${av1_encoding[@]} \
+					$(_is_vaapi_allowed "AV1" && echo "${init_ffmpeg_filter[@]}") \
+					-vf $(echo $((( ${#filter_sw[@]} > 0 )) \
+						&& echo " ${filter_sw[@]}")$((( ${#filter_hw[@]} > 0 )) \
+						&& echo " ${filter_hw[@]}") | tr " " ",") \
+					-an \
+					"${S}/tools/perf/page_sets/media_cases/tulip0.av1.mp4" )
+					einfo "${cmd[@]}"
+					"${cmd[@]}" || die "${cmd[@]}"
+				einfo "Saving work to ${ASSET_CACHE}/tulip0.av1.mp4 for faster rebuilds."
+				cp -a "${S}/tools/perf/page_sets/media_cases/tulip0.av1.mp4" \
+					"${ASSET_CACHE}/tulip0.av1.mp4" || die
+				sha512sum "${ASSET_CACHE}/tulip0.av1.mp4" \
+					| cut -f 1 -d " " > "${ASSET_CACHE}/tulip0.av1.mp4.sha512" || die
+			fi
+		fi
+	fi
+}
+
+gen_full_pgo_external_access_uris() {
+	#
+	# Function just reports URIs used primarily by remote_access_use PGO
+	# trainers below.
+	#
+	# The package doesn't have some web benchmarks but you need to snapshot
+	# a website to PGO train from them.
+	#
+	if use pgo-full ; then
+		for u in ${remote_access_use[@]} ; do
+			# This section is still unfinished
+			# TODO: Still categorizing benchmarks if local copy
+			# or network access access is required
+			if [[ "${u}" =~ "blink_perf" \
+				|| "${u}" =~ "dummy_benchmark" \
+				|| "${u}" =~ "memory_desktop" \
+				|| "${u}" =~ "speedometer2" \
+				|| "${u}" =~ "webrtc" \
+				]] ; then
+				:; # Skip if local copy
+			elif has network-sandbox $FEATURES ; then
+				# -network-sandbox requirement applies to:
+				# dromaeo
+				# jetstream
+				# jetstream2
+				# kraken
+				# octane
+				# power.mobile
+				# speedometer
+				# speedometer-future
+				# system_health_pcscan
+				# tab_switching_typical_25
+				# wasmpspdfkit
+eerror
+eerror "The ${u} USE flag requires FEATURES=\"-network-sandbox\" to be added as"
+eerror "a per-package envvar to allowed Internet access to a website in order to"
+eerror "perform benchmarks in the src_compile() phase."
+eerror
+				die
+			fi
+		done
+		# Backtrack tools/perf/benchmark.csv to find the USE flag
+		# All sites in remote_access_use assume real time retrieval.
+		# TODO: check if all relevant USE flags added:
+		local remote_access_use=(
+			cr_pgo_trainers_desktop_ui
+			cr_pgo_trainers_loading_desktop
+			cr_pgo_trainers_loading_mobile
+			cr_pgo_trainers_power_mobile
+			cr_pgo_trainers_rasterize_and_record_micro_top_25
+			cr_pgo_trainers_rendering_mobile
+			cr_pgo_trainers_system_health_common_desktop
+			cr_pgo_trainers_system_health_common_mobile
+			cr_pgo_trainers_system_health_memory_desktop
+			cr_pgo_trainers_system_health_memory_mobile
+			cr_pgo_trainers_system_health_pcscan
+			cr_pgo_trainers_tab_switching_typical_25
+			cr_pgo_trainers_unscheduled_loading_mbi
+			cr_pgo_trainers_unscheduled_v8_loading_desktop
+			cr_pgo_trainers_v8_runtime_stats_top_25
+		)
+		local warned=0
+ewarn
+ewarn "Discovered URIs for external access for PGO trainers:"
+ewarn
+		echo "http://dromaeo.com?"{'dom-attr','dom-modify','dom-query','dom-traverse'} \
+			> "${T}/found_uris" || die
+		( grep -Pzo -r -e "URL_LIST = \[[^\]]+\]" \
+			"${S}/tools/perf/page_sets" || die ) \
+			| tr "\0" "\n" \
+			| sed -e "s|.*URL_LIST =|URL_LIST =|g" \
+				-e "\|URL_LIST = \[DOWNLOAD_URL\]|d" \
+			>> "${T}/found_uris" || die
+		( grep  -Pzo -r -e "(urls_list|ads_urls_list) = \[\n([^\]]*\n)+" \
+			"${S}/tools/perf" || die ) \
+			| sed -e "s|/.*.py:||g" \
+			>> "${T}/found_uris" || die
+		( grep -Pzo -r -e "URL = ([(][^)]+|'[^']+)" \
+			"${S}/tools/perf/page_sets" || die ) \
+			| tr "\0" "\n" \
+			| sed -e "s|.*URL =|URL =|g" \
+			>> "${T}/found_uris" || die
+		( grep -Pzo -r -e "AddStor(ies|y)\((((.*)(\[|,)\n(.*#.*\n)*)+|(.*#.*\n)|([^']*\n.*http.*\n)|(.*http.*)) " \
+			"${S}/tools/perf/" || die ) \
+			| tr "\0" "\n" \
+			| sed -e "s|.*AddStories||g" \
+			| sed -e "s|.*.py:AddStory||"
+			>> "${T}/found_uris" || die
+		cat "${T}/found_uris" || die
+ewarn
+ewarn "A more comprehensive list of external URIs to be accessed that are"
+ewarn "possibly used by some PGO trainers can be read.  You can be read this"
+ewarn "info by scrolling up with ctrl + page up or by doing the following in"
+ewarn "another terminal:"
+ewarn
+ewarn "  \`cat ${T}/found_uris\`"
+ewarn
+ewarn "Some may or may not be relevant depending on the USE flags used."
+ewarn
+		local accepted_use_list=()
+		for u in ${remote_access_use[@]} ; do
+			if use "${u}" ; then
+				accepted_use_list+=( ${u} )
+				warned=1
+			fi
+		done
+		if (( ${warned} == 1 )) ; then
+ewarn
+ewarn "The following affected USE flags were consented for access and use of"
+ewarn "the web for PGO trainers:"
+ewarn
+for u in ${accepted_use_list[@]} ; do
+ewarn "  ${u}"
+done
+ewarn
+ewarn "The affected USE flag(s) may access external sites with possibly"
+ewarn "untrusted user contributed data when using PGO profile generation and"
+ewarn "may need site terms of use to be reviewed for acceptable use.  They also"
+ewarn "may access news, governmental, political, or corporate sites.  They may"
+ewarn "access or reference unfree trademarks and content."
+ewarn
+ewarn "You have 180 seconds to remove this USE flag if you disagree with such"
+ewarn "access.  You may cancel and make changes by pressing ctrl + c."
+ewarn
+			sleep 180
+		fi
+	fi
+}
+
+verify_clang_commit() {
+	use pre-check-llvm || return
+	local commit_id=$(grep -r -e "CLANG_REVISION" \
+		"${S}/tools/clang/scripts/update.py" \
+		| head -n 1 \
+		| grep -E -o -e "-g[a-f0-9]+" \
+		| sed -e "s|-g||g")
+	if [[ "${CR_CLANG_USED}" =~ ^"${commit_id}" ]] ; then
+		:;
+	else
+		# Update on every major version of this package.
+		eerror "The LLVM commit is out of date.  Update CR_CLANG_*,"
+		eerror "LLVM_SLOTS, CR_CLANG_SLOT_OFFICIAL variables."
+		die
+	fi
 }
 
 src_prepare() {
 	# Calling this here supports resumption via FEATURES=keepwork
 	python_setup
 
-	local PATCHES=(
-		"${WORKDIR}/patches"
+	local PATCHES=()
+	if ( ! use clang ) || use system-libstdcxx ; then
+		# Contains arm64 patches for unknown purpose.
+		# TODO: split GCC only and libstdc++ only.
+		# The patches purpose are not documented well.
+ewarn
+ewarn "Applying GCC & libstdc++ compatibility patches."
+ewarn
+		PATCHES+=( "${WORKDIR}/patches" )
+	fi
+
+	PATCHES+=(
 		"${FILESDIR}/chromium-93-InkDropHost-crash.patch"
-		"${FILESDIR}/chromium-97-arm-tflite-cast.patch"
+		$(usex arm64 "${FILESDIR}/chromium-97-arm-tflite-cast.patch" "")
 		"${FILESDIR}/chromium-98-EnumTable-crash.patch"
 		"${FILESDIR}/chromium-98-gtk4-build.patch"
 		"${FILESDIR}/chromium-use-oauth2-client-switches-as-default.patch"
@@ -256,8 +3153,46 @@ src_prepare() {
 
 	use ppc64 && PATCHES+=( "${WORKDIR}/patches-ppc64" )
 
+	if use clang ; then
+		if tc-is-clang ; then # Duplicate conditional is for testing reasons
+			# Using gcc with these patches results in this error:
+			# Two or more targets generate the same output:
+			#   lib.unstripped/libEGL.so
+			ceapply "${FILESDIR}/extra-patches/${PN}-92-clang-toolchain-1.patch"
+			ceapply "${FILESDIR}/extra-patches/${PN}-92-clang-toolchain-2.patch"
+		fi
+	fi
+
+	if use arm64 && use shadowcallstack ; then
+		ceapply "${FILESDIR}/extra-patches/chromium-94-arm64-shadow-call-stack.patch"
+	fi
+
+	ceapply "${FILESDIR}/extra-patches/chromium-95.0.4638.54-zlib-selective-simd.patch"
+
 	default
 
+	if use cr_pgo_trainers_custom && [[ ! -f "${T}/epatch_user.log" ]] ; then
+eerror
+eerror "You must supply a per-package patch to use the cr_pgo_trainers_custom"
+eerror "USE flag."
+eerror
+		die
+	fi
+
+	if ( (( ${#PATCHES[@]} > 0 || ${USED_EAPPLY} == 1 )) || [[ -f "${T}/epatch_user.log" ]] ) ; then
+		if use official ; then
+			ewarn
+			ewarn "The use of unofficial patches is not endorsed upstream."
+			ewarn
+		fi
+
+		if use pgo ; then
+			ewarn
+			ewarn "The use of patching can interfere with the pregenerated PGO profile."
+			ewarn
+		fi
+	fi
+
 	mkdir -p third_party/node/linux/node-linux-x64/bin || die
 	ln -s "${EPREFIX}"/usr/bin/node third_party/node/linux/node-linux-x64/bin/node || die
 
@@ -487,6 +3422,7 @@ src_prepare() {
 		third_party/xcbproto
 		third_party/zxcvbn-cpp
 		third_party/zlib/google
+		third_party/zlib
 		url/third_party/mozilla
 		v8/src/third_party/siphash
 		v8/src/third_party/valgrind
@@ -500,18 +3436,26 @@ src_prepare() {
 		third_party/usb_ids
 		third_party/xdg-utils
 	)
-	if ! use system-ffmpeg; then
+	# third_party/zlib is already kept but may use system no need split conditional for CFI or official builds.
+	if use pgo-full ; then
+		keeplibs+=(
+			third_party/catapult/third_party/gsutil
+			third_party/catapult/third_party/tsproxy
+			third_party/catapult/third_party/typ
+		)
+	fi
+	if ! use system-ffmpeg ; then
 		keeplibs+=( third_party/ffmpeg third_party/opus )
 	fi
-	if ! use system-icu; then
+	if ! use system-icu ; then
 		keeplibs+=( third_party/icu )
 	fi
 	if ! use system-png; then
 		keeplibs+=( third_party/libpng )
 	fi
-	if use libcxx; then
-		keeplibs+=( third_party/re2 )
-	fi
+	# For re2 see ! use system-libstdcxx conditional below
+	#
+	#
 	if use system-harfbuzz; then
 		keeplibs+=( third_party/harfbuzz-ng/utils )
 	else
@@ -523,9 +3467,25 @@ src_prepare() {
 	if use arm64 || use ppc64 ; then
 		keeplibs+=( third_party/swiftshader/third_party/llvm-10.0 )
 	fi
+	if ! use system-libstdcxx \
+		|| use cfi-cast \
+		|| use cfi-icall \
+		|| use cfi-vcall \
+		|| use official ; then
+		keeplibs+=( third_party/libxml )
+		keeplibs+=( third_party/libxslt )
+		keeplibs+=( third_party/re2 )
+		#keeplibs+=( third_party/snappy )
+		if use proprietary-codecs ; then
+			keeplibs+=( third_party/openh264 )
+		fi
+		if use system-icu ; then
+			keeplibs+=( third_party/icu )
+		fi
+	fi
 	# we need to generate ppc64 stuff because upstream does not ship it yet
 	# it has to be done before unbundling.
-	if use ppc64; then
+	if use ppc64 ; then
 		pushd third_party/libvpx >/dev/null || die
 		mkdir -p source/config/linux/ppc64 || die
 		# requires git and clang, bug #832803
@@ -540,42 +3500,99 @@ src_prepare() {
 		popd >/dev/null || die
 	fi
 
-	# Remove most bundled libraries. Some are still needed.
-	build/linux/unbundle/remove_bundled_libraries.py "${keeplibs[@]}" --do-remove || die
+	if ! is_generating_credits ; then
+		einfo "Unbundling third party internal libraries and packages"
+		# Remove most bundled libraries. Some are still needed.
+		build/linux/unbundle/remove_bundled_libraries.py "${keeplibs[@]}" --do-remove || die
+	fi
 
-	if use js-type-check; then
+	if use js-type-check ; then
 		ln -s "${EPREFIX}"/usr/bin/java third_party/jdk/current/bin/java || die
 	fi
 
-	# bundled eu-strip is for amd64 only and we don't want to pre-stripped binaries
-	mkdir -p buildtools/third_party/eu-strip/bin || die
-	ln -s "${EPREFIX}"/bin/true buildtools/third_party/eu-strip/bin/eu-strip || die
+	if ! is_generating_credits ; then
+		# bundled eu-strip is for amd64 only and we don't want to pre-stripped binaries
+		mkdir -p buildtools/third_party/eu-strip/bin || die
+		ln -s "${EPREFIX}"/bin/true buildtools/third_party/eu-strip/bin/eu-strip || die
+	fi
+
+	verify_clang_commit
+	gen_full_pgo_assets
+	gen_full_pgo_external_access_uris
+
+	(( ${NABIS} > 1 )) \
+		&& multilib_copy_sources
 }
 
-src_configure() {
+_configure_pgx() {
+	local chost=$(get_abi_CHOST ${ABI})
 	# Calling this here supports resumption via FEATURES=keepwork
 	python_setup
 
+	if use pgo-full ; then
+		for f in $(grep -l -F -r -e "/opt/chromium/chrome_sandbox" testing) ; do
+			einfo "Changing hardcoded /opt/chromium/chrome_sandbox -> ${BUILD_DIR}/out/Release/chrome_sandbox for ${f}"
+			sed -i -e "s|/opt/chromium/chrome_sandbox|${BUILD_DIR}/out/Release/chrome_sandbox|" \
+				"${f}" || die
+		done
+	fi
+
 	local myconf_gn=""
 
 	# Make sure the build system will use the right tools, bug #340795.
-	tc-export AR CC CXX NM
+	tc-export AR CC CXX NM READELF STRIP
+
+	if tc-is-clang && ! use clang ; then
+ewarn
+ewarn "Clang detected but clang USE flag was disabled."
+ewarn
+ewarn "Enable the clang USE flag for clang otherwise disable the clang USE"
+ewarn "flag for gcc."
+ewarn
+		die
+	fi
 
-	if { [[ ${CHROMIUM_FORCE_CLANG} == yes ]] || use libcxx; } && ! tc-is-clang; then
-		# Force clang since gcc is either broken or build is using libcxx.
+	# Final CC selected
+	if use clang ; then
+		# See build/toolchain/linux/unbundle/BUILD.gn for allowed overridable envvars.
+		# See build/toolchain/gcc_toolchain.gni#L657 for consistency.
 		if tc-is-cross-compiler; then
-			CC="${CBUILD}-clang -target ${CHOST} --sysroot ${ESYSROOT}"
-			CXX="${CBUILD}-clang++ -target ${CHOST} --sysroot ${ESYSROOT}"
-			BUILD_CC=${CBUILD}-clang
-			BUILD_CXX=${CBUILD}-clang++
+			export CC="${CBUILD}-clang -target ${CHOST} --sysroot ${ESYSROOT}"
+			export CXX="${CBUILD}-clang++ -target ${CHOST} --sysroot ${ESYSROOT}"
+			export BUILD_CC=${CBUILD}-clang
+			export BUILD_CXX=${CBUILD}-clang++
+		elif [[ -n ${FORCE_LLVM_SLOT} ]] ; then
+			export CC="clang-${FORCE_LLVM_SLOT} $(get_abi_CFLAGS ${ABI})"
+			export CXX="clang++-${FORCE_LLVM_SLOT} $(get_abi_CFLAGS ${ABI})"
 		else
-			CC=${CHOST}-clang
-			CXX=${CHOST}-clang++
+			export CC="clang-${LLVM_SLOT} $(get_abi_CFLAGS ${ABI})"
+			export CXX="clang++-${LLVM_SLOT} $(get_abi_CFLAGS ${ABI})"
+		fi
+		export AR=llvm-ar # Required for LTO
+		export NM=llvm-nm
+		export READELF=llvm-readelf
+		export STRIP=llvm-strip
+		if ! which llvm-ar 2>/dev/null 1>/dev/null ; then
+			die "llvm-ar is unreachable"
 		fi
-		strip-unsupported-flags
+	else
+		einfo "Forcing GCC"
+		export CC="gcc $(get_abi_CFLAGS ${ABI})"
+		export CXX="g++ $(get_abi_CFLAGS ${ABI})"
+		export AR=ar
+		export NM=nm
+		export READELF=readelf
+		export STRIP=strip
+		export LD=ld.bfd
 	fi
+	strip-unsupported-flags
+
+	# Handled by the build scripts
+	filter-flags \
+		'-f*sanitize*' \
+		'-f*visibility*'
 
-	if tc-is-clang || use libcxx; then
+	if use clang ; then
 		myconf_gn+=" is_clang=true clang_use_chrome_plugins=false"
 	else
 		myconf_gn+=" is_clang=false"
@@ -584,11 +3601,11 @@ src_configure() {
 	# Define a custom toolchain for GN
 	myconf_gn+=" custom_toolchain=\"//build/toolchain/linux/unbundle:default\""
 
-	if tc-is-cross-compiler; then
+	if tc-is-cross-compiler ; then
 		tc-export BUILD_{AR,CC,CXX,NM}
 		myconf_gn+=" host_toolchain=\"//build/toolchain/linux/unbundle:host\""
 		myconf_gn+=" v8_snapshot_toolchain=\"//build/toolchain/linux/unbundle:host\""
-		myconf_gn+=" pkg_config=\"$(tc-getPKG_CONFIG)\""
+		myconf_gn+=" pkg_config=\"$(tc-get_PKG_CONFIG)\""
 		myconf_gn+=" host_pkg_config=\"$(tc-getBUILD_PKG_CONFIG)\""
 
 		# setup cups-config, build system only uses --libs option
@@ -604,6 +3621,8 @@ src_configure() {
 		myconf_gn+=" host_toolchain=\"//build/toolchain/linux/unbundle:default\""
 	fi
 
+# Debug symbols level 2 is still on when official is on even though is_debug=false:
+# See https://github.com/chromium/chromium/blob/100.0.4896.75/build/config/compiler/compiler.gni#L276
 	# GN needs explicit config for Debug/Release as opposed to inferring it from build directory.
 	myconf_gn+=" is_debug=false"
 
@@ -619,6 +3638,12 @@ src_configure() {
 	# Disable nacl, we can't build without pnacl (http://crbug.com/269560).
 	myconf_gn+=" enable_nacl=false"
 
+	if use partitionalloc ; then
+		myconf_gn+=" use_allocator=\"partition\""
+	else
+		myconf_gn+=" use_allocator=\"none\""
+	fi
+
 	# Use system-provided libraries.
 	# TODO: freetype -- remove sources (https://bugs.chromium.org/p/pdfium/issues/detail?id=733).
 	# TODO: use_system_hunspell (upstream changes needed).
@@ -626,6 +3651,7 @@ src_configure() {
 	# TODO: use_system_sqlite (http://crbug.com/22208).
 
 	# libevent: https://bugs.gentoo.org/593458
+	# [B] all of gn_system_libraries set
 	local gn_system_libraries=(
 		flac
 		fontconfig
@@ -635,25 +3661,51 @@ src_configure() {
 		libdrm
 		libjpeg
 		libwebp
-		libxml
-		libxslt
-		openh264
+		# moved in use system-libstdcxx cond
+		# moved in use system-libstdcxx cond
+		# moved in use system-libstdcxx cond
 		zlib
 	)
-	if use system-ffmpeg; then
+	if use system-ffmpeg ; then
 		gn_system_libraries+=( ffmpeg opus )
 	fi
-	if use system-icu; then
+	if use system-icu ; then
 		gn_system_libraries+=( icu )
 	fi
-	if use system-png; then
+	if use system-png ; then
 		gn_system_libraries+=( libpng )
 	fi
-	# re2 library interface relies on std::string and std::vector
-	if ! use libcxx; then
+	if use system-libstdcxx ; then
+		# unbundle only without libc++, because libc++ is not fully ABI compatible with libstdc++
+		gn_system_libraries+=( libxml )
+		gn_system_libraries+=( libxslt )
+		# re2 library interface relies on std::string and std::vector
 		gn_system_libraries+=( re2 )
+		if use proprietary-codecs ; then
+			gn_system_libraries+=( openh264 )
+		fi
+	fi
+	# [C]
+	if ! use system-libstdcxx \
+		|| use cfi-cast \
+		|| use cfi-icall \
+		|| use cfi-vcall \
+		|| use official ; then
+		# Unbundling breaks cfi-icall and cfi-cast.
+		# Unbundling weakens the security because it removes
+		# noexecstack, full RELRO, SSP.
+einfo
+einfo "Forcing use of internal libs to maintain upstream security expectations"
+einfo "and requirements."
+einfo
+	else
+		if ! is_generating_credits ; then
+ewarn
+ewarn "Unbundling libs and disabling hardening (CFI, SSP, noexecstack, Full RELRO)."
+ewarn
+			build/linux/unbundle/replace_gn_files.py --system-libraries "${gn_system_libraries[@]}" || die
+		fi
 	fi
-	build/linux/unbundle/replace_gn_files.py --system-libraries "${gn_system_libraries[@]}" || die
 
 	# See dependency logic in third_party/BUILD.gn
 	myconf_gn+=" use_system_harfbuzz=$(usex system-harfbuzz true false)"
@@ -683,16 +3735,25 @@ src_configure() {
 
 	# TODO: link_pulseaudio=true for GN.
 
-	myconf_gn+=" disable_fieldtrial_testing_config=true"
+	#myconf_gn+=" disable_fieldtrial_testing_config=true"
 
 	# Never use bundled gold binary. Disable gold linker flags for now.
+	myconf_gn+=" use_gold=false use_sysroot=false"
 	# Do not use bundled clang.
 	# Trying to use gold results in linker crash.
-	myconf_gn+=" use_gold=false use_sysroot=false"
-	myconf_gn+=" use_custom_libcxx=$(usex libcxx true false)"
+	if use official && ( use cfi-cast || use cfi-icall || use cfi-vcall ) || use bundled-libcxx ; then
+		# If you didn't do systemwide CFI Cross-DSO, it must be static.
+		myconf_gn+=" use_custom_libcxx=true"
+	else
+		myconf_gn+=" use_custom_libcxx=false"
+	fi
 
-	# Disable forced lld, bug 641556
-	myconf_gn+=" use_lld=false"
+	if use clang || tc-is-clang ; then
+		filter-flags -fuse-ld=*
+		myconf_gn+=" use_lld=true"
+	else
+		myconf_gn+=" use_lld=false"
+	fi
 
 	# Disable pseudolocales, only used for testing
 	myconf_gn+=" enable_pseudolocales=false"
@@ -718,18 +3779,18 @@ src_configure() {
 	local myarch="$(tc-arch)"
 
 	# Avoid CFLAGS problems, bug #352457, bug #390147.
-	if ! use custom-cflags; then
+	if ! use custom-cflags ; then
 		replace-flags "-Os" "-O2"
 		strip-flags
 
 		# Debug info section overflows without component build
 		# Prevent linker from running out of address space, bug #471810 .
-		if ! use component-build || use x86; then
+		if ! use component-build || use x86 ; then
 			filter-flags "-g*"
 		fi
 
 		# Prevent libvpx build failures. Bug 530248, 544702, 546984.
-		if [[ ${myarch} == amd64 || ${myarch} == x86 ]]; then
+		if [[ ${myarch} == amd64 || ${myarch} == x86 ]] ; then
 			filter-flags -mno-mmx -mno-sse2 -mno-ssse3 -mno-sse4.1 -mno-avx -mno-avx2 -mno-fma -mno-fma4
 		fi
 	fi
@@ -757,6 +3818,42 @@ src_configure() {
 		die "Failed to determine target arch, got '$myarch'."
 	fi
 
+	local target_cpu=""
+	case "${ABI}" in
+		amd64*|x64*)
+			target_cpu="x64"
+			;;
+		arm|n32|n64|o32)
+			target_cpu="${chost%%-*}"
+			;;
+		arm64|ppc|ppc64|s390*)
+			target_cpu="${ABI}"
+			;;
+		ppc_aix,ppc_macos)
+			target_cpu="ppc"
+			;;
+		x86*)
+			target_cpu="x86"
+			;;
+		*)
+			einfo "${ABI} is not supported"
+			;;
+	esac
+
+	myconf_gn+=" target_cpu=\"${target_cpu}\""
+	myconf_gn+=" v8_current_cpu=\"${target_cpu}\""
+	myconf_gn+=" current_cpu=\"${target_cpu}\""
+	myconf_gn+=" host_cpu=\"${target_cpu}\""
+	myconf_gyp+=" -Dtarget_arch=${target_arch}"
+
+	if ! use cpu_flags_x86_sse4_2 ; then
+		myconf_gn+=" use_sse4_2=false"
+	fi
+
+	if ! use cpu_flags_x86_ssse3 ; then
+		myconf_gn+=" use_ssse3=false"
+	fi
+
 	# Make sure that -Werror doesn't get added to CFLAGS by the build system.
 	# Depending on GCC version the warnings are different and we don't want
 	# the build to fail because of that.
@@ -765,12 +3862,6 @@ src_configure() {
 	# Disable fatal linker warnings, bug 506268.
 	myconf_gn+=" fatal_linker_warnings=false"
 
-	# Disable external code space for V8 for ppc64. It is disabled for ppc64
-	# by default, but cross-compiling on amd64 enables it again.
-	if use ppc64; then
-		myconf_gn+=" v8_enable_external_code_space=false"
-	fi
-
 	# Bug 491582.
 	export TMPDIR="${WORKDIR}/temp"
 	mkdir -p -m 755 "${TMPDIR}" || die
@@ -778,10 +3869,10 @@ src_configure() {
 	# https://bugs.gentoo.org/654216
 	addpredict /dev/dri/ #nowarn
 
-	#if ! use system-ffmpeg; then
-	if false; then
+	#if ! use system-ffmpeg ; then
+	if false ; then
 		local build_ffmpeg_args=""
-		if use pic && [[ "${ffmpeg_target_arch}" == "ia32" ]]; then
+		if use pic && [[ "${ffmpeg_target_arch}" == "ia32" ]] ; then
 			build_ffmpeg_args+=" --disable-asm"
 		fi
 
@@ -813,10 +3904,11 @@ src_configure() {
 	myconf_gn+=" use_ozone=true ozone_auto_platforms=false"
 	myconf_gn+=" ozone_platform_headless=true"
 	myconf_gn+=" ozone_platform_x11=$(usex headless false true)"
-	if use wayland || use headless; then
-		if use headless; then
+	if use wayland || use headless ; then
+		if use headless ; then
 			myconf_gn+=" ozone_platform=\"headless\""
 			myconf_gn+=" use_xkbcommon=false use_gtk=false"
+			myconf_gn+=" use_x11=false"
 			myconf_gn+=" use_glib=false use_gio=false"
 			myconf_gn+=" use_pangocairo=false use_alsa=false"
 			myconf_gn+=" use_libpci=false use_udev=false"
@@ -835,17 +3927,90 @@ src_configure() {
 
 	# Enable official builds
 	myconf_gn+=" is_official_build=$(usex official true false)"
-	myconf_gn+=" use_thin_lto=false"
-	if use official; then
+	if use clang || tc-is-clang ; then
+		ewarn "Using ThinLTO"
+		myconf_gn+=" use_thin_lto=true "
+		use lto-opt && myconf_gn+=" thin_lto_enable_optimizations=true"
+	else
+		# gcc doesn't like -fsplit-lto-unit and -fwhole-program-vtables
+		myconf_gn+=" use_thin_lto=false "
+	fi
+	if use official ; then
 		# Allow building against system libraries in official builds
 		sed -i 's/OFFICIAL_BUILD/GOOGLE_CHROME_BUILD/' \
 			tools/generate_shim_headers/generate_shim_headers.py || die
-		# Disable CFI: unsupported for GCC, requires clang+lto+lld
+	fi
+
+# See https://github.com/chromium/chromium/blob/100.0.4896.75/build/config/sanitizers/BUILD.gn#L196
+	if use cfi-vcall ; then
+		myconf_gn+=" is_cfi=true"
+	else
 		myconf_gn+=" is_cfi=false"
-		# Disable PGO, because profile data is only compatible with >=clang-11
+	fi
+
+# See https://github.com/chromium/chromium/blob/100.0.4896.75/tools/mb/mb_config.pyl#L2950
+	if use cfi-cast ; then
+		myconf_gn+=" use_cfi_cast=true"
+	else
+		myconf_gn+=" use_cfi_cast=false"
+	fi
+
+	if use cfi-icall ; then
+		myconf_gn+=" use_cfi_icall=true"
+	else
+		myconf_gn+=" use_cfi_icall=false"
+	fi
+
+	if use arm64 && use branch-protection-standard ; then
+		myconf_gn+=" arm_control_flow_integrity=standard"
+	fi
+
+	if use arm64 && use shadowcallstack ; then
+		myconf_gn+=" use_shadow_call_stack=true"
+	fi
+
+	if use pgo ; then
+		if ! is_profdata_compatible ; then
+			eerror
+			eerror "Profdata compatibility:"
+			eerror
+			eerror "The PGO profile is not compatible with this version of LLVM."
+			eerror "Expected:  $(get_pregenerated_profdata_version)"
+			eerror "Found:  ${CURRENT_PROFDATA_VERSION} for ~sys-devel/llvm-${CURRENT_PROFDATA_LLVM_VERSION}"
+			eerror
+			eerror "The solution is to rebuild using a newer/older commit or tag."
+			eerror
+			eerror "The mapping between INSTR_PROF_INDEX_VERSION and the commit or tag can be"
+			eerror "found in InstrProfData.inc in the LLVM repo."
+			eerror
+			die
+		else
+			einfo
+			einfo "Profdata compatibility:"
+			einfo
+			einfo "Expected:  $(get_pregenerated_profdata_version)"
+			einfo "Found:  ${CURRENT_PROFDATA_VERSION} for ~sys-devel/llvm-${CURRENT_PROFDATA_LLVM_VERSION}"
+			einfo
+		fi
+	fi
+
+# See also build/config/compiler/pgo/BUILD.gn#L71 for PGO flags.
+# See also https://github.com/chromium/chromium/blob/100.0.4896.75/docs/pgo.md
+# profile-instr-use is clang which that file assumes but gcc doesn't have.
+	if use pgo-full ; then
+		myconf_gn+=" chrome_pgo_phase=${PGO_PHASE}"
+		mkdir -p "${BUILD_DIR}/chrome/build/pgo_profiles" || die
+		[[ "${PGO_PHASE}" == "2" ]] && \
+		myconf_gn+=" pgo_data_path=\"${BUILD_DIR}/chrome/build/pgo_profiles/custom.profdata\""
+	elif use pgo && tc-is-clang && ver_test $(clang-version) -ge 11 ; then
+		# The profile data is already shipped so use it.
+		# PGO profile location: chrome/build/pgo_profiles/chrome-linux-*.profdata
+		myconf_gn+=" chrome_pgo_phase=2"
+	else
+		# The pregenerated profiles are not GCC compatible.
 		myconf_gn+=" chrome_pgo_phase=0"
-		# Don't add symbols to build
-		myconf_gn+=" symbol_level=0"
+		# Kept symbols in build for debug reports for official
+		# myconf_gn+=" symbol_level=0"
 	fi
 
 	einfo "Configuring Chromium..."
@@ -854,38 +4019,266 @@ src_configure() {
 	"$@" || die
 }
 
-src_compile() {
-	# Final link uses lots of file descriptors.
-	ulimit -n 2048
-
-	# Calling this here supports resumption via FEATURES=keepwork
-	python_setup
+_build() {
+	local ninja_into="${1}"
+	local target_id="${2}"
+	local pax_path="${3}"
+	local file_name=$(basename "${2}")
 
-	# Don't inherit PYTHONPATH from environment, bug #789021, #812689
-	local -x PYTHONPATH=
+	einfo "Building ${file_name}"
+	eninja -C "${ninja_into}" "${target_id}"
 
-	#"${EPYTHON}" tools/clang/scripts/update.py --force-local-build --gcc-toolchain /usr --skip-checkout --use-system-cmake --without-android || die
+	if [[ -n "${pax_path}" ]] ; then
+		pax-mark m "${pax_path}"
+	fi
+}
 
+_build_pgx() {
+	if [[ -f out/Release/chromedriver ]] ; then
+		rm out/Release/chromedriver || die
+	fi
+	if [[ -f out/Release/chromedriver.unstripped ]] ; then
+		rm out/Release/chromedriver.unstripped || die
+	fi
+	if [[ -f out/Release/build.ninja ]] ; then
+		pushd out/Release || popd
+			einfo "Cleaning out build"
+			eninja -t clean
+		popd
+	fi
 	# Build mksnapshot and pax-mark it.
 	local x
 	for x in mksnapshot v8_context_snapshot_generator; do
-		if tc-is-cross-compiler; then
-			eninja -C out/Release "host/${x}"
-			pax-mark m "out/Release/host/${x}"
+		if tc-is-cross-compiler ; then
+			_build "out/Release" "host/${x}" "out/Release/host/${x}"
 		else
-			eninja -C out/Release "${x}"
-			pax-mark m "out/Release/${x}"
+			_build "out/Release" "${x}" "out/Release/${x}"
 		fi
 	done
 
 	# Even though ninja autodetects number of CPUs, we respect
 	# user's options, for debugging with -j 1 or any other reason.
-	eninja -C out/Release chrome chromedriver
-	use suid && eninja -C out/Release chrome_sandbox
-
-	pax-mark m out/Release/chrome
+	_build "out/Release" "chrome" "out/Release/chrome"
+	_build "out/Release" "chromedriver" ""
+	if use suid ; then
+		_build "out/Release" "chrome_sandbox" ""
+	fi
 
 	mv out/Release/chromedriver{.unstripped,} || die
+}
+
+_run_training_suite() {
+# See also https://github.com/chromium/chromium/blob/100.0.4896.75/docs/pgo.md
+# https://github.com/chromium/chromium/blob/100.0.4896.75/testing/buildbot/generate_buildbot_json.py
+# https://github.com/chromium/chromium/commit/8acfdce99c84fbc35ad259692ac083a9ea18392c
+# tools/perf/contrib/vr_benchmarks
+	export PYTHONPATH=$(_get_pythonpath)
+	einfo "PYTHONPATH=${PYTHONPATH}"
+	local benchmarks_allowed=()
+	# TODO add CONTRIB_BENCHMARKS
+	for x in ${OFFICIAL_BENCHMARKS[@]} ; do
+		t="${x}"
+		t="${t//-/_}"
+		t="${t//./_}"
+		t="${t,,}"
+		if use "cr_pgo_trainers_${t}" ; then
+			if [[ -d "${T}/${x}" ]] ; then
+				# Clear for different ABI builds
+				rm -vrf "${T}/${x}" || die
+			fi
+			benchmarks_allowed+=( ${x} )
+		fi
+	done
+	local benchmarks=$(echo "${benchmarks_allowed[@]}" | tr " " ",")
+	export CHROME_SANDBOX_ENV="${BUILD_DIR}/out/Release/chrome_sandbox" # For testing/test_env.py
+	export MESA_GLSL_CACHE_DIR="${HOME}/mesa_shader_cache" # \
+	  # Prevent a sandbox violation and isolate between parallel running emerges.
+	local display_args
+	if use headless ; then
+		display_args=()
+	elif use wayland ; then
+		display_args=(--xvfb --no-xvfb --use-weston)
+	else
+		display_args=(--xvfb)
+	fi
+	local run_benchmark_args=(
+		--assert-gpu-compositing
+		--browser=exact
+		--browser-executable="${BUILD_DIR}/out/Release/chrome")
+	local cmd=(vpython -cache-dir "${CIPD_CACHE_DIR}" bin/run_performance_test_suite
+		--benchmarks=${benchmarks}
+		--isolated-script-test-output="${T}/pgo-test-output.json"
+		${display_args[@]}
+		${run_benchmark_args[@]})
+	pushd out/Release || die
+		einfo "${cmd[@]}"
+		"${cmd[@]}" || die "${cmd[@]}"
+	popd
+}
+
+_gen_pgo_profile() {
+	pushd "${BUILD_DIR}/out/Release" || die
+		if ! ls *.profraw 2>/dev/null 1>/dev/null ; then
+			die "Missing *.profraw files"
+		fi
+		einfo "Merging PGO profile data to build PGO profile"
+		llvm-profdata merge *.profraw \
+			-o "${BUILD_DIR}/chrome/build/pgo_profiles/custom.profdata" \
+			|| die
+	popd
+}
+
+_start_pgo_training() {
+	_run_training_suite
+	_gen_pgo_profile
+}
+
+_update_licenses() {
+	# Upstream doesn't package PATENTS files
+	if [[ -n "${CHROMIUM_EBUILD_MAINTAINER}" \
+		&& -n "${GEN_ABOUT_CREDITS}" \
+		&& "${GEN_ABOUT_CREDITS}" == "1" ]] ; then
+		einfo "Generating license and copyright notice file"
+		eninja -C out/Release about_credits
+		# It should be updated when the major.minor.build.x changes
+		# because of new features.
+		local license_file_name="${PN}-"$(ver_cut 1-3 ${PV})".x"
+einfo
+einfo "Update the license file by doing the following:"
+einfo
+einfo "  \`cp -a ${BUILD_DIR}/out/Release/gen/components/resources/about_credits.html \
+${MY_OVERLAY_DIR}/licenses/${license_file_name}\`"
+einfo
+einfo "LICENSE_FINGERPRINT (with sha512sum) and LICENSE need to be updated also."
+einfo "When you are done updating, comment out GEN_ABOUT_CREDITS."
+einfo
+		die
+	fi
+}
+
+_clean_profraw() {
+	if [[ -d "${BUILD_DIR}/out/Release" ]] ; then
+		find "${BUILD_DIR}/out/Release" -name "*.profraw" -delete || die
+	fi
+}
+
+_get_pythonpath() {
+	local pp=(
+		"${BUILD_DIR}/third_party/catapult/common/py_utils"
+		"${BUILD_DIR}/third_party/catapult/telemetry/telemetry"
+		"${BUILD_DIR}/third_party/catapult/telemetry/third_party/png"
+		"${BUILD_DIR}/third_party/catapult/telemetry/third_party/pyfakefs"
+		"${BUILD_DIR}/third_party/catapult/third_party/typ"
+		"${BUILD_DIR}/third_party/catapult/tracing"
+		"${BUILD_DIR}/tools/perf"
+	)
+	echo $(echo "${pp}" | tr " " ":")
+}
+
+_init_cr_pgo_trainers_rasterize_and_record_micro_top_25() {
+	# No automated script for this found.
+	# It's better to snapshot free websites instead of personal data or nonfree ones.
+	local static_pages_interactive=(
+		"https://mail.google.com/mail/ gmail.html"
+		"https://www.google.com/calendar/ googlecalendar.html"
+		"https://www.google.com/search?q=cats&tbm=isch googleimagesearch.html"
+		"https://docs.google.com/document/d/1X-IKNjtEnx-WW5JIKRLsyhz5sbsat3mfTpAPUSX3_s4/view googledocs.html"
+		"https://plus.google.com/110031535020051778989/posts googleplus.html"
+		"http://www.youtube.com youtube.html"
+	)
+	local static_pages_non_interactive=(
+		"http://www.amazon.com amazon.html"
+		"http://googlewebmastercentral.blogspot.com/ blogger.html"
+		"http://booking.com booking.html"
+		"http://www.cnn.com cnn.html"
+		"http://www.ebay.com ebay.html"
+		"http://espn.go.com espn.html"
+		"https://www.facebook.com/barackobama facebook.html"
+		"https://www.google.com/search?q=barack+obama google.html"
+		"http://www.linkedin.com/in/linustorvalds linkedin.html"
+		"http://pinterest.com pinterest.html"
+		"http://techcrunch.com techcrunch.html"
+		"https://twitter.com/katyperry twitter.html"
+		"http://www.weather.com/weather/right-now/Mountain+View+CA+94043 weather.html"
+		"http://en.wikipedia.org/wiki/Wikipedia wikipedia.html"
+		"http://en.blog.wordpress.com/2012/09/04/freshly-pressed-editors-picks-for-august-2012/ wordpress.html"
+		"http://answers.yahoo.com yahooanswers.html"
+		"http://games.yahoo.com yahoogames.html"
+		"http://news.yahoo.com yahoonews.html"
+		"http://sports.yahoo.com/ yahoosports.html"
+	)
+	# Update sync both columns from
+	#   tools/perf/page_sets/static_top_25/README.md
+	#   tools/perf/page_sets/static_top_25_pages.py
+#	for entry in ${static_pages_interactive[@]} ; do
+		# Temporary disabled
+#		local url=$(cut -f 1 -d " ")
+#		local file=$(cut -f 2 -d " ")
+#		einfo "Fetching interactive static page for ${url}"
+#		${EPYTHON} "${BUILD_DIR}/third_party/catapult/telemetry/bin/snap_page" \
+#			--browser=system \
+#			--url="${url}" \
+#			--snapshot-path=${file} \
+#			--interactive || die
+#	done
+	for entry in ${static_pages_non_interactive[@]} ; do
+		local url=$(cut -f 1 -d " ")
+		local file=$(cut -f 2 -d " ")
+		einfo "Fetching static page for ${url}"
+		${EPYTHON} "${BUILD_DIR}/third_party/catapult/telemetry/bin/snap_page" \
+			--browser=system \
+			--url="${url}" \
+			--snapshot-path=${file} || die
+	done
+}
+
+_init_pgo_training() {
+	if use pgo-full ; then
+		export PYTHONPATH=$(_get_pythonpath)
+		einfo "PYTHONPATH=${PYTHONPATH}"
+		eninja -C out/Release bin/run_performance_test_suite
+		init_vpython
+		fetching_pgo_deps
+		if use cr_pgo_trainers_rasterize_and_record_micro_top_25 ; then
+			# This also applies to generic_trace.top25
+			_init_cr_pgo_trainers_rasterize_and_record_micro_top_25
+		fi
+	fi
+}
+
+multilib_src_compile() {
+	if (( ${NABIS} == 1 )) ; then
+		export BUILD_DIR="${S}"
+		cd "${BUILD_DIR}" || die
+	fi
+
+	# Final link uses lots of file descriptors.
+	ulimit -n 2048
+
+	# Calling this here supports resumption via FEATURES=keepwork
+	python_setup
+
+	# Don't inherit PYTHONPATH from environment, bug #789021, #812689
+	local -x PYTHONPATH=
+
+	#"${EPYTHON}" tools/clang/scripts/update.py --force-local-build --gcc-toolchain /usr --skip-checkout --use-system-cmake --without-android || die
+
+	if use pgo-full ; then
+		_clean_profraw
+		PGO_PHASE=1
+		_configure_pgx # pgi
+		_update_licenses
+		_init_pgo_training
+		_build_pgx
+		_start_pgo_training
+		PGO_PHASE=2
+		_configure_pgx # pgo
+		_build_pgx
+	else
+		_configure_pgx # pgo / no-pgo
+		_update_licenses
+		_build_pgx
+	fi
 
 	# Build manpage; bug #684550
 	sed -e 's|@@PACKAGE@@|chromium-browser|g;
@@ -894,9 +4287,7 @@ src_compile() {
 		out/Release/chromium-browser.1 || die
 
 	# Build desktop file; bug #706786
-	sed -e 's|@@MENUNAME@@|Chromium|g;
-		s|@@USR_BIN_SYMLINK_NAME@@|chromium-browser|g;
-		s|@@PACKAGE@@|chromium-browser|g;
+	sed -e 's|@@PACKAGE@@|chromium-browser|g;
 		s|\(^Exec=\)/usr/bin/|\1|g;' \
 		chrome/installer/linux/common/desktop.template > \
 		out/Release/chromium-browser-chromium.desktop || die
@@ -905,19 +4296,104 @@ src_compile() {
 	sed -e 's|${ICD_LIBRARY_PATH}|./libvk_swiftshader.so|g' \
 		third_party/swiftshader/src/Vulkan/vk_swiftshader_icd.json.tmpl > \
 		out/Release/vk_swiftshader_icd.json || die
+
+	local suffix
+	if (( ${NABIS} > 1 )) ; then
+		suffix=" (${ABI})"
+	fi
+	sed -i -e "s|@@MENUNAME@@|Chromium${suffix}|g" \
+		-e "s|@@USR_BIN_SYMLINK_NAME@@|chromium-browser-${ABI}|g" \
+		out/Release/chromium-browser-chromium.desktop || die
+}
+
+_install_header_license() {
+	local dir_path=$(dirname "${1}")
+	local file_name=$(basename "${1}")
+	local license_name="${2}"
+	local length="${3}"
+	d="${dir_path}"
+	dl="licenses/${d}"
+	docinto "${dl}"
+	mkdir -p "${T}/${dl}" || die
+	head -n ${length} "${S}/${d}/${file_name}" > \
+		"${T}/${dl}/${license_name}" || die
+	dodoc "${T}/${dl}/${license_name}"
+}
+
+_install_header_license_mid() {
+	local dir_path=$(dirname "${1}")
+	local file_name=$(basename "${1}")
+	local license_name="${2}"
+	local start="${3}"
+	local length="${4}"
+	d="${dir_path}"
+	dl="licenses/${d}"
+	docinto "${dl}"
+	mkdir -p "${T}/${dl}" || die
+	tail -n +${start} "${S}/${d}/${file_name}" \
+		| head -n ${length} > \
+		"${T}/${dl}/${license_name}" || die
+	dodoc "${T}/${dl}/${license_name}"
+}
+
+# @FUNCTION: _install_licenses
+# @DESCRIPTION:
+# Installs licenses and copyright notices from packages and other internal
+# packages.
+_install_licenses() {
+	[[ -f "${T}/.copied_licenses" ]] && return
+
+	einfo "Copying third party licenses and copyright notices"
+	export IFS=$'\n'
+	for f in $(find "${S}" \
+	  -iname "*licens*" -type f \
+	  -o -iname "*licenc*" \
+	  -o -iname "*copyright*" \
+	  -o -iname "*copying*" \
+	  -o -iname "*patent*" \
+	  -o -iname "ofl.txt" \
+	  -o -iname "*notice*" \
+	  -o -iname "*author*" \
+	  -o -iname "*CONTRIBUTORS*" \
+	  ) $(grep -i -G -l \
+		-e "copyright" \
+		-e "licens" \
+		-e "licenc" \
+		-e "warrant" \
+		$(find "${S}" -iname "*readme*")) ; \
+	do
+		if [[ -f "${f}" ]] ; then
+			d=$(dirname "${f}" | sed -e "s|^${S}||")
+		else
+			d=$(echo "${f}" | sed -e "s|^${S}||")
+		fi
+		docinto "licenses/${d}"
+		dodoc -r "${f}"
+	done
+	export IFS=$' \t\n'
+
+	# Place _install_header_license or _install_header_license_mid
+	# calls here.
+
+	touch "${T}/.copied_licenses"
 }
 
-src_install() {
+multilib_src_install() {
+	if (( ${NABIS} == 1 )) ; then
+		export BUILD_DIR="${S}"
+		cd "${BUILD_DIR}" || die
+	fi
+
 	local CHROMIUM_HOME="/usr/$(get_libdir)/chromium-browser"
 	exeinto "${CHROMIUM_HOME}"
 	doexe out/Release/chrome
 
-	if use suid; then
+	if use suid ; then
 		newexe out/Release/chrome_sandbox chrome-sandbox
 		fperms 4755 "${CHROMIUM_HOME}/chrome-sandbox"
 	fi
 
-	doexe out/Release/chromedriver
+	newexe out/Release/chromedriver chromedriver-${ABI}
 	doexe out/Release/chrome_crashpad_handler
 
 	ozone_auto_session () {
@@ -925,18 +4401,22 @@ src_install() {
 	}
 	local sedargs=( -e
 			"s:/usr/lib/:/usr/$(get_libdir)/:g;
+			s:chromium-browser-chromium.desktop:chromium-browser-chromium-${ABI}.desktop:g;
 			s:@@OZONE_AUTO_SESSION@@:$(ozone_auto_session):g"
 	)
 	sed "${sedargs[@]}" "${FILESDIR}/chromium-launcher-r7.sh" > chromium-launcher.sh || die
-	doexe chromium-launcher.sh
+	newexe chromium-launcher.sh chromium-launcher-${ABI}.sh
 
 	# It is important that we name the target "chromium-browser",
 	# xdg-utils expect it; bug #355517.
-	dosym "${CHROMIUM_HOME}/chromium-launcher.sh" /usr/bin/chromium-browser
+	dosym "${CHROMIUM_HOME}/chromium-launcher-${ABI}.sh" /usr/bin/chromium-browser-${ABI}
+	dosym "${CHROMIUM_HOME}/chromium-launcher-${ABI}.sh" /usr/bin/chromium-browser
 	# keep the old symlink around for consistency
-	dosym "${CHROMIUM_HOME}/chromium-launcher.sh" /usr/bin/chromium
+	dosym "${CHROMIUM_HOME}/chromium-launcher-${ABI}.sh" /usr/bin/chromium-${ABI}
+	dosym "${CHROMIUM_HOME}/chromium-launcher-${ABI}.sh" /usr/bin/chromium
 
-	dosym "${CHROMIUM_HOME}/chromedriver" /usr/bin/chromedriver
+	dosym "${CHROMIUM_HOME}/chromedriver-${ABI}" /usr/bin/chromedriver-${ABI}
+	dosym "${CHROMIUM_HOME}/chromedriver-${ABI}" /usr/bin/chromedriver
 
 	# Allow users to override command-line options, bug #357629.
 	insinto /etc/chromium
@@ -965,7 +4445,7 @@ src_install() {
 	# Install vk_swiftshader_icd.json; bug #827861
 	doins out/Release/vk_swiftshader_icd.json
 
-	if [[ -d out/Release/swiftshader ]]; then
+	if [[ -d out/Release/swiftshader ]] ; then
 		insinto "${CHROMIUM_HOME}/swiftshader"
 		doins out/Release/swiftshader/*.so
 	fi
@@ -982,7 +4462,7 @@ src_install() {
 	done
 
 	# Install desktop entry
-	domenu out/Release/chromium-browser-chromium.desktop
+	newmenu out/Release/chromium-browser-chromium.desktop chromium-browser-chromium-${ABI}.desktop
 
 	# Install GNOME default application entry (bug #303100).
 	insinto /usr/share/gnome-control-center/default-apps
@@ -993,6 +4473,11 @@ src_install() {
 	dosym chromium-browser.1 /usr/share/man/man1/chromium.1
 
 	readme.gentoo_create_doc
+
+	# This next pass will copy PATENTS files, *ThirdParty*, and NOTICE files
+	# and npm micropackages copyright notices and licenses which may not
+	# have been present in the listed the the .html (about:credits) file
+	_install_licenses
 }
 
 pkg_postrm() {
@@ -1006,15 +4491,84 @@ pkg_postinst() {
 	readme.gentoo_print_elog
 
 	if ! use headless; then
-		if use vaapi; then
-			elog "VA-API is disabled by default at runtime. You have to enable it"
-			elog "by adding --enable-features=VaapiVideoDecoder to CHROMIUM_FLAGS"
-			elog "in /etc/chromium/default."
+		if use vaapi ; then
+			# It says 3 args:  https://github.com/chromium/chromium/blob/100.0.4896.75/docs/gpu/vaapi.md#vaapi-on-linux
+			elog "VA-API is disabled by default at runtime.  You have to enable it"
+			elog "by adding --enable-features=VaapiVideoDecoder --ignore-gpu-blocklist"
+			elog "--use-gl=desktop or --use-gl=egl to the CHROMIUM_FLAGS in"
+			elog "/etc/chromium/default."
+
+			if has_version "x11-libs/libva-intel-driver" ; then
+				ewarn
+				ewarn "x11-libs/libva-intel-driver is the older vaapi driver but intended for"
+				ewarn "select hardware.  See also x11-libs/libva-intel-media-driver package"
+				ewarn "to access more VA-API accelerated encoders if driver support overlaps."
+				ewarn
+			fi
+
+			if use video_cards_intel || use video_cards_i965 || use video_cards_iris ; then
+				einfo
+				einfo "Intel Quick Sync Video is required for hardware accelerated H.264 VA-API"
+				einfo "encode."
+				einfo
+				einfo "For hardware support, see the AVC row at"
+				einfo "https://en.wikipedia.org/wiki/Intel_Quick_Sync_Video#Hardware_decoding_and_encoding"
+				einfo
+				einfo "Driver ebuild packages for their corresponding hardware can be found at:"
+				einfo
+				einfo "x11-libs/libva-intel-driver:"
+				einfo "https://github.com/intel/intel-vaapi-driver/blob/master/README"
+				einfo
+				einfo "x11-libs/libva-intel-media-driver:"
+				einfo "https://github.com/intel/media-driver#decodingencoding-features"
+				einfo
+			fi
+			if use video_cards_amdgpu \
+				|| use video_cards_r600 \
+				|| use video_cards_radeonsi ; then
+				einfo
+				einfo "You need VCE (Video Code Engine) or VCN (Video Core Next) for"
+				einfo "hardware accelerated H.264 VA-API encode."
+				einfo
+				einfo "For details see https://en.wikipedia.org/wiki/Video_Coding_Engine#Feature_overview"
+				einfo "or https://www.x.org/wiki/RadeonFeature/"
+				einfo
+				einfo "The r600 driver only supports ARUBA for VCE encode."
+				einfo "For newer hardware, try a newer free driver like"
+				einfo "the radeonsi driver or closed drivers."
+				einfo
+			fi
+			if use video_cards_nouveau ; then
+				einfo
+				einfo "For details see, https://nouveau.freedesktop.org/VideoAcceleration.html"
+				einfo "Reconsider using the official driver instead."
+				einfo
+			fi
+			einfo
+			einfo "Some drivers may require firmware for proper VA-API support."
+			einfo
+			einfo "The user must be part of the video group to use VA-API support."
+			# Because it touches /dev/dri/renderD128
+			einfo
+			einfo "The LIBVA_DRIVER_NAME envvar may need to be changed if both open"
+			einfo "and closed drivers are installed to one of the following"
+			einfo
+			has_version "x11-libs/libva-intel-driver" \
+				&& einfo "  LIBVA_DRIVER_NAME=\"i965\""
+			has_version "x11-libs/libva-intel-media-driver" \
+				&& einfo "  LIBVA_DRIVER_NAME=\"iHD\""
+			use video_cards_r600 \
+				&& einfo "  LIBVA_DRIVER_NAME=\"r600\""
+			( use video_cards_radeonsi || use video_cards_amdgpu ) \
+				&& einfo "  LIBVA_DRIVER_NAME=\"radeonsi\""
+			einfo
+			einfo "to your ~/.bashrc or ~/.xinitrc and relogging."
+			einfo
 		fi
-		if use screencast; then
+		if use screencast ; then
 			elog "Screencast is disabled by default at runtime. Either enable it"
 			elog "by navigating to chrome://flags/#enable-webrtc-pipewire-capturer"
-			elog "inside Chromium or add --enable-features=WebRTCPipeWireCapturer"
+			elog "inside Chromium or add --enable-webrtc-pipewire-capturer"
 			elog "to CHROMIUM_FLAGS in /etc/chromium/default."
 		fi
 		if use gtk4; then
@@ -1023,4 +4577,17 @@ pkg_postinst() {
 			elog "to CHROMIUM_FLAGS in /etc/chromium/default."
 		fi
 	fi
+
+	einfo
+	einfo "By default, the /usr/bin/chromium and /usr/bin/chromedriver symlinks are"
+	einfo "set to the last ABI installed.  You must change it manually if you want"
+	einfo "to run on a different default ABI."
+	einfo
+	einfo "Examples:"
+	einfo
+	einfo "  ln -sf /usr/lib64/chromium-browser/chromium-launcher-${ABI}.sh /usr/bin/chromium"
+	einfo "  ln -sf /usr/lib/chromium-browser/chromium-launcher-${ABI}.sh /usr/bin/chromium"
+	einfo "  ln -sf /usr/lib32/chromium-browser/chromium-launcher-${ABI}.sh /usr/bin/chromium"
+	einfo "  ln -sf /usr/lib32/chromium-browser/chromedriver-${ABI} /usr/bin/chromedriver"
+	einfo
 }
