Patch Status: Work In Progress / Incomplete
Patch Author: Orson Teodoro <orsonteodoro@hotmail.com>
Date: Jul 2, 2020
TODOs:
setkey tresor-xts for dmcrypt
----
diff -urp linux-5.4.49-ot.orig/arch/x86/crypto/tresor_asm.S linux-5.4.49-ot/arch/x86/crypto/tresor_asm.S
--- linux-5.4.49-ot.orig/arch/x86/crypto/tresor_asm.S	2020-07-02 18:29:35.570382073 -0700
+++ linux-5.4.49-ot/arch/x86/crypto/tresor_asm.S	2020-07-02 18:42:12.300885203 -0700
@@ -48,6 +48,12 @@
 .set	db2,	%db2		/* round key 1a */
 .set	db3,	%db3		/* round key 1b */
 
+/* 32-bit values storing parts of the tweak key for xts */
+.set	db4,	%db4		/* tweak key 0a */
+.set	db5,	%db5		/* tweak key 0b */
+.set	db6,	%db6		/* tweak key 1a */
+.set	db7,	%db7		/* tweak key 1b */
+
 /* 32-bit GPR registers */
 .set	eax,	%eax
 .set	ebx,	%ebx
@@ -518,6 +524,8 @@ rc_tab:	.long	0x00000001, 0x00000002, 0x
 	.global		tresor_set_key
 	.global		tresor_encblk_128
 	.global		tresor_decblk_128
+	.global		tresor_set_key_xts_tweak_128
+	.global		tresor_encblk_128_xts_tweak
 	.extern		crypto_ft_tab
 	.extern		crypto_fl_tab
 	.extern		crypto_it_tab
@@ -560,6 +568,24 @@ tresor_decblk_128:
 	i_lround	rk1
 	epilog
 
+/* void tresor_encblk_128_xts_tweak(u8 *out, const u8 *in) */
+tresor_encblk_128_xts_tweak:
+	prolog 
+	dbg_to_sse	db4,db5,db6,db7,rk1
+	pxor		rk1,rstate
+	key_schedule
+	f_nround	rk1
+	f_nround	rk2
+	f_nround	rk3
+	f_nround	rk4
+	f_nround	rk5
+	f_nround_	rk6a,rk6b,rk5
+	f_nround_	rk7a,rk7b,rk5
+	f_nround_	rk8a,rk8b,rk5
+	f_nround_	rk9a,rk9b,rk5
+	f_lround	rk10
+	epilog
+
 /* void tresor_set_key(const u8 *in_key) */
 tresor_set_key:
 #if __x86_64__
@@ -584,3 +610,28 @@ tresor_set_key:
 #endif
 	xorl		eax, eax
 	ret
+
+/* void tresor_set_key_xts_tweak_128(const u8 *in_key) */
+tresor_set_key_xts_tweak_128:
+#if __x86_64__
+	movl		0(rdi),eax
+	movq		rax,db4
+	movl		4(rdi),eax
+	movq		rax,db5
+	movl		8(rdi),eax
+	movq		rax,db6
+	movl		12(rdi),eax
+	movq		rax,db7
+#else
+	movl		4(esp),edx
+	movl		0(edx),eax
+	movl		eax,db4
+	movl		4(edx),eax
+	movl		eax,db5
+	movl		8(edx),eax
+	movl		eax,db6
+	movl		12(edx),eax
+	movl		eax,db7
+#endif
+	xorl		eax, eax
+	ret
diff -urp linux-5.4.49-ot.orig/arch/x86/crypto/tresor_glue.c linux-5.4.49-ot/arch/x86/crypto/tresor_glue.c
--- linux-5.4.49-ot.orig/arch/x86/crypto/tresor_glue.c	2020-07-02 18:29:35.523380239 -0700
+++ linux-5.4.49-ot/arch/x86/crypto/tresor_glue.c	2020-07-02 18:54:19.454671317 -0700
@@ -5,6 +5,26 @@
  * Copyright (C) 2012	Hans Spath <tresor@hans-spath.de>
  * Copyright (C) 2012	Johannes Goetzfried <johannes@jgoetzfried.de>
  *
+ * Portions use skcipher cbc_, ecb_, ctr_ code from crypto/cast5_avx_glue.c by:
+ *   Copyright (C) 2012 Johannes Goetzfried
+ *       <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>
+ *   Copyright © 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>
+ *
+ * Portions use aesni_init and aesni_skciphers code from crypto/aesni-intel_glue.c by:
+ *   Copyright (C) 2008, Intel Corp.
+ *      Author: Huang Ying <ying.huang@intel.com>
+ *
+ * Portions use xts glue code from crypto/cast6_avx_glue.c
+ *   Copyright (C) 2012 Johannes Goetzfried
+ *       <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>
+ *   Copyright © 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>
+ *
+ * CBC & ECB parts based on code (crypto/cbc.c,ecb.c) by:
+ *   Copyright (c) 2006 Herbert Xu <herbert@gondor.apana.org.au>
+ *
+ * CTR part based on code (crypto/ctr.c) by:
+ *   (C) Copyright IBM Corp. 2007 - Joy Latten <latten@us.ibm.com>
+ *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
@@ -17,10 +37,17 @@
  * You should have received a copy of the GNU General Public License along with
  * this program; if not, write to the Free Software Foundation, Inc., 59 Temple
  * Place - Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * Portions include skcipher updates by Eric Biggers <ebiggers@google.com> and
+ * Herbert Xu <herbert@gondor.apana.org.au>.
  */
 
+#include <asm/crypto/glue_helper.h>
 #include <crypto/algapi.h>
+#include <crypto/b128ops.h>
+#include <crypto/internal/simd.h>
 #include <crypto/tresor.h>
+#include <crypto/xts.h>
 #include <linux/module.h>
 #include <crypto/aes.h>
 #include <linux/smp.h>
@@ -30,8 +57,10 @@
  * Assembly functions implemented in tresor-intel_asm.S
  */
 asmlinkage void tresor_set_key(const u8 *in_key);
+asmlinkage void tresor_set_key_xts_tweak_128(const u8 *in_key);
 asmlinkage void tresor_encblk_128(u8 *out, const u8 *in);
 asmlinkage void tresor_decblk_128(u8 *out, const u8 *in);
+asmlinkage void tresor_encblk_128_xts_tweak(u8 *out, const u8 *in);
 
 
 
@@ -117,6 +146,328 @@ void tresor_setkey(const u8 *in_key)
 	on_each_cpu(tresor_setkey_current_cpu, (void *)in_key, 1);
 }
 
+/*
+ * Set XTS tweak key
+ */
+static void tresor_setkey_xts_tweak_current_cpu(void *data)
+{
+	printk(KERN_DEBUG "TRESOR: %s running on cpu %d\n",
+		__func__, smp_processor_id());
+	tresor_set_key_xts_tweak_128((const u8 *)data);
+}
+
+void tresor_setkey_xts_tweak(const u8 *in_key)
+{
+	on_each_cpu(tresor_setkey_xts_tweak_current_cpu, (void *)in_key, 1);
+}
+
+static int tresor_skcipher_setkey(struct crypto_skcipher *tfm, const u8 *key, unsigned int keylen)
+{
+	tresor_setdummykey(crypto_skcipher_tfm(tfm), key, keylen);
+	return 0;
+}
+
+static int ecb_crypt(struct skcipher_request *req, bool enc)
+{
+	struct skcipher_walk walk;
+	const unsigned int bsize = AES_BLOCK_SIZE;
+	unsigned int nbytes;
+	void (*fn)(u8 *dst, const u8 *src);
+	int err;
+	unsigned long irq_flags;
+
+	err = skcipher_walk_virt(&walk, req, true);
+
+	fn = (enc) ? tresor_encblk_128 : tresor_decblk_128;
+
+	tresor_prolog(&irq_flags);
+	while ((nbytes = walk.nbytes)) {
+		u8 *wsrc = walk.src.virt.addr;
+		u8 *wdst = walk.dst.virt.addr;
+
+		fn = (enc) ? tresor_encblk_128 : tresor_decblk_128;
+
+		/* Handle leftovers */
+		do {
+			fn(wdst, wsrc);
+
+			wsrc += bsize;
+			wdst += bsize;
+			nbytes -= bsize;
+		} while (nbytes >= bsize);
+
+		err = skcipher_walk_done(&walk, nbytes);
+	}
+	tresor_epilog(&irq_flags);
+
+	return err;
+}
+
+static int ecb_encrypt(struct skcipher_request *req)
+{
+	return ecb_crypt(req, true);
+}
+
+static int ecb_decrypt(struct skcipher_request *req)
+{
+	return ecb_crypt(req, false);
+}
+
+
+static int cbc_encrypt(struct skcipher_request *req)
+{
+	const unsigned int bsize = AES_BLOCK_SIZE;
+	struct skcipher_walk walk;
+	unsigned int nbytes;
+	int err;
+
+	err = skcipher_walk_virt(&walk, req, false);
+
+	while ((nbytes = walk.nbytes)) {
+		u64 *src = (u64 *)walk.src.virt.addr;
+		u64 *dst = (u64 *)walk.dst.virt.addr;
+		u64 *iv = (u64 *)walk.iv;
+
+		do {
+			*dst = *src ^ *iv;
+			tresor_encblk_128((u8 *)dst, (u8 *)dst);
+			iv = dst;
+			src++;
+			dst++;
+			nbytes -= bsize;
+		} while (nbytes >= bsize);
+
+		*(u64 *)walk.iv = *iv;
+		err = skcipher_walk_done(&walk, nbytes);
+	}
+
+	return err;
+}
+
+static unsigned int __cbc_decrypt(struct crypto_aes_ctx *ctx,
+				  struct skcipher_walk *walk)
+{
+	const unsigned int bsize = AES_BLOCK_SIZE;
+	unsigned int nbytes = walk->nbytes;
+	u64 *src = (u64 *)walk->src.virt.addr;
+	u64 *dst = (u64 *)walk->dst.virt.addr;
+	u64 last_iv;
+
+	/* Start of the last block. */
+	src += nbytes / bsize - 1;
+	dst += nbytes / bsize - 1;
+
+	last_iv = *src;
+
+	/* Handle leftovers */
+	for (;;) {
+		tresor_decblk_128((u8 *)dst, (u8 *)src);
+
+		nbytes -= bsize;
+		if (nbytes < bsize)
+			break;
+
+		*dst ^= *(src - 1);
+		src -= 1;
+		dst -= 1;
+	}
+
+	*dst ^= *(u64 *)walk->iv;
+	*(u64 *)walk->iv = last_iv;
+
+	return nbytes;
+}
+
+static int cbc_decrypt(struct skcipher_request *req)
+{
+	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+	struct crypto_aes_ctx *ctx = crypto_skcipher_ctx(tfm);
+	struct skcipher_walk walk;
+	unsigned int nbytes;
+	int err;
+	unsigned long irq_flags;
+
+	err = skcipher_walk_virt(&walk, req, false);
+
+	tresor_prolog(&irq_flags);
+	while ((nbytes = walk.nbytes)) {
+		nbytes = __cbc_decrypt(ctx, &walk);
+		err = skcipher_walk_done(&walk, nbytes);
+	}
+	tresor_epilog(&irq_flags);
+	return err;
+}
+
+static void ctr_crypt_final(struct skcipher_walk *walk, struct crypto_aes_ctx *ctx)
+{
+	u8 *ctrblk = walk->iv;
+	u8 keystream[AES_BLOCK_SIZE];
+	u8 *src = walk->src.virt.addr;
+	u8 *dst = walk->dst.virt.addr;
+	unsigned int nbytes = walk->nbytes;
+
+	tresor_encblk_128(keystream, ctrblk);
+	crypto_xor_cpy(dst, keystream, src, nbytes);
+
+	crypto_inc(ctrblk, AES_BLOCK_SIZE);
+}
+
+static unsigned int __ctr_crypt(struct skcipher_walk *walk,
+				struct crypto_aes_ctx *ctx)
+{
+	const unsigned int bsize = AES_BLOCK_SIZE;
+	unsigned int nbytes = walk->nbytes;
+	u64 *src = (u64 *)walk->src.virt.addr;
+	u64 *dst = (u64 *)walk->dst.virt.addr;
+
+	/* Handle leftovers */
+	do {
+		u64 ctrblk;
+
+		if (dst != src)
+			*dst = *src;
+
+		ctrblk = *(u64 *)walk->iv;
+		be64_add_cpu((__be64 *)walk->iv, 1);
+
+		tresor_encblk_128((u8 *)&ctrblk, (u8 *)&ctrblk);
+		*dst ^= ctrblk;
+
+		src += 1;
+		dst += 1;
+		nbytes -= bsize;
+	} while (nbytes >= bsize);
+
+	return nbytes;
+}
+
+static int ctr_crypt(struct skcipher_request *req)
+{
+	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+	struct crypto_aes_ctx *ctx = crypto_skcipher_ctx(tfm);
+	struct skcipher_walk walk;
+	unsigned int nbytes;
+	int err;
+	unsigned long irq_flags;
+
+	err = skcipher_walk_virt(&walk, req, false);
+
+	tresor_prolog(&irq_flags);
+	while ((nbytes = walk.nbytes) >= AES_BLOCK_SIZE) {
+		nbytes = __ctr_crypt(&walk, ctx);
+		err = skcipher_walk_done(&walk, nbytes);
+	}
+	tresor_epilog(&irq_flags);
+
+	if (walk.nbytes) {
+		ctr_crypt_final(&walk, ctx);
+		err = skcipher_walk_done(&walk, 0);
+	}
+
+	return err;
+}
+
+void __tresor_encrypt(struct tresor_ctx *ctx, u8 *dst, const u8 *src) {
+	unsigned long irq_flags;
+
+	/* encrypt using the cipher key */
+	tresor_prolog(&irq_flags);
+	tresor_encblk_128(dst, src);
+	tresor_epilog(&irq_flags);
+}
+
+void __tresor_decrypt(struct tresor_ctx *ctx, u8 *dst, const u8 *src) {
+	unsigned long irq_flags;
+
+	/* decrypt using the cipher key */
+	tresor_prolog(&irq_flags);
+	tresor_decblk_128(dst, src);
+	tresor_epilog(&irq_flags);
+}
+
+void __xts_tweak_tresor_encrypt(struct tresor_ctx *ctx, u8 *dst, const u8 *src) {
+	unsigned long irq_flags;
+
+	/* encrypt using the tweak key */
+	tresor_prolog(&irq_flags);
+	tresor_encblk_128_xts_tweak(dst, src);
+	tresor_epilog(&irq_flags);
+}
+
+struct tresor_xts_ctx {
+	struct tresor_ctx crypt_ctx;
+	struct tresor_ctx tweak_ctx;
+};
+
+static int xts_tresor_setkey(struct crypto_skcipher *tfm, const u8 *key,
+			    unsigned int keylen)
+{
+	int err;
+
+	err = xts_verify_key(tfm, key, keylen);
+	if (err)
+		return err;
+
+	keylen /= 2;
+
+	if (keylen != AES_KEYSIZE_128)
+		return -EINVAL;
+
+	/* Same reason explained in tresor_setdummykey comment */
+	return 0;
+}
+
+static void tresor_xts_enc(void *ctx, u128 *dst, const u128 *src, le128 *iv)
+{
+	glue_xts_crypt_128bit_one(ctx, dst, src, iv,
+				  GLUE_FUNC_CAST(__tresor_encrypt));
+}
+
+static void tresor_xts_dec(void *ctx, u128 *dst, const u128 *src, le128 *iv)
+{
+	glue_xts_crypt_128bit_one(ctx, dst, src, iv,
+				  GLUE_FUNC_CAST(__tresor_decrypt));
+}
+
+static const struct common_glue_ctx tresor_enc_xts = {
+	.num_funcs = 1,
+	.fpu_blocks_limit = 1,
+
+	.funcs = { {
+		.num_blocks = 1,
+		.fn_u = { .xts = GLUE_XTS_FUNC_CAST(tresor_xts_enc) }
+	} }
+};
+
+static const struct common_glue_ctx tresor_dec_xts = {
+	.num_funcs = 1,
+	.fpu_blocks_limit = 1,
+
+	.funcs = { {
+		.num_blocks = 1,
+		.fn_u = { .xts = GLUE_XTS_FUNC_CAST(tresor_xts_dec) }
+	} }
+};
+
+static int xts_encrypt(struct skcipher_request *req)
+{
+	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+	struct tresor_xts_ctx *ctx = crypto_skcipher_ctx(tfm);
+
+	return glue_xts_req_128bit(&tresor_enc_xts, req,
+				   XTS_TWEAK_CAST(__xts_tweak_tresor_encrypt),
+				   &ctx->tweak_ctx, &ctx->crypt_ctx, false);
+}
+
+static int xts_decrypt(struct skcipher_request *req)
+{
+	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+	struct tresor_xts_ctx *ctx = crypto_skcipher_ctx(tfm);
+
+	return glue_xts_req_128bit(&tresor_dec_xts, req,
+				   XTS_TWEAK_CAST(__xts_tweak_tresor_encrypt),
+				   &ctx->tweak_ctx, &ctx->crypt_ctx, true);
+}
 
 /*
  * Crypto API algorithm
@@ -142,12 +493,96 @@ static struct crypto_alg tresor_alg = {
 	}
 };
 
+static struct skcipher_alg tresor_skciphers[] = {
+	{
+		.base = {
+			.cra_name		= "__ecb(tresor)",
+			.cra_driver_name	= "__ecb-tresor-sse2",
+			.cra_priority		= 400,
+			.cra_flags		= CRYPTO_ALG_INTERNAL,
+			.cra_blocksize		= AES_BLOCK_SIZE,
+			.cra_ctxsize		= sizeof(struct crypto_aes_ctx),
+			.cra_module		= THIS_MODULE,
+		},
+		.min_keysize	= AES_MIN_KEY_SIZE,
+		.max_keysize	= AES_MIN_KEY_SIZE,
+		.setkey		= tresor_skcipher_setkey,
+		.encrypt	= ecb_encrypt,
+		.decrypt	= ecb_decrypt,
+	}, {
+		.base = {
+			.cra_name		= "__cbc(tresor)",
+			.cra_driver_name	= "__cbc-tresor-sse2",
+			.cra_priority		= 400,
+			.cra_flags		= CRYPTO_ALG_INTERNAL,
+			.cra_blocksize		= AES_BLOCK_SIZE,
+			.cra_ctxsize		= sizeof(struct crypto_aes_ctx),
+			.cra_module		= THIS_MODULE,
+		},
+		.min_keysize	= AES_MIN_KEY_SIZE,
+		.max_keysize	= AES_MIN_KEY_SIZE,
+		.ivsize		= AES_BLOCK_SIZE,
+		.setkey		= tresor_skcipher_setkey,
+		.encrypt	= cbc_encrypt,
+		.decrypt	= cbc_decrypt,
+#ifdef CONFIG_X86_64
+	}, {
+		.base = {
+			.cra_name		= "__ctr(tresor)",
+			.cra_driver_name	= "__ctr-tresor-sse2",
+			.cra_priority		= 400,
+			.cra_flags		= CRYPTO_ALG_INTERNAL,
+			.cra_blocksize		= 1,
+			.cra_ctxsize		= sizeof(struct crypto_aes_ctx),
+			.cra_module		= THIS_MODULE,
+		},
+		.min_keysize	= AES_MIN_KEY_SIZE,
+		.max_keysize	= AES_MIN_KEY_SIZE,
+		.ivsize		= AES_BLOCK_SIZE,
+		.chunksize	= AES_BLOCK_SIZE,
+		.setkey		= tresor_skcipher_setkey,
+		.encrypt	= ctr_crypt,
+		.decrypt	= ctr_crypt,
+	}, {
+		.base = {
+			.cra_name		= "__xts(aes)",
+			.cra_driver_name	= "__xts-tresor-sse2",
+			.cra_priority		= 401,
+			.cra_flags		= CRYPTO_ALG_INTERNAL,
+			.cra_blocksize		= AES_BLOCK_SIZE,
+			.cra_ctxsize		= sizeof(struct tresor_xts_ctx),
+			.cra_module		= THIS_MODULE,
+		},
+		.min_keysize	= 2 * AES_MIN_KEY_SIZE,
+		.max_keysize	= 2 * AES_MIN_KEY_SIZE,
+		.ivsize		= AES_BLOCK_SIZE,
+		.setkey		= xts_tresor_setkey,
+		.encrypt	= xts_encrypt,
+		.decrypt	= xts_decrypt,
+#endif
+	}
+};
+
+static struct simd_skcipher_alg *tresor_simd_skciphers[ARRAY_SIZE(tresor_skciphers)];
 
 /* Initialize module */
 static int __init tresor_init(void)
 {
 	int retval;
 	retval = crypto_register_alg(&tresor_alg);
+	if (retval)
+		return retval;
+
+	retval = simd_register_skciphers_compat(tresor_skciphers,
+					     ARRAY_SIZE(tresor_skciphers),
+					     tresor_simd_skciphers);
+	if (retval)
+		goto unregister_cipher;
+
+	return 0;
+
+unregister_cipher:
+	crypto_unregister_alg(&tresor_alg);
 	return retval;
 }
 module_init(tresor_init);
@@ -156,6 +591,8 @@ module_init(tresor_init);
 /* Remove module */
 static void __exit tresor_fini(void)
 {
+	simd_unregister_skciphers(tresor_skciphers, ARRAY_SIZE(tresor_skciphers),
+				  tresor_simd_skciphers);
 	crypto_unregister_alg(&tresor_alg);
 }
 module_exit(tresor_fini);
Only in linux-5.4.49-ot/arch/x86/crypto: tresor_glue.c.orig
diff -urp linux-5.4.49-ot.orig/crypto/testmgr.c linux-5.4.49-ot/crypto/testmgr.c
--- linux-5.4.49-ot.orig/crypto/testmgr.c	2020-07-02 18:29:35.616383867 -0700
+++ linux-5.4.49-ot/crypto/testmgr.c	2020-07-02 18:42:12.302885281 -0700
@@ -2500,8 +2500,11 @@ static int test_skcipher_vec_cfg(const c
 		crypto_skcipher_clear_flags(tfm,
 					    CRYPTO_TFM_REQ_FORBID_WEAK_KEYS);
 #ifdef CONFIG_CRYPTO_TRESOR
-	if (strstr(driver, "tresor"))
+	if (strstr(driver, "tresor")) {
 		tresor_setkey(vec->key);
+		if (strstr(driver, "xts"))
+			tresor_setkey_xts_tweak(vec->key + tfm->keysize/2);
+	}
 #endif
 	err = crypto_skcipher_setkey(tfm, vec->key, vec->klen);
 	if (err) {
diff -urp linux-5.4.49-ot.orig/include/crypto/tresor.h linux-5.4.49-ot/include/crypto/tresor.h
--- linux-5.4.49-ot.orig/include/crypto/tresor.h	2020-07-02 18:29:35.536380746 -0700
+++ linux-5.4.49-ot/include/crypto/tresor.h	2020-07-02 18:42:12.302885281 -0700
@@ -10,10 +10,15 @@
 /* number of chars to clear memory */
 #define TRESOR_RANDOM_CHARS 4096
 
+struct tresor_ctx {
+	int dummy;
+};
+
 /* TRESOR core functionality (enc, dec, setkey) */
 void tresor_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src);
 void tresor_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src);
 void tresor_setkey(const u8 *in_key);
+void tresor_setkey_xts_tweak(const u8 *in_key);
 bool tresor_capable(void);
 
 #ifdef CONFIG_CRYPTO_TRESOR_PROMPT
