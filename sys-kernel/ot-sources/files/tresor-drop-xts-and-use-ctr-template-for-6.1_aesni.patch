--- a/arch/x86/crypto/tresor_glue.c.orig	2024-02-04 20:20:06.926376469 -0800
+++ b/arch/x86/crypto/tresor_glue.c	2024-02-04 20:23:37.019442335 -0800
@@ -9,11 +9,6 @@
  *   Copyright (C) 2008, Intel Corp.
  *      Author: Huang Ying <ying.huang@intel.com>
  *
- * Portions use xts glue code from crypto/cast6_avx_glue.c
- *   Copyright (C) 2012 Johannes Goetzfried
- *       <Johannes.Goetzfried@informatik.stud.uni-erlangen.de>
- *   Copyright Â© 2013 Jussi Kivilinna <jussi.kivilinna@iki.fi>
- *
  * This program is free software; you can redistribute it and/or modify it
  * under the terms and conditions of the GNU General Public License,
  * version 2, as published by the Free Software Foundation.
@@ -40,8 +35,9 @@
 #include <crypto/algapi.h>
 #include <crypto/b128ops.h>
 #include <crypto/internal/simd.h>
+#include <crypto/internal/skcipher.h>
+#include <crypto/skcipher.h>
 #include <crypto/tresor.h>
-#include <crypto/xts.h>
 #include <linux/module.h>
 #include <crypto/aes.h>
 #include <linux/smp.h>
@@ -52,7 +48,6 @@
 #include <crypto/gf128mul.h>
 #include <crypto/internal/skcipher.h>
 #include <crypto/scatterwalk.h>
-#include <crypto/xts.h>
 // END From glue_helper.c
 
 #include "ecb_cbc_helpers.h"
@@ -62,14 +57,12 @@
  */
 asmlinkage bool tresor_capable(void);
 asmlinkage void tresor_set_key(const u8 *in_key);
-asmlinkage void tresor_set_key_xts_tweak_128(const u8 *in_key);
 asmlinkage void tresor_encblk_128(u8 *out, const u8 *in);
 asmlinkage void tresor_decblk_128(u8 *out, const u8 *in);
 asmlinkage void tresor_encblk_192(u8 *out, const u8 *in);
 asmlinkage void tresor_decblk_192(u8 *out, const u8 *in);
 asmlinkage void tresor_encblk_256(u8 *out, const u8 *in);
 asmlinkage void tresor_decblk_256(u8 *out, const u8 *in);
-asmlinkage void tresor_encblk_128_xts_tweak(u8 *out, const u8 *in);
 
 
 
@@ -190,21 +183,6 @@ void tresor_setkey(const u8 *in_key)
 	on_each_cpu(tresor_setkey_current_cpu, (void *)in_key, 1);
 }
 
-/*
- * Set XTS tweak key
- */
-static void tresor_setkey_xts_tweak_current_cpu(void *data)
-{
-	printk(KERN_DEBUG "TRESOR: %s running on cpu %d\n",
-		__func__, smp_processor_id());
-	tresor_set_key_xts_tweak_128((const u8 *)data);
-}
-
-void tresor_setkey_xts_tweak(const u8 *in_key)
-{
-	on_each_cpu(tresor_setkey_xts_tweak_current_cpu, (void *)in_key, 1);
-}
-
 static int tresor_skcipher_setkey(struct crypto_skcipher *tfm, const u8 *key, unsigned int keylen)
 {
 	tresor_setdummykey(crypto_skcipher_tfm(tfm), key, keylen);
@@ -240,57 +218,6 @@ static int cbc_decrypt(struct skcipher_r
 	CBC_WALK_END();
 }
 
-void __xts_tresor_encrypt(const void *ctx, u8 *dst, const u8 *src) {
-	/* encrypt using the cipher key */
-	__tresor_encrypt(AES_KEYSIZE_128, dst, src);
-}
-
-void __xts_tresor_decrypt(const void *ctx, u8 *dst, const u8 *src) {
-	/* decrypt using the cipher key */
-	__tresor_decrypt(AES_KEYSIZE_128, dst, src);
-}
-
-void __xts_tweak_tresor_encrypt(const void *ctx, u8 *dst, const u8 *src) {
-	unsigned long irq_flags;
-	/* encrypt using the tweak key */
-	tresor_prolog(&irq_flags);
-	tresor_encblk_128_xts_tweak(dst, src);
-	tresor_epilog(&irq_flags);
-}
-
-struct tresor_xts_ctx {
-	struct tresor_ctx crypt_ctx;
-	struct tresor_ctx tweak_ctx;
-};
-
-static int xts_tresor_setkey(struct crypto_skcipher *tfm, const u8 *key,
-			    unsigned int keylen)
-{
-	struct tresor_xts_ctx *ctx = crypto_skcipher_ctx(tfm);
-	int err;
-
-	keylen /= 2;
-
-	/* Limited hardware breakpoint address registers limits us to 128-bit */
-	if (keylen != AES_KEYSIZE_128)
-		return -EINVAL;
-
-	// Comparison can only happen in assembly
-	//err = xts_verify_key(tfm, key, keylen*2);
-	//if (err)
-	//	return err;
-	tresor_setkey_xts_tweak(key + keylen);
-
-	ctx->crypt_ctx.key_length = keylen;
-	ctx->tweak_ctx.key_length = keylen;
-
-	/* Same reason explained in tresor_setdummykey comment */
-	return 0;
-}
-
-static void tresor_xts_enc(const void *ctx, u8 *dst, const u8 *src, le128 *iv);
-static void tresor_xts_dec(const void *ctx, u8 *dst, const u8 *src, le128 *iv);
-
 // From glue_helper.h
 static inline bool glue_fpu_begin(unsigned int bsize, int fpu_blocks_limit,
 				  struct skcipher_walk *walk,
@@ -322,195 +249,6 @@ static inline void glue_fpu_end(bool fpu
 		kernel_fpu_end();
 }
 
-// From glue_helper.c with changes
-static unsigned int __glue_xts_req_128bit(void *ctx,
-					  struct skcipher_walk *walk,
-					  bool decrypt)
-{
-	const unsigned int bsize = 128 / 8;
-	unsigned int nbytes = walk->nbytes;
-	u128 *src = walk->src.virt.addr;
-	u128 *dst = walk->dst.virt.addr;
-	unsigned int func_bytes;
-
-	func_bytes = bsize;
-
-	if (nbytes >= func_bytes) {
-		do {
-			if (decrypt)
-				tresor_xts_enc(ctx, (u8 *)dst,
-							(const u8 *)src,
-							walk->iv);
-			else
-				tresor_xts_dec(ctx, (u8 *)dst,
-							(const u8 *)src,
-							walk->iv);
-
-			src += 1; /* num_blocks */
-			dst += 1; /* num_blocks */
-			nbytes -= func_bytes;
-		} while (nbytes >= func_bytes);
-
-		if (nbytes < bsize)
-			goto done;
-	}
-
-done:
-	return nbytes;
-}
-
-// From glue_helper.c with changes
-int glue_xts_req_128bit(struct skcipher_request *req,
-			void *tweak_ctx,
-			void *crypt_ctx, bool decrypt)
-{
-	const bool cts = (req->cryptlen % XTS_BLOCK_SIZE);
-	const unsigned int bsize = 128 / 8;
-	struct skcipher_request subreq;
-	struct skcipher_walk walk;
-	bool fpu_enabled = false;
-	unsigned int nbytes, tail;
-	int err;
-
-	if (req->cryptlen < XTS_BLOCK_SIZE)
-		return -EINVAL;
-
-	if (unlikely(cts)) {
-		struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-
-		tail = req->cryptlen % XTS_BLOCK_SIZE + XTS_BLOCK_SIZE;
-
-		skcipher_request_set_tfm(&subreq, tfm);
-		skcipher_request_set_callback(&subreq,
-					      crypto_skcipher_get_flags(tfm),
-					      NULL, NULL);
-		skcipher_request_set_crypt(&subreq, req->src, req->dst,
-					   req->cryptlen - tail, req->iv);
-		req = &subreq;
-	}
-
-	err = skcipher_walk_virt(&walk, req, false);
-	nbytes = walk.nbytes;
-	if (err)
-		return err;
-
-	/* set minimum length to bsize, for tweak_fn */
-	fpu_enabled = glue_fpu_begin(bsize, 1 /* fpu_blocks_limit */,
-				     &walk, fpu_enabled,
-				     nbytes < bsize ? bsize : nbytes);
-
-	/* calculate first value of T */
-	__xts_tweak_tresor_encrypt(tweak_ctx, walk.iv, walk.iv);
-
-	while (nbytes) {
-		nbytes = __glue_xts_req_128bit(crypt_ctx, &walk, decrypt);
-
-		err = skcipher_walk_done(&walk, nbytes);
-		nbytes = walk.nbytes;
-	}
-
-	if (unlikely(cts)) {
-		u8 *next_tweak, *final_tweak = req->iv;
-		struct scatterlist *src, *dst;
-		struct scatterlist s[2], d[2];
-		le128 b[2];
-
-		dst = src = scatterwalk_ffwd(s, req->src, req->cryptlen);
-		if (req->dst != req->src)
-			dst = scatterwalk_ffwd(d, req->dst, req->cryptlen);
-
-		if (decrypt) {
-			next_tweak = memcpy(b, req->iv, XTS_BLOCK_SIZE);
-			gf128mul_x_ble(b, b);
-		} else {
-			next_tweak = req->iv;
-		}
-
-		skcipher_request_set_crypt(&subreq, src, dst, XTS_BLOCK_SIZE,
-					   next_tweak);
-
-		err = skcipher_walk_virt(&walk, req, false) ?:
-		      skcipher_walk_done(&walk,
-				__glue_xts_req_128bit(crypt_ctx, &walk, decrypt));
-		if (err)
-			goto out;
-
-		scatterwalk_map_and_copy(b, dst, 0, XTS_BLOCK_SIZE, 0);
-		memcpy(b + 1, b, tail - XTS_BLOCK_SIZE);
-		scatterwalk_map_and_copy(b, src, XTS_BLOCK_SIZE,
-					 tail - XTS_BLOCK_SIZE, 0);
-		scatterwalk_map_and_copy(b, dst, 0, tail, 1);
-
-		skcipher_request_set_crypt(&subreq, dst, dst, XTS_BLOCK_SIZE,
-					   final_tweak);
-
-		err = skcipher_walk_virt(&walk, req, false) ?:
-		      skcipher_walk_done(&walk,
-				__glue_xts_req_128bit(crypt_ctx, &walk, decrypt));
-	}
-
-out:
-	glue_fpu_end(fpu_enabled);
-
-	return err;
-}
-
-// From glue_helper.c with changes
-void glue_xts_crypt_128bit_one(const void *ctx, u8 *dst, const u8 *src,
-			       le128 *iv, bool decrypt)
-{
-	le128 ivblk = *iv;
-
-	/* generate next IV */
-	gf128mul_x_ble(iv, &ivblk);
-
-	/* CC <- T xor C */
-	u128_xor((u128 *)dst, (const u128 *)src, (u128 *)&ivblk);
-
-	/* PP <- D(Key2,CC) */
-	if (decrypt)
-		__xts_tresor_decrypt(ctx, dst, dst);
-	else
-		__xts_tresor_encrypt(ctx, dst, dst);
-
-	/* P <- T xor PP */
-	u128_xor((u128 *)dst, (u128 *)dst, (u128 *)&ivblk);
-}
-
-static void tresor_xts_enc(const void *ctx, u8 *dst, const u8 *src, le128 *iv)
-{
-	glue_xts_crypt_128bit_one(ctx, dst, src, iv,
-				  false);
-}
-
-static void tresor_xts_dec(const void *ctx, u8 *dst, const u8 *src, le128 *iv)
-{
-	glue_xts_crypt_128bit_one(ctx, dst, src, iv,
-				  true);
-}
-
-static int xts_encrypt(struct skcipher_request *req)
-{
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-	struct tresor_xts_ctx *ctx = crypto_skcipher_ctx(tfm);
-
-	return glue_xts_req_128bit(req,
-				   &ctx->tweak_ctx,
-				   &ctx->crypt_ctx,
-				   false);
-}
-
-static int xts_decrypt(struct skcipher_request *req)
-{
-	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
-	struct tresor_xts_ctx *ctx = crypto_skcipher_ctx(tfm);
-
-	return glue_xts_req_128bit(req,
-				   &ctx->tweak_ctx,
-				   &ctx->crypt_ctx,
-				   true);
-}
-
 /*
  * Crypto API algorithm
  */
@@ -567,24 +305,6 @@ static struct skcipher_alg tresor_skciph
 		.setkey		= tresor_skcipher_setkey,
 		.encrypt	= cbc_encrypt,
 		.decrypt	= cbc_decrypt,
-#ifdef CONFIG_X86_64
-	}, {
-		.base = {
-			.cra_name		= "__xts(tresor)",
-			.cra_driver_name	= "__xts-tresor-aesni",
-			.cra_priority		= 401,
-			.cra_flags		= CRYPTO_ALG_INTERNAL,
-			.cra_blocksize		= AES_BLOCK_SIZE,
-			.cra_ctxsize		= sizeof(struct tresor_xts_ctx),
-			.cra_module		= THIS_MODULE,
-		},
-		.min_keysize	= 2 * AES_MIN_KEY_SIZE,
-		.max_keysize	= 2 * AES_MIN_KEY_SIZE,
-		.ivsize		= AES_BLOCK_SIZE,
-		.setkey		= xts_tresor_setkey,
-		.encrypt	= xts_encrypt,
-		.decrypt	= xts_decrypt,
-#endif
 	}
 };
 
--- a/crypto/Kconfig.orig	2024-02-04 20:21:30.357176820 -0800
+++ b/crypto/Kconfig	2024-02-04 20:24:10.251002039 -0800
@@ -381,7 +381,7 @@ config CRYPTO_TRESOR
 	select CRYPTO_ALGAPI
 	select CRYPTO_MANAGER
 	select CRYPTO_MANAGER2
-	imply CRYPTO_CTR
+	# imply CRYPTO_CTR # broken? selftest     : unknown
 	default n
 	help
 	  TRESOR Runs Encryption Securely Outside RAM
--- a/crypto/testmgr.c.orig	2024-02-04 20:20:06.870377292 -0800
+++ b/crypto/testmgr.c	2024-02-04 20:25:09.390231627 -0800
@@ -2864,17 +2864,9 @@ static int test_skcipher_vec_cfg(int enc
 					    CRYPTO_TFM_REQ_FORBID_WEAK_KEYS);
 #ifdef CONFIG_CRYPTO_TRESOR
 	if (strstr(driver, "tresor")) {
-		/* continue tests so we can see breakage */
-		if (strstr(driver, "xts") && vec->klen > 32) {
-			pr_info("alg: skcipher: vec->klen=%d for %s is skipped and unsupported.", vec->klen, driver);
-			return 0;
-		}
-
 		pr_info("alg: skcipher: testing: vec->klen=%d for %s.  enc=%d.", vec->klen, driver, enc);
 
 		tresor_setkey(vec->key);
-		if (strstr(driver, "xts"))
-			tresor_setkey_xts_tweak(vec->key + vec->klen/2);
 	}
 #endif
 	err = do_setkey(crypto_skcipher_setkey, tfm, vec->key, vec->klen,
@@ -5798,16 +5790,6 @@ static const struct alg_test_desc alg_te
 			.cipher = __VECS(serpent_xts_tv_template)
 		}
 	}, {
-#ifdef CONFIG_CRYPTO_TRESOR
-		.alg = "xts(tresor)",
-		.generic_driver = "xts(ecb(aes-generic))",
-		.test = alg_test_skcipher,
-		.fips_allowed = 1,
-		.suite = {
-			.cipher = __VECS(aes_xts_tv_template)
-		}
-	}, {
-#endif
 		.alg = "xts(twofish)",
 		.generic_driver = "xts(ecb(twofish-generic))",
 		.test = alg_test_skcipher,
--- a/include/crypto/tresor.h.orig	2024-02-04 20:20:06.762378879 -0800
+++ b/include/crypto/tresor.h	2024-02-04 20:21:30.365176708 -0800
@@ -18,7 +18,6 @@ struct tresor_ctx {
 void tresor_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src);
 void tresor_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src);
 void tresor_setkey(const u8 *in_key);
-void tresor_setkey_xts_tweak(const u8 *in_key);
 bool tresor_capable(void);
 
 void tresor_kernel_init(void);
