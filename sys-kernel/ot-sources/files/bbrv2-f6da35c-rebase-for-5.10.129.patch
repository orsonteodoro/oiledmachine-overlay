# This is a rebase for the 5.10.129 release.
# Original commit:  f6da35cbef6549b1141a4a5631b91748d2ed0922
# URL:  https://github.com/google/bbr/commit/f6da35cbef6549b1141a4a5631b91748d2ed0922
# Fix mispatch from fuzz factor

include/net/tcp.h:
/* SPDX-License-Identifier: GPL-2.0-or-later */

net/ipv4/tcp_rate.c:
// SPDX-License-Identifier: GPL-2.0-only

--- a/include/net/tcp.h.orig	2022-07-11 19:27:05.339161860 -0700
+++ b/include/net/tcp.h	2022-07-11 19:28:10.170669238 -0700
@@ -855,9 +855,11 @@ struct tcp_skb_cb {
 	__u32		ack_seq;	/* Sequence number ACK'd	*/
 	union {
 		struct {
+#define TCPCB_DELIVERED_CE_MASK ((1U<<20) - 1)
 			/* There is space for up to 24 bytes */
 			__u32 is_app_limited:1, /* cwnd not fully used? */
-			      unused:31;
+			      delivered_ce:20,
+			      unused:11;
 			/* pkts S/ACKed so far upon tx of skb, incl retrans: */
 			__u32 delivered;
 			/* start of send pipeline phase */
@@ -1034,7 +1036,9 @@ struct ack_sample {
 struct rate_sample {
 	u64  prior_mstamp; /* starting timestamp for interval */
 	u32  prior_delivered;	/* tp->delivered at "prior_mstamp" */
+	u32  prior_delivered_ce;/* tp->delivered_ce at "prior_mstamp" */
 	s32  delivered;		/* number of packets delivered over interval */
+	s32  delivered_ce;	/* number of packets delivered w/ CE marks*/
 	long interval_us;	/* time for tp->delivered to incr "delivered" */
 	u32 snd_interval_us;	/* snd interval for delivered packets */
 	u32 rcv_interval_us;	/* rcv interval for delivered packets */
--- a/net/ipv4/tcp_rate.c.orig	2022-07-11 19:27:05.340161898 -0700
+++ b/net/ipv4/tcp_rate.c	2022-07-11 19:29:05.366804157 -0700
@@ -65,6 +65,7 @@ void tcp_rate_skb_sent(struct sock *sk,
 	TCP_SKB_CB(skb)->tx.first_tx_mstamp	= tp->first_tx_mstamp;
 	TCP_SKB_CB(skb)->tx.delivered_mstamp	= tp->delivered_mstamp;
 	TCP_SKB_CB(skb)->tx.delivered		= tp->delivered;
+	TCP_SKB_CB(skb)->tx.delivered_ce	= tp->delivered_ce;
 	TCP_SKB_CB(skb)->tx.is_app_limited	= tp->app_limited ? 1 : 0;
 }
 
@@ -90,6 +91,7 @@ void tcp_rate_skb_delivered(struct sock
 	if (!rs->prior_delivered ||
 	    tcp_skb_sent_after(tx_tstamp, tp->first_tx_mstamp,
 			       scb->end_seq, rs->last_end_seq)) {
+		rs->prior_delivered_ce  = scb->tx.delivered_ce;
 		rs->prior_delivered  = scb->tx.delivered;
 		rs->prior_mstamp     = scb->tx.delivered_mstamp;
 		rs->is_app_limited   = scb->tx.is_app_limited;
@@ -143,6 +145,10 @@ void tcp_rate_gen(struct sock *sk, u32 d
 	}
 	rs->delivered   = tp->delivered - rs->prior_delivered;
 
+	rs->delivered_ce = tp->delivered_ce - rs->prior_delivered_ce;
+	/* delivered_ce occupies less than 32 bits in the skb control block */
+	rs->delivered_ce &= TCPCB_DELIVERED_CE_MASK;
+
 	/* Model sending data and receiving ACKs as separate pipeline phases
 	 * for a window. Usually the ACK phase is longer, but with ACK
 	 * compression the send phase can be longer. To be safe we use the
