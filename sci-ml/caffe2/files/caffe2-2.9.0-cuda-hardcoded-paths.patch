--- a/cmake/Modules/FindCUDAToolkit.cmake.orig	2025-10-08 18:09:57.000000000 -0700
+++ b/cmake/Modules/FindCUDAToolkit.cmake	2025-10-31 17:28:33.798246455 -0700
@@ -619,7 +619,7 @@ else()
   if(NOT CUDAToolkit_ROOT_DIR)
     if(UNIX)
       if(NOT APPLE)
-        set(platform_base "/usr/local/cuda-")
+        set(platform_base "/opt/cuda")
       else()
         set(platform_base "/Developer/NVIDIA/CUDA-")
       endif()
@@ -656,7 +656,7 @@ else()
 
     # Force the global default /usr/local/cuda to the front on Unix.
     if(UNIX)
-      list(INSERT search_paths 0 "/usr/local/cuda")
+      list(INSERT search_paths 0 "/opt/cuda")
     endif()
 
     # Now search for the toolkit again using the platform default search paths.
--- a/torch/utils/collect_env.py.orig	2025-10-08 18:09:57.000000000 -0700
+++ b/torch/utils/collect_env.py	2025-10-31 17:29:25.237624533 -0700
@@ -242,7 +242,7 @@ def get_cudnn_version(run_lambda):
         # https://docs.nvidia.com/cuda/archive/9.0/cuda-installation-guide-mac-os-x/index.html#installation
         # https://docs.nvidia.com/deeplearning/cudnn/installation/latest/
         # Use CUDNN_LIBRARY when cudnn library is installed elsewhere.
-        cudnn_cmd = "ls /usr/local/cuda/lib/libcudnn*"
+        cudnn_cmd = "ls /opt/cuda/lib64/libcudnn*"
     else:
         cudnn_cmd = 'ldconfig -p | grep libcudnn | rev | cut -d" " -f1 | rev'
     rc, out, _ = run_lambda(cudnn_cmd)
--- a/cmake/Modules_CUDA_fix/upstream/FindCUDA.cmake.orig	2025-10-08 18:09:57.000000000 -0700
+++ b/cmake/Modules_CUDA_fix/upstream/FindCUDA.cmake	2025-10-31 17:27:54.646957371 -0700
@@ -927,7 +927,7 @@ elseif(CUDA_USE_STATIC_CUDA_RUNTIME AND
   if(APPLE)
     # We need to add the default path to the driver (libcuda.dylib) as an rpath, so that
     # the static cuda runtime can find it at runtime.
-    list(APPEND CUDA_LIBRARIES -Wl,-rpath,/usr/local/cuda/lib)
+    list(APPEND CUDA_LIBRARIES -Wl,-rpath,/opt/cuda/lib64)
   endif()
 else()
   list(APPEND CUDA_LIBRARIES ${CUDA_CUDART_LIBRARY})
