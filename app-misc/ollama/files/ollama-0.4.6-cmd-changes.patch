diff '--color=auto' -urp ollama-0.4.6.orig/cmd/cmd.go ollama-0.4.6/cmd/cmd.go
--- ollama-0.4.6.orig/cmd/cmd.go	2024-11-27 13:40:57.000000000 -0800
+++ ollama-0.4.6/cmd/cmd.go	2024-11-28 13:50:50.516964448 -0800
@@ -17,9 +17,12 @@ import (
 	"net"
 	"net/http"
 	"os"
+	"os/exec" // oteodoro:  added line
 	"os/signal"
 	"path/filepath"
+	"regexp" // oteodoro:  added line
 	"runtime"
+	"sort" // oteodoro:  added line
 	"strconv"
 	"strings"
 	"sync/atomic"
@@ -69,6 +72,2057 @@ func getModelfileName(cmd *cobra.Command
 	return absName, nil
 }
 
+var sizeTable = map[string]string{
+	// Quality control notes:
+	// q6*, q5* for round downs for 16MB, 32MB, 64MB, 128MB, 256MB, 512MB, 1GB, 2GB, 4GB, 8GB, 16GB, 32GB, 64GB, 128GB, 256GB, 512GB boundary
+	// fp16, q8_0 for max AGI
+	// q4_0 is balanced but preference for speed over AGI (default)
+	// For security based LLMs >= q5
+	"adens/quran-guide": "2.0GB",
+	"akx/viking-7b": "4.6GB",
+	"agcobra/liberated-qwen1.5-72b": "44GB",
+	"alfred:40b": "24GB",
+	"alfred:40b-1023-q5_0": "29GB",
+	"alfred:40b-1023-q5_1": "32GB",
+	"alfred:40b-1023-q8_0": "44GB",
+	"ALIENTELLIGENCE/christiancounselor": "4.7GB",
+	"ALIENTELLIGENCE/crisisintervention": "4.7GB",
+	"ALIENTELLIGENCE/doomsdayurvivalist": "4.7GB",
+	"ALIENTELLIGENCE/enriquecastillorincon": "4.7GB",
+	"ALIENTELLIGENCE/gamemasterroleplaying": "4.7GB",
+	"ALIENTELLIGENCE/holybible": "4.7GB",
+	"ALIENTELLIGENCE/mentalwellness": "4.7GB",
+	"ALIENTELLIGENCE/pcarchitect": "4.7GB",
+	"ALIENTELLIGENCE/prayerline": "4.7GB",
+	"ALIENTELLIGENCE/sarah": "4.7GB",
+	"ALIENTELLIGENCE/sarahv2": "4.7GB",
+	"ALIENTELLIGENCE/whiterabbit": "4.7GB",
+	"ALIENTELLIGENCE/whiterabbitv2": "4.7GB",
+	"all-minilm:22m": "46MB",
+	"all-minilm:33m": "67MB",
+	"all-minilm:l12": "67MB",
+	"all-minilm:l12-v2": "67MB",
+	"all-minilm:l6": "46MB",
+	"all-minilm:l6-v2": "46MB",
+	"all-minilm:v2": "46MB",
+	"all-minilm:22m-l6-v2-fp16": "46MB",
+	"all-minilm:33m-l12-v2-fp16": "67MB",
+	"Artalius/lixi": "2.0GB",
+	"artifish/mlewd-v2.4": "7.9GB",
+	"athene-v2": "72GB",
+	"aya:8b": "4.8GB",
+	"aya:35b": "20GB",
+	"aya:8b-23": "4.8GB",
+	"aya:35b-23": "20GB",
+	"aya:8b-23-q6_K": "6.6GB",
+	"aya:8b-23-q8_0": "8.5GB",
+	"aya:35b-23-q6_K": "29GB",
+	"aya:35b-23-q8_0": "37GB",
+	"aya-expanse:8b": "5.1GB",
+	"aya-expanse:32b": "20GB",
+	"aya-expanse:8b-fp16": "16GB",
+	"aya-expanse:32b-fp16": "65GB",
+	"aya-expanse:8b-q6_K": "6.6GB",
+	"aya-expanse:8b-q8_0": "8.5GB",
+	"aya-expanse:32b-q6_K": "27GB",
+	"aya-expanse:32b-q8_0": "34GB",
+	"bakllava:7b": "4.7GB",
+	"bakllava:7b-v1-q6_K": "6.6GB",
+	"bakllava:7b-v1-q8_0": "8.3GB",
+	"bakllava:7b-v1-fp16": "15GB",
+	"bge-large:335m": "671MB",
+	"bge-large:335m-en-v1.5-fp16": "671MB",
+	"bge-m3:567m": "1.2GB",
+	"bge-m3:567m-fp16": "1.2GB",
+	"benevolentjoker/belial": "4.9GB",
+	"benevolentjoker/bethanygpt": "4.7GB",
+	"benevolentjoker/nsfwmonika": "4.7GB",
+	"benevolentjoker/nsfwvanessa": "4.9GB",
+	"benevolentjoker/satan": "4.9GB",
+	"bespoke-minicheck:7b": "4.7GB",
+	"bespoke-minicheck:7b-q6_K": "6.4GB",
+	"bespoke-minicheck:7b-q8_0": "8.2GB",
+	"bespoke-minicheck:7b-fp16": "15GB",
+	"canadiangamer/neena": "3.8GB",
+	"canadiangamer/priya": "3.8GB",
+	"captainkyd/whiterabbitneo7b": "7.2GB",
+	"chatgph/70b-instruct": "53GB",
+	"chatgph/gph-main": "5.5GB",
+	"chatgph/medix-ph": "3.8GB",
+	"codebooga:34b": "19GB",
+	"codebooga:34b-v0.1-q6_K": "28GB",
+	"codebooga:34b-v0.1-q8_0": "36GB",
+	"codebooga:34b-v0.1-fp16": "67GB",
+	"codegeex4:9b": "5.5GB",
+	"codegeex4:9b-all-q5_1": "7.1GB",
+	"codegeex4:9b-all-q6_K": "8.3GB",
+	"codegeex4:9b-all-q8_0": "10.0GB",
+	"codegeex4:9b-all-fp16": "19GB",
+	"codegemma:2b": "1.6GB",
+	"codegemma:7b": "5.0GB",
+	"codegemma:code": "1.6GB",
+	"codegemma:instruct": "5.0GB",
+	"codegemma:2b-code": "1.6GB",
+	"codegemma:2b-v1.1": "1.6GB",
+	"codegemma:7b-code": "5.0GB",
+	"codegemma:7b-instruct": "5.0GB",
+	"codegemma:7b-v1.1": "5.0GB",
+	"codegemma:2b-code-q8_0": "2.7GB",
+	"codegemma:2b-code-v1.1-q8_0": "2.7GB",
+	"codegemma:7b-code-q6_K": "7.0GB",
+	"codegemma:7b-instruct-q6_K": "7.0GB",
+	"codegemma:7b-instruct-v1.1-q6_K": "7.0GB",
+	"codegemma:7b-code-q8_0": "9.1GB",
+	"codegemma:7b-instruct-q8_0": "9.1GB",
+	"codegemma:7b-instruct-v1.1-q8_0": "9.1GB",
+	"codegemma:2b-code-fp16": "5.0GB",
+	"codegemma:2b-code-v1.1-fp16": "5.0GB",
+	"codegemma:7b-code-fp16": "17GB",
+	"codegemma:7b-instruct-fp16": "17GB",
+	"codegemma:7b-instruct-v1.1-fp16": "17GB",
+	"codellama:7b": "3.8GB",
+	"codellama:13b": "7.4GB",
+	"codellama:34b": "19GB",
+	"codellama:70b": "39GB",
+	"codellama:code": "3.8GB",
+	"codellama:instruct": "3.8GB",
+	"codellama:python": "3.8GB",
+	"codellama:7b-code": "3.8GB",
+	"codellama:7b-instruct": "3.8GB",
+	"codellama:7b-python": "3.8GB",
+	"codellama:13b-code": "7.4GB",
+	"codellama:13b-instruct": "7.4GB",
+	"codellama:13b-python": "7.4GB",
+	"codellama:34b-code": "19GB",
+	"codellama:34b-instruct": "19GB",
+	"codellama:34b-python": "19GB",
+	"codellama:70b-code": "39GB",
+	"codellama:70b-instruct": "39GB",
+	"codellama:70b-python": "39GB",
+	"codellama:7b-code-q8_0": "7.2GB",
+	"codellama:7b-instruct-q8_0": "7.2GB",
+	"codellama:7b-python-q8_0": "7.2GB",
+	"codellama:13b-code-q8_0": "14GB",
+	"codellama:13b-instruct-q8_0": "14GB",
+	"codellama:13b-python-q8_0": "14GB",
+	"codellama:34b-instruct-q6_K": "28GB",
+	"codellama:34b-python-q6_K": "28GB",
+	"codellama:34b-instruct-q8_0": "36GB",
+	"codellama:34b-python-q8_0": "36GB",
+	"codellama:70b-code-q8_0": "73GB",
+	"codellama:70b-instruct-q8_0": "73GB",
+	"codellama:70b-python-q8_0": "73GB",
+	"codellama:7b-code-fp16": "13GB",
+	"codellama:7b-instruct-fp16": "13GB",
+	"codellama:7b-python-fp16": "13GB",
+	"codellama:13b-code-fp16": "26GB",
+	"codellama:13b-instruct-fp16": "26GB",
+	"codellama:13b-python-fp16": "26GB",
+	"codellama:34b-instruct-fp16": "67GB",
+	"codellama:34b-python-fp16": "67GB",
+	"codellama:70b-code-fp16": "138GB",
+	"codellama:70b-instruct-fp16": "138GB",
+	"codellama:70b-python-fp16": "138GB",
+	"codeqwen:7b": "4.2GB",
+	"codeqwen:chat": "4.2GB",
+	"codeqwen:code": "4.2GB",
+	"codeqwen:v1.5": "4.2GB",
+	"codeqwen:v1.5-chat": "4.2GB",
+	"codeqwen:v1.5-code": "4.2GB",
+	"codeqwen:7b-chat": "4.2GB",
+	"codeqwen:7b-code": "4.2GB",
+	"codeqwen:7b-chat-v1.5-q8_0": "7.7GB",
+	"codeqwen:7b-code-v1.5-q8_0": "7.7GB",
+	"codeqwen:7b-chat-v1.5-fp16": "15GB",
+	"codeqwen:7b-code-v1.5-fp16": "15GB",
+	"codestral:22b": "13GB",
+	"codestral:v0.1": "13GB",
+	"codestral:22b-v0.1-q5_0": "15GB",
+	"codestral:22b-v0.1-q5_K_M": "16GB",
+	"codestral:22b-v0.1-q8_0": "24GB",
+	"codeup:13b": "7.4GB",
+	"codeup:13b-llama2": "7.4GB",
+	"codeup:13b-llama2-chat": "7.4GB",
+	"codeup:13b-llama2-chat-q8_0": "14GB",
+	"codeup:13b-llama2-chat-fp16": "26GB",
+	"command-r:35b": "19GB",
+	"command-r:35b-08-2024-q6_K": "27GB",
+	"command-r:35b-v0.1-q6_K": "29GB",
+	"command-r:35b-08-2024-q8_0": "34GB",
+	"command-r:35b-v0.1-q8_0": "37GB",
+	"command-r:35b-08-2024-fp16": "65GB",
+	"command-r:35b-v0.1-fp16": "70GB",
+	"command-r:v0.1": "20GB",
+	"command-r-plus:104b": "59GB",
+	"command-r-plus:104b-08-2024-q8_0": "110GB",
+	"command-r-plus:104b-08-2024-fp16": "208GB",
+	"dbrx:132b": "74GB",
+	"dbrx:instruct": "74GB",
+	"dbrx:132b-instruct-q8_0": "140GB",
+	"dbrx:132b-instruct-fp16": "263GB",
+	"deepseek-coder-v2:16b": "8.9GB",
+	"deepseek-coder-v2:236b": "133GB",
+	"deepseek-coder-v2:lite": "8.9GB",
+	"deepseek-coder-v2:16b-lite-base-q8_0": "17GB",
+	"deepseek-coder-v2:16b-lite-instruct-q8_0": "17GB",
+	"deepseek-coder-v2:236b-lite-base-q8_0": "251GB",
+	"deepseek-coder-v2:236b-lite-instruct-q8_0": "251GB",
+	"deepseek-coder-v2:16b-lite-base-fp16": "31GB",
+	"deepseek-coder-v2:16b-lite-instruct-fp16": "31GB",
+	"deepseek-coder-v2:236b-lite-base-fp16": "472GB",
+	"deepseek-coder-v2:236b-lite-instruct-fp16": "472GB",
+	"deepseek-llm:7b": "4.0GB",
+	"deepseek-llm:67b": "38GB",
+	"deepseek-llm:7b-base": "4.0GB",
+	"deepseek-llm:7b-chat": "4.0GB",
+	"deepseek-llm:67b-base": "38GB",
+	"deepseek-llm:67b-chat": "38GB",
+	"deepseek-llm:7b-base-q6_k": "5.7GB",
+	"deepseek-llm:7b-chat-q6_k": "5.7GB",
+	"deepseek-llm:67b-base-q6_k": "55GB",
+	//"deepseek-llm:67b-chat-q6_k": "55GB",
+	"deepseek-llm:7b-base-q8_0": "7.3GB",
+	"deepseek-llm:7b-chat-q8_0": "7.3GB",
+	"deepseek-llm:67b-base-q8_0": "72GB",
+	//"deepseek-llm:67b-chat-q8_0": "72GB",
+	"deepseek-llm:7b-base-fp16": "14GB",
+	"deepseek-llm:7b-chat-fp16": "14GB",
+	"deepseek-llm:67b-base-fp16": "135GB",
+	"deepseek-llm:67b-chat-fp16": "135GB",
+	"deepseek-v2:16b": "8.9GB",
+	"deepseek-v2:236b": "133GB",
+	"deepseek-v2:lite": "8.9GB",
+	"deepseek-v2:16b-lite-chat-q6_K": "14GB",
+	"deepseek-v2:236b-chat-q6_K": "194GB",
+	"deepseek-v2:16b-lite-chat-q8_0": "17GB",
+	"deepseek-v2:236b-chat-q8_0": "251GB",
+	"deepseek-v2:16b-lite-chat-fp16": "31GB",
+	"deepseek-v2:236b-chat-fp16": "472GB",
+	"deepseek-v2.5:236b": "133GB",
+	"deepseek-v2.5:236b-q8_0": "251GB",
+	"disinfozone/telos": "5.1GB",
+	"dolphin-llama3:8b": "4.7GB",
+	"dolphin-llama3:70b": "40GB",
+	"dolphin-llama3:v2.9": "4.7GB",
+	"dolphin-llama3:8b-256k": "4.7GB",
+	"dolphin-llama3:8b-256k-v2.9": "4.7GB",
+	"dolphin-llama3:8b-v2.9": "4.7GB",
+	"dolphin-llama3:70b-v2.9": "40GB",
+	"dolphin-llama3:8b-256k-v2.9-q6_K": "6.6GB",
+	"dolphin-llama3:8b-v2.9-q6_K": "6.6GB",
+	"dolphin-llama3:70b-v2.9-q6_K": "58GB",
+	"dolphin-llama3:8b-256k-v2.9-q8_0": "8.5GB",
+	"dolphin-llama3:8b-v2.9-q8_0": "8.5GB",
+	"dolphin-llama3:70b-v2.9-q8_0": "75GB",
+	"dolphin-llama3:8b-256k-v2.9-fp16": "16GB",
+	"dolphin-llama3:8b-v2.9-fp16": "16GB",
+	"dolphin-llama3:70b-v2.9-fp16": "141GB",
+	"dolphin-mistral:7b": "4.1GB",
+	"dolphin-mistral:v2": "4.1GB",
+	"dolphin-mistral:v2.1": "4.1GB",
+	"dolphin-mistral:v2.2": "4.1GB",
+	"dolphin-mistral:v2.2.1": "4.1GB",
+	"dolphin-mistral:v2.6": "4.1GB",
+	"dolphin-mistral:v2.8": "4.1GB",
+	"dolphin-mistral:7b-v2": "4.1GB",
+	"dolphin-mistral:7b-v2.1": "4.1GB",
+	"dolphin-mistral:7b-v2.2": "4.1GB",
+	"dolphin-mistral:7b-v2.2.1": "4.1GB",
+	"dolphin-mistral:7b-v2.6": "4.1GB",
+	"dolphin-mistral:7b-v2.6-dpo-laser": "4.1GB",
+	"dolphin-mistral:7b-v2.8": "4.1GB",
+	"dolphin-mistral:7b-v2-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.1-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.2-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.2.1-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.6-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.6-dpo-laser-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.8-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2-fp16": "14GB",
+	"dolphin-mistral:7b-v2.1-fp16": "14GB",
+	"dolphin-mistral:7b-v2.2-fp16": "14GB",
+	"dolphin-mistral:7b-v2.2.1-fp16": "14GB",
+	"dolphin-mistral:7b-v2.6-fp16": "14GB",
+	"dolphin-mistral:7b-v2.6-dpo-laser-fp16": "14GB",
+	"dolphin-mistral:7b-v2.8-fp16": "14GB",
+	"dolphin-mixtral:8x7b": "26GB",
+	"dolphin-mixtral:8x22b": "80GB",
+	"dolphin-mixtral:v2.5": "26GB",
+	"dolphin-mixtral:v2.6": "26GB",
+	"dolphin-mixtral:v2.6.1": "26GB",
+	"dolphin-mixtral:v2.7": "26GB",
+	"dolphin-mixtral:8x7b-v2.5": "26GB",
+	"dolphin-mixtral:8x7b-v2.6": "26GB",
+	"dolphin-mixtral:8x7b-v2.6.1": "26GB",
+	"dolphin-mixtral:8x7b-v2.7": "26GB",
+	"dolphin-mixtral:8x22b-v2.9": "80GB",
+	"dolphin-mixtral:8x22b-v2.9-q6_K": "116GB",
+	"dolphin-mixtral:8x7b-v2.5-q8_0": "50GB",
+	"dolphin-mixtral:8x7b-v2.6-q8_0": "50GB",
+	"dolphin-mixtral:8x7b-v2.6.1-q8_0": "50GB",
+	"dolphin-mixtral:8x7b-v2.7-q8_0": "50GB",
+	"dolphin-mixtral:8x22b-v2.9-q8_0": "149GB",
+	"dolphin-mixtral:8x7b-v2.5-fp16": "93GB",
+	"dolphin-mixtral:8x7b-v2.6-fp16": "93GB",
+	"dolphin-mixtral:8x7b-v2.6.1-fp16": "93GB",
+	"dolphin-mixtral:8x7b-v2.7-fp16": "93GB",
+	"dolphin-mixtral:8x22b-v2.9-fp16": "281GB",
+	"dolphin-phi:2.7b": "1.6GB",
+	"dolphin-phi:2.7b-v2.6": "1.6GB",
+	"dolphin-phi:2.7b-v2.6-q5_0": "1.9GB",
+	"dolphin-phi:2.7b-v2.6-q8_0": "3.0GB",
+	"dolphincoder:7b": "4.1GB",
+	"dolphincoder:15b": "9.1GB",
+	"dolphincoder:7b-starcoder2": "4.2GB",
+	"dolphincoder:15b-starcoder2": "9.1GB",
+	"dolphincoder:7b-starcoder2-q6_K": "6.1GB",
+	"dolphincoder:15b-starcoder2-q6_K": "13GB",
+	"dolphincoder:7b-starcoder2-q8_0": "7.9GB",
+	"dolphincoder:15b-starcoder2-q8_0": "17GB",
+	"dolphincoder:7b-starcoder2-fp16": "15GB",
+	"dolphincoder:15b-starcoder2-fp16": "32GB",
+	"duckdb-nsql:7b": "3.8GB",
+	"duckdb-nsql:7b-q8_0": "7.2GB",
+	"duckdb-nsql:7b-fp16": "13GB",
+	"ehartford/theprofessor:155b-q4_K_M": "93GB",
+	"eramax/aura_v3:Q5": "5.1GB",
+	"everythinglm:13b": "7.4GB",
+	"everythinglm:13b-16k": "7.4GB",
+	"everythinglm:13b-16k-q8_0": "14GB",
+	"everythinglm:13b-16k-fp16": "26GB",
+	"falcon:7b": "4.2GB",
+	"falcon:40b": "24GB",
+	"falcon:180b": "101GB",
+	"falcon:instruct": "4.2GB",
+	"falcon:text": "4.2GB",
+	"falcon:7b-instruct": "4.2GB",
+	"falcon:7b-text": "4.2GB",
+	"falcon:40b-instruct": "24GB",
+	"falcon:40b-text": "24GB",
+	"falcon:180b-instruct": "101GB",
+	"falcon:180b-text": "101GB",
+	"falcon:7b-instruct-q8_0": "7.7GB",
+	"falcon:7b-text-q8_0": "7.7GB",
+	"falcon:40b-instruct-q5_0": "29GB",
+	"falcon:40b-text-q5_0": "29GB",
+	"falcon:40b-instruct-q5_1": "32GB",
+	"falcon:40b-text-q5_1": "32GB",
+	"falcon:40b-instruct-q8_0": "44GB",
+	"falcon:40b-text-q8_0": "44GB",
+	"falcon:7b-instruct-fp16": "14GB",
+	"falcon:7b-text-fp16": "14GB",
+	"falcon:40b-instruct-fp16": "84GB",
+	"falcon:40b-text-fp16": "84GB",
+	"falcon:180b-instruct-fp16": "101GB",
+	"falcon:180b-text-fp16": "101GB",
+	"falcon2:11b": "6.4GB",
+	"falcon2:11b-q5_0": "7.7GB",
+	"falcon2:11b-q5_1": "8.4GB",
+	"falcon2:11b-q8_0": "12GB",
+	"falcon2:11b-fp16": "22GB",
+	"firefunction-v2:70b": "40GB",
+	"firefunction-v2:70b-q6_K": "58GB",
+	"firefunction-v2:70b-q8_0": "75GB",
+	"firefunction-v2:70b-fp16": "141GB",
+	"fixt/home-3b-v3:q4_k_m": "1.7GB",
+	"fixt/home-3b-v3:q5_k_m": "2.0GB",
+	"fixt/home-3b-v3:q8_0": "3.0GB",
+	"fixt/home-3b-v3:f16": "5.6GB",
+	"fixt/home-3b-v2:q4_k_m": "1.7GB",
+	"fixt/home-3b-v2:q5_k_m": "2.0GB",
+	"fixt/home-3b-v2:q8_0": "3.0GB",
+	"gemma:2b": "1.7GB",
+	"gemma:7b": "5.0GB",
+	"gemma:instruct": "5.0GB",
+	"gemma:text": "5.2GB",
+	"gemma:v1.1": "5.0GB",
+	"gemma:2b-instruct": "1.6GB",
+	"gemma:2b-text": "1.7GB",
+	"gemma:2b-v1.1": "1.6GB",
+	"gemma:7b-instruct": "5.0GB",
+	"gemma:7b-text": "5.2GB",
+	"gemma:7b-v1.1": "5.0GB",
+	"gemma:2b-instruct-q8_0": "2.7GB",
+	"gemma:2b-instruct-v1.1-q8_0": "2.7GB",
+	"gemma:2b-text-q8_0": "2.7GB",
+	"gemma:7b-instruct-q8_0": "9.1GB",
+	"gemma:7b-instruct-v1.1-q8_0": "9.1GB",
+	"gemma:7b-text-q8_0": "9.1GB",
+	"gemma:2b-instruct-fp16": "4.5GB",
+	"gemma:2b-instruct-v1.1-fp16": "5.0GB",
+	"gemma:2b-text-fp16": "4.5GB",
+	"gemma:7b-instruct-fp16": "17GB",
+	"gemma:7b-instruct-v1.1-fp16": "17GB",
+	"gemma:7b-text-fp16": "16GB",
+	"gemma2:2b": "1.6GB",
+	"gemma2:9b": "5.4GB",
+	"gemma2:27b": "16GB",
+	"gemma2:2b-instruct-q8_0": "2.8GB",
+	"gemma2:2b-text-q8_0": "2.8GB",
+	"gemma2:9b-instruct-q8_0": "9.8GB",
+	"gemma2:9b-text-q8_0": "9.8GB",
+	"gemma2:27b-instruct-q8_0": "29GB",
+	"gemma2:27b-text-q8_0": "29GB",
+	"gemma2:2b-instruct-fp16": "5.2GB",
+	"gemma2:2b-text-fp16": "5.2GB",
+	"gemma2:9b-instruct-fp16": "18GB",
+	"gemma2:9b-text-fp16": "18GB",
+	"gemma2:27b-instruct-fp16": "54GB",
+	"gemma2:27b-text-fp16": "54GB",
+	"glm4:9b": "5.5GB",
+	"glm4:9b-chat-q5_1": "7.1GB",
+	"glm4:9b-text-q5_1": "7.1GB",
+	"glm4:9b-chat-q6_K": "8.3GB",
+	"glm4:9b-text-q6_K": "8.3GB",
+	"glm4:9b-chat-q8_0": "10.0GB",
+	"glm4:9b-text-q8_0": "10.0GB",
+	"glm4:9b-chat-fp16": "19GB",
+	"glm4:9b-text-fp16": "19GB",
+	"goliath:120b-q4_0": "66GB",
+	"goliath:120b-q8_0": "125GB",
+	"goliath:120b-fp16": "236GB",
+	"granite-code:3b": "2.0GB",
+	"granite-code:8b": "4.6GB",
+	"granite-code:20b": "12GB",
+	"granite-code:34b": "19GB",
+	"granite-code:3b-base": "2.0GB",
+	"granite-code:3b-instruct": "2.0GB",
+	"granite-code:8b-base": "4.6GB",
+	"granite-code:8b-instruct": "4.6GB",
+	"granite-code:20b-base": "12GB",
+	"granite-code:34b-base": "19GB",
+	"granite-code:3b-base-q8_0": "3.7GB",
+	"granite-code:3b-instruct-q8_0": "3.7GB",
+	"granite-code:3b-128k-instruct-q8_0": "3.7GB",
+	"granite-code:8b-base-q6_K": "6.6GB",
+	"granite-code:8b-base-q8_0": "8.6GB",
+	"granite-code:8b-instruct-q6_K": "6.6GB",
+	"granite-code:8b-instruct-q8_0": "8.6GB",
+	"granite-code:8b-instruct-128k-q4_0": "4.6GB",
+	"granite-code:8b-instruct-128k-q4_1": "5.1GB",
+	"granite-code:20b-base-q5_K_M": "15GB",
+	"granite-code:20b-base-q8_0": "21GB",
+	"granite-code:20b-instruct-8k-q6_K": "15GB",
+	"granite-code:20b-instruct-8k-q8_0": "21GB",
+	"granite-code:34b-base-q6_K": "28GB",
+	"granite-code:34b-base-q8_0": "36GB",
+	"granite-code:34b-instruct-q6_K": "28GB",
+	"granite-code:34b-instruct-q8_0": "36GB",
+	"granite-code:3b-base-fp16": "7.0GB",
+	"granite-code:3b-instruct-fp16": "7.0GB",
+	"granite-code:3b-128k-instruct-fp16": "7.0GB",
+	"granite-code:8b-base-fp16": "16GB",
+	"granite-code:8b-instruct-fp16": "16GB",
+	"granite-code:20b-base-fp16": "40GB",
+	"granite-code:20b-instruct-8k-fp16": "40GB",
+	"granite3-dense:2b": "1.6GB",
+	"granite3-dense:8b": "4.9GB",
+	"granite3-dense:2b-instruct-q5_1": "2.0GB",
+	"granite3-dense:2b-instruct-q8_0": "2.8GB",
+	"granite3-dense:8b-instruct-q6_K": "6.7GB",
+	"granite3-dense:8b-instruct-q8_0": "8.7GB",
+	"granite3-dense:2b-instruct-fp16": "5.3GB",
+	"granite3-dense:8b-instruct-fp16": "16GB",
+	"granite3-guardian:2b": "2.7GB",
+	"granite3-guardian:8b": "5.8GB",
+	"granite3-guardian:2b-q8_0": "2.7GB",
+	"granite3-guardian:2b-fp16": "5.1GB",
+	"granite3-guardian:8b-q6_K": "6.7GB",
+	"granite3-guardian:8b-q8_0": "8.7GB",
+	"granite3-guardian:8b-fp16": "16GB",
+	"granite3-moe:1b": "822MB",
+	"granite3-moe:3b": "2.1GB",
+	"granite3-moe:1b-instruct-q8_0": "1.4GB",
+	"granite3-moe:3b-instruct-q8_0": "3.6GB",
+	"granite3-moe:1b-instruct-fp16": "2.7GB",
+	"granite3-moe:3b-instruct-fp16": "6.8GB",
+	"hemanth/chessplayer": "3.8GB",
+	"hermes3:8b": "4.7GB",
+	"hermes3:70b": "40GB",
+	"hermes3:405b": "229GB",
+	"hermes3:8b-llama3.1-q6_K": "6.6GB",
+	"hermes3:70b-llama3.1-q6_K": "58GB",
+	"hermes3:405b-llama3.1-q6_K": "333GB",
+	"hermes3:8b-llama3.1-q8_0": "8.5GB",
+	"hermes3:70b-llama3.1-q8_0": "75GB",
+	"hermes3:405b-llama3.1-q8_0": "431GB",
+	"hermes3:8b-llama3.1-fp16": "16GB",
+	"hermes3:70b-llama3.1-fp16": "141GB",
+	"hermes3:405b-llama3.1-fp16": "812GB",
+	"hookingai/monah-8b:q5_k_M": "5.7GB",
+	"hookingai/monah-8b:q6_K": "6.6GB",
+	"hookingai/monah-8b:F16": "16GB",
+	"internlm2:1m": "4.5GB",
+	"internlm2:1.8b": "1.1GB",
+	"internlm2:7b": "4.5GB",
+	"internlm2:20b": "11GB",
+	"internlm2:1.8b-chat-v2.5-q5_1": "1.4GB",
+	"internlm2:7b-chat-1m-v2.5-q5_1": "5.8GB",
+	"internlm2:7b-chat-v2.5-q5_1": "5.8GB",
+	"internlm2:20b-chat-v2.5-q5_1": "15GB",
+	"internlm2:1.8b-chat-v2.5-q6_K": "1.6GB",
+	"internlm2:7b-chat-1m-v2.5-q6_K": "6.4GB",
+	"internlm2:7b-chat-v2.5-q6_K": "6.4GB",
+	"internlm2:20b-chat-v2.5-q6_K": "16GB",
+	"internlm2:1.8b-chat-v2.5-q8_0": "2.0GB",
+	"internlm2:7b-chat-1m-v2.5-q8_0": "8.2GB",
+	"internlm2:7b-chat-v2.5-q8_0": "8.2GB",
+	"internlm2:20b-chat-v2.5-q8_0": "21GB",
+	"internlm2:1.8b-chat-v2.5-fp16": "3.8GB",
+	"internlm2:7b-chat-1m-v2.5-fp16": "15GB",
+	"internlm2:7b-chat-v2.5-fp16": "15GB",
+	"internlm2:20b-chat-v2.5-fp16": "40GB",
+	"jimscard/adult-film-screenwriter-nsfw": "4.1GB",
+	"jimscard/whiterabbit-neo:13b": "9.2GB",
+	"jimscard/whiterabbit-neo:13b-q5": "9.2GB",
+	"jimscard/whiterabbit-neo:13b-q5_K_M": "9.2GB",
+	"joefamous/grok-1:314b-q6_K": "260GB",
+	"leeplenty/lumimaid-v0.2:8b": "8.5GB",
+	"leeplenty/lumimaid-v0.2:12b": "13GB",
+	"leeplenty/lumimaid-v0.2:70b": "50GB",
+	"leeplenty/lumimaid-v0.2:123b": "130GB",
+	"llama-pro:instruct": "4.7GB",
+	"llama-pro:text": "4.7GB",
+	"llama-pro:8b-instruct-q6_K": "6.9GB",
+	"llama-pro:8b-text-q6_K": "6.9GB",
+	"llama-pro:8b-instruct-q8_0": "8.9GB",
+	"llama-pro:8b-text-q8_0": "8.9GB",
+	"llama-pro:8b-instruct-fp16": "17GB",
+	"llama-pro:8b-text-fp16": "17GB",
+	"llama2:7b": "3.8GB",
+	"llama2:13b": "7.4GB",
+	"llama2:70b": "39GB",
+	"llama2:chat": "3.8GB",
+	"llama2:text": "3.8GB",
+	"llama2:7b-chat": "3.8GB",
+	"llama2:7b-text": "3.8GB",
+	"llama2:70b-chat": "39GB",
+	"llama2:70b-text": "39GB",
+	"llama2:7b-chat-q8_0": "7.2GB",
+	"llama2:7b-text-q8_0": "7.2GB",
+	"llama2:13b-chat-q8_0": "14GB",
+	"llama2:13b-text-q8_0": "14GB",
+	"llama2:70b-chat-q6_K": "57GB",
+	"llama2:70b-text-q6_K": "57GB",
+	"llama2:70b-chat-q8_0": "73GB",
+	"llama2:70b-text-q8_0": "73GB",
+	"llama2:7b-chat-fp16": "13GB",
+	"llama2:7b-text-fp16": "13GB",
+	"llama2:13b-chat-fp16": "26GB",
+	"llama2:13b-text-fp16": "26GB",
+	"llama2:70b-chat-fp16": "138GB",
+	"llama2:70b-text-fp16": "138GB",
+	"llama2-chinese:7b": "3.8GB",
+	"llama2-chinese:13b": "7.4GB",
+	"llama2-chinese:7b-chat": "3.8GB",
+	"llama2-chinese:13b-chat": "7.4GB",
+	"llama2-chinese:7b-chat-q8_0": "7.2GB",
+	"llama2-chinese:13b-chat-q8_0": "14GB",
+	"llama2-chinese:7b-chat-fp16": "13GB",
+	"llama2-chinese:13b-chat-fp16": "26GB",
+	"llama2-uncensored:7b": "3.8GB",
+	"llama2-uncensored:70b": "39GB",
+	"llama2-uncensored:7b-chat": "3.8GB",
+	"llama2-uncensored:70b-chat": "39GB",
+	"llama2-uncensored:7b-chat-q8_0":"7.2GB",
+	"llama2-uncensored:70b-chat-q6_K":"57GB",
+	"llama2-uncensored:70b-chat-q8_0":"73GB",
+	"llama2-uncensored:7b-chat-fp16": "13GB",
+	"llama3:8b": "4.7GB",
+	"llama3:70b": "40GB",
+	"llama3:instruct": "4.7GB",
+	"llama3:text": "4.7GB",
+	"llama3:8b-text": "4.7GB",
+	"llama3:70b-instruct": "40GB",
+	"llama3:70b-text": "40GB",
+	"llama3:8b-instruct-q6_K": "6.6GB",
+	"llama3:8b-text-q6_K": "6.6GB",
+	"llama3:8b-instruct-q8_0": "8.5GB",
+	"llama3:8b-text-q8_0": "8.5GB",
+	"llama3:70b-instruct-q6_K": "58GB",
+	"llama3:70b-text-q6_K": "58GB",
+	"llama3:70b-instruct-q8_0": "75GB",
+	"llama3:70b-text-q8_0": "75GB",
+	"llama3:8b-instruct-fp16": "16GB",
+	"llama3:8b-text-fp16": "16GB",
+	"llama3:70b-instruct-fp16": "141GB",
+	"llama3:70b-text-fp16": "141GB",
+	"llama3-chatqa:8b": "4.7GB",
+	"llama3-chatqa:70b": "40GB",
+	"llama3-chatqa:8b-v1.5": "4.7GB",
+	"llama3-chatqa:70b-v1.5": "40GB",
+	"llama3-chatqa:8b-v1.5-q6_K": "6.6GB",
+	"llama3-chatqa:70b-v1.5-q6_K": "58GB",
+	"llama3-chatqa:8b-v1.5-q8_0": "8.5GB",
+	"llama3-chatqa:70b-v1.5-q8_0": "75GB",
+	"llama3-chatqa:8b-v1.5-fp16": "16GB",
+	"llama3-chatqa:70b-v1.5-fp16": "141GB",
+	"llama3-gradient:1024k": "4.7GB",
+	"llama3-gradient:8b": "4.7GB",
+	"llama3-gradient:70b": "40GB",
+	"llama3-gradient:instruct": "4.7GB",
+	"llama3-gradient:8b-instruct-1048k-q6_K": "6.6GB",
+	"llama3-gradient:70b-instruct-1048k-q6_K": "6.6GB",
+	"llama3-gradient:8b-instruct-1048k-q8_0": "8.5GB",
+	"llama3-gradient:70b-instruct-1048k-q8_0": "75GB",
+	"llama3-gradient:8b-instruct-1048k-fp16": "16GB",
+	"llama3-gradient:70b-instruct-1048k-fp16": "141GB",
+	"llama3-groq-tool-use:8b": "4.7GB",
+	"llama3-groq-tool-use:70b": "40GB",
+	"llama3-groq-tool-use:8b-q6_K": "6.6GB",
+	"llama3-groq-tool-use:70b-q6_K": "58GB",
+	"llama3-groq-tool-use:8b-q8_0": "8.5GB",
+	"llama3-groq-tool-use:70b-q8_0": "75GB",
+	"llama3-groq-tool-use:8b-fp16": "16GB",
+	"llama3-groq-tool-use:70b-fp16": "141GB",
+	"llama3.1:8b": "4.7GB",
+	"llama3.1:70b": "40GB",
+	"llama3.1:405b": "229GB",
+	"llama3.1:8b-instruct-q6_K": "6.6GB",
+	"llama3.1:8b-text-q6_K": "6.6GB",
+	"llama3.1:8b-instruct-q8_0": "8.5GB",
+	"llama3.1:8b-text-q8_0": "8.5GB",
+	"llama3.1:70b-instruct-q6_K": "58GB",
+	"llama3.1:70b-text-q6_K": "58GB",
+	"llama3.1:70b-instruct-q8_0": "75GB",
+	"llama3.1:70b-text-q8_0": "75GB",
+	"llama3.1:405b-instruct-q8_0": "431GB",
+	"llama3.1:405b-text-q8_0": "431GB",
+	"llama3.1:8b-instruct-fp16": "16GB",
+	"llama3.1:8b-text-fp16": "16GB",
+	"llama3.1:70b-instruct-fp16": "141GB",
+	"llama3.1:70b-text-fp16": "141GB",
+	"llama3.1:405b-instruct-fp16": "812GB",
+	"llama3.1:405b-text-fp16": "812GB",
+	"llama3.2-vision:11b":  "7.9GB",
+	"llama3.2-vision:90b":  "55GB",
+	"llama3.2-vision:11b-instruct-q8_0":  "12GB",
+	"llama3.2-vision:11b-instruct-fp16":  "21GB",
+	"llama3.2-vision:90b-instruct-q8_0":  "95GB",
+	"llama3.2-vision:90b-instruct-fp16":  "177GB",
+	"llama3.2:3b": "2.0GB",
+	"llama3.2:1b": "1.3GB",
+	"llama3.2:1b-instruct-q5_1": "953MB",
+	"llama3.2:1b-text-q5_1": "953MB",
+	"llama3.2:1b-instruct-q6_K": "1.0GB",
+	"llama3.2:1b-text-q6_K": "1.0GB",
+	"llama3.2:1b-instruct-q8.0": "1.3GB",
+	"llama3.2:1b-text-q8_0": "1.3GB",
+	"llama3.2:3b-instruct-q8_0": "3.4GB",
+	"llama3.2:3b-text-q8_0": "3.4GB",
+	"llama3.2:1b-instruct-fp16": "2.5GB",
+	"llama3.2:1b-text-fp16": "2.5GB",
+	"llama3.2:3b-instruct-fp16": "6.4GB",
+	"llama3.2:3b-text-fp16": "6.4GB",
+	"llama-guard3:1b": "1.6GB",
+	"llama-guard3:8b": "4.9GB",
+	"llama-guard3:1b-q4_1": "996MB",
+	"llama-guard3:1b-q8_0": "1.6GB",
+	"llama-guard3:8b-q6_K": "6.6GB",
+	"llama-guard3:8b-q8_0": "8.5GB",
+	"llama-guard3:1b-fp16": "3.0GB",
+	"llama-guard3:8b-fp16": "16GB",
+	"llava:7b": "4.7GB",
+	"llava:13b": "8.0GB",
+	"llava:34b": "20.0GB",
+	"llava:v1.6": "4.7GB",
+	"llava:7b-v1.6": "4.7GB",
+	"llava:13b-v1.6": "8.0GB",
+	"llava:34b-v1.6": "20.0GB",
+	"llava:7b-v1.5-q8_0": "7.8GB",
+	"llava:7b-v1.6-mistral-q6_K": "6.6GB",
+	"llava:7b-v1.6-mistral-q8_0": "8.3GB",
+	"llava:7b-v1.6-vicuna-q8_0": "7.8GB",
+	"llava:13b-v1.5-q8_0": "14GB",
+	"llava:13b-v1.6-vicuna-q8_0": "14GB",
+	"llava:34b-v1.6-q6_K": "29GB",
+	"llava:34b-v1.6-q8_0": "37GB",
+	"llava:7b-v1.5-fp16": "14GB",
+	"llava:7b-v1.6-mistral-fp16": "15GB",
+	"llava:7b-v1.6-vicuna-fp16": "14GB",
+	"llava:13b-v1.5-fp16": "27GB",
+	"llava:13b-v1.6-vicuna-fp16": "27GB",
+	"llava:34b-v1.6-fp16": "69GB",
+	"llava-llama3:8b": "5.5GB",
+	"llava-llama3:8b-v1.1-fp16": "17GB",
+	"llava-llama3:8b-v1.1-q4_0": "5.5GB",
+	"llava-phi3:3.8b": "2.9GB",
+	"llava-phi3:3.8b-mini-fp16": "8.3GB",
+	"llava-phi3:3.8b-mini-q4_0": "2.9GB",
+	"magicoder:7b": "3.8GB",
+	"magicoder:7b-s-cl-q8_0": "7.2GB",
+	"magicoder:7b-s-cl-fp16": "13GB",
+	"mannix/llamax3-8b-alpaca:q4_0": "4.7GB",
+	"mannix/llamax3-8b-alpaca:q6_K": "6.6GB",
+	"mannix/llamax3-8b-alpaca:q8_0": "8.5GB",
+	"mannix/replete-adapted-llama3-8b:iq4_xs": "4.4GB",
+	"mannix/replete-adapted-llama3-8b:iq4_nl": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_0": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_k_s": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_k_m": "4.9GB",
+	"mannix/replete-adapted-llama3-8b:q4_1": "5.1GB",
+	"mannix/replete-adapted-llama3-8b:q5_0": "5.6GB",
+	"mannix/replete-adapted-llama3-8b:q5_1": "6.1GB",
+	"mannix/replete-adapted-llama3-8b:q5_k_s": "6.1GB",
+	"mannix/replete-adapted-llama3-8b:q6_k": "6.6GB",
+	"mannix/replete-adapted-llama3-8b:q8_0": "8.5GB",
+	"mannix/replete-adapted-llama3-8b:fp16": "16GB",
+	"mannix/replete-coder-llama3-8b:q8_0": "8.5GB",
+	"mannix/replete-coder-llama3-8b:fp16": "16GB",
+	"mannix/smaug-qwen2-72b:q4_0": "41GB",
+	"mannix/smaug-qwen2-72b:q5_1": "55GB",
+	"mannix/smaug-qwen2-72b:q6_K": "64GB",
+	"mannix/smaug-qwen2-72b:q8_0": "77GB",
+	"marco-o1:7b": "4.7GB",
+	"marco-o1:7b-fp16": "15GB",
+	"marco-o1:7b-q8_0": "8.1GB",
+	"mathstral:7b": "4.1GB",
+	"mathstral:7b-v0.1-q8_0": "7.7GB",
+	"mathstral:7b-v0.1-fp16": "14GB",
+	"meditron:7b": "3.8GB",
+	"meditron:70b": "39GB",
+	"meditron:7b-q8_0": "7.2GB",
+	"meditron:70b-q5_1": "52GB",
+	"meditron:7b-fp16": "13GB",
+	"medllama2:7b": "3.8GB",
+	"medllama2:7b-q8_0": "7.2GB",
+	"medllama2:7b-fp16": "13GB",
+	"megadolphin:120b": "68GB",
+	"megadolphin:v2.2": "68GB",
+	"megadolphin:120b-v2.2": "68GB",
+	"megadolphin:120b-v2.2-q6_K": "99GB",
+	"megadolphin:120b-v2.2-q8_0": "128GB",
+	"megadolphin:120b-v2.2-fp16": "241GB",
+	"minicpm-v:8b": "5.5GB",
+	"minicpm-v:8b-2.6-q6_K": "7.3GB",
+	"minicpm-v:8b-2.6-q8_0": "9.1GB",
+	"minicpm-v:8b-2.6-fp16": "16GB",
+	"mistral:7b": "4.1GB",
+	"mistral:instruct": "4.1GB",
+	"mistral:text": "4.1GB",
+	"mistral:v0.1": "4.1GB",
+	"mistral:v0.2": "4.1GB",
+	"mistral:v0.3": "4.1GB",
+	"mistral:7b-instruct": "4.1GB",
+	"mistral:7b-text": "4.1GB",
+	"mistral:7b-instruct-q6_K": "5.9GB",
+	"mistral:7b-instruct-v0.2-q6_K": "5.9GB",
+	"mistral:7b-instruct-v0.3-q6_K": "5.9GB",
+	"mistral:7b-text-q6_K": "5.9GB",
+	"mistral:7b-text-v0.2-q6_K": "5.9GB",
+	"mistral:7b-instruct-q8_0": "7.7GB",
+	"mistral:7b-instruct-v0.2-q8_0": "7.7GB",
+	"mistral:7b-instruct-v0.3-q8_0": "7.7GB",
+	"mistral:7b-text-q8_0": "7.7GB",
+	"mistral:7b-text-v0.2-q8_0": "7.7GB",
+	"mistral:7b-instruct-fp16": "14GB",
+	"mistral:7b-instruct-v0.2-fp16": "14GB",
+	"mistral:7b-instruct-v0.3-fp16": "14GB",
+	"mistral:7b-text-fp16": "14GB",
+	"mistral:7b-text-v0.2-fp16": "14GB",
+	"mistral-large:123b": "73GB",
+	"mistral-large:123b-instruct-2407-q6_K": "101GB",
+	"mistral-large:123b-instruct-2407-q8_0": "130GB",
+	"mistral-large:123b-instruct-2407-fp16": "245GB",
+	"mistral-large:123b-instruct-2411-q6_K": "101GB",
+	"mistral-large:123b-instruct-2411-q8_0": "130GB",
+	"mistral-large:123b-instruct-2411-fp16": "245GB",
+	"mistral-nemo:12b": "7.1GB",
+	"mistral-nemo:12b-instruct-2407-q8_0": "13GB",
+	"mistral-nemo:12b-instruct-2407-fp16": "25GB",
+	"mistral-openorca:7b": "4.1GB",
+	"mistral-openorca:7b-q8_0": "7.7GB",
+	"mistral-openorca:7b-fp16": "14GB",
+	"mistral-small:22b": "13GB",
+	"mistral-small:22b-instruct-2409-q5_0": "15GB",
+	"mistral-small:22b-instruct-2409-q5_K_S": "15GB",
+	"mistral-small:22b-instruct-2409-q5_K_M": "16GB",
+	"mistral-small:22b-instruct-2409-q8_0": "24GB",
+	"mistral-small:22b-instruct-2409-fp16": "44GB",
+	"mistrallite:7b": "4.1GB",
+	"mistrallite:7b-v0.1-q8_0": "7.7GB",
+	"mistrallite:7b-v0.1-fp16": "14GB",
+	"mixtral:8x7b": "26GB",
+	"mixtral:8x22b": "80GB",
+	"mixtral:instruct": "26GB",
+	"mixtral:text": "26GB",
+	"mixtral:v0.1": "80GB",
+	"mixtral:v0.1-instruct": "80GB",
+	"mixtral:8x22b-instruct": "80GB",
+	"mixtral:8x22b-text": "80GB",
+	"mixtral:8x7b-instruct-v0.1-q8_0": "50GB",
+	"mixtral:8x7b-text-v0.1-q8_0": "50GB",
+	"mixtral:8x22b-instruct-v0.1-q6_K": "115GB",
+	"mixtral:8x22b-text-v0.1-q6_K": "115GB",
+	"mixtral:8x22b-instruct-v0.1-q8_0": "149GB",
+	"mixtral:8x22b-text-v0.1-q8_0": "149GB",
+	"mixtral:8x7b-instruct-v0.1-fp16": "93GB",
+	"mixtral:8x7b-text-v0.1-fp16": "93GB",
+	"mixtral:8x22b-instruct-v0.1-fp16": "281GB",
+	"mixtral:8x22b-text-v0.1-fp16": "281GB",
+	"monotykamary/whiterabbitneo-v1.5a:7b": "4.1GB",
+	"monotykamary/whiterabbitneo-v1.5a:7b_q4_K_M": "4.1GB",
+	"moondream:1.8b": "1.7GB",
+	"moondream:v2": "1.7GB",
+	"moondream:1.8b-v2-q5_0": "1.9GB",
+	"moondream:1.8b-v2-q5_1": "2.0GB",
+	"moondream:1.8b-v2-q8_0": "2.4GB",
+	"moondream:1.8b-v2-fp16": "3.7GB",
+	"mxbai-embed-large:335m": "670MB",
+	"mxbai-embed-large:v1": "670MB",
+	"mxbai-embed-large:335m-v1-fp16": "670MB",
+	"nemotron:70b": "43GB",
+	"nemotron:70b-instruct-q6_K": "58GB",
+	"nemotron:70b-instruct-q8_0": "75GB",
+	"nemotron:70b-instruct-fp16": "141GB",
+	"nemotron-mini:4b": "2.7GB",
+	"nemotron-mini:4b-instruct-q6_K": "3.4GB",
+	"nemotron-mini:4b-instruct-q8_0": "4.5GB",
+	"nemotron-mini:4b-instruct-fp16": "8.4GB",
+	"neural-chat:7b": "4.1GB",
+	"neural-chat:7b-v3.1": "4.1GB",
+	"neural-chat:7b-v3.2": "4.1GB",
+	"neural-chat:7b-v3.3": "4.1GB",
+	"neural-chat:7b-v3.1-q8_0": "7.7GB",
+	"neural-chat:7b-v3.2-q8_0": "7.7GB",
+	"neural-chat:7b-v3.3-q8_0": "7.7GB",
+	"neural-chat:7b-v3.1-fp16": "14GB",
+	"neural-chat:7b-v3.2-fp16": "14GB",
+	"neural-chat:7b-v3.3-fp16": "14GB",
+	"nexusraven:13b": "7.4GB",
+	"nexusraven:13b-q8_0": "14GB",
+	"nexusraven:13b-v2-q8_0": "14GB",
+	"nexusraven:13b-fp16": "26GB",
+	"nexusraven:13b-v2-fp16": "26GB",
+	"nomic-embed-text:v1.5": "274MB",
+	"nomic-embed-text:137m-v1.5-fp16": "274MB",
+	"notus:7b": "4.1GB",
+	"notus:7b-v1": "4.1GB",
+	"notus:7b-v1-q8_0": "7.7GB",
+	"notus:7b-v1-fp16": "14GB",
+	"notux:8x7b": "26GB",
+	"notux:8x7b-v1": "26GB",
+	"notux:8x7b-v1-q8_0": "50GB",
+	"notux:8x7b-v1-fp16": "93GB",
+	"nous-hermes:7b": "3.8GB",
+	"nous-hermes:13b": "7.4GB",
+	"nous-hermes:7b-llama2": "3.8GB",
+	"nous-hermes:13b-llama2": "7.4GB",
+	"nous-hermes:13b-q6_K": "11GB",
+	"nous-hermes:7b-llama2-q6_K": "5.5GB",
+	"nous-hermes:13b-llama2-q6_K": "11GB",
+	"nous-hermes:70b-llama2-q6_K": "57GB",
+	"nous-hermes:13b-q8_0": "14GB",
+	"nous-hermes:7b-llama2-q8_0": "7.2GB",
+	"nous-hermes:13b-llama2-q8_0": "14GB",
+	//"nous-hermes:70b-llama2-q8_0": "GB",
+	"nous-hermes:13b-fp16": "26GB",
+	"nous-hermes:7b-llama2-fp16": "13GB",
+	"nous-hermes:13b-llama2-fp16": "26GB",
+	"nous-hermes:70b-llama2-fp16": "138GB",
+	"nous-hermes2:10.7b": "6.1GB",
+	"nous-hermes2:34b": "19GB",
+	"nous-hermes2:10.7b-solar-q5_0": "7.4GB",
+	"nous-hermes2:10.7b-solar-q5_1": "8.1GB",
+	"nous-hermes2:10.7b-solar-q6_K": "8.8GB",
+	"nous-hermes2:34b-yi-q6_K": "28GB",
+	"nous-hermes2:10.7b-solar-q8_0": "11GB",
+	"nous-hermes2:34b-yi-q8_0": "37GB",
+	"nous-hermes2:10.7b-solar-fp16": "21GB",
+	"nous-hermes2:34b-yi-fp16": "69GB",
+	"nous-hermes2-mixtral:8x7b": "26GB",
+	"nous-hermes2-mixtral:dpo": "26GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q4_0": "26GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q4_1": "29GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q5_0": "32GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q8_0": "50GB",
+	"nous-hermes2-mixtral:8x7b-dpo-fp16": "93GB",
+	"nqduc/gemsura:2b": "5.0GB",
+	"nqduc/gemsura:7b": "17.0GB",
+	"nqduc/gemsura:2b-q4_0": "1.6GB",
+	"nqduc/gemsura:2b-q8_0": "2.7GB",
+	"nqduc/gemsura:7b-q4_0": "5.0GB",
+	"nqduc/gemsura:7b-q8_0": "9.1GB",
+	"nqduc/mixsura:mixsura-q4_0": "26GB",
+	"nqduc/mixsura:mixsura-q4_1": "29GB",
+	"nqduc/mixsura:mixsura-q5_0": "32GB",
+	"nqduc/mixsura:mixsura-q5_1": "35GB",
+	"nqduc/mixsura:mixsura-q6_K": "38GB",
+	"nqduc/mixsura:mixsura-q8_0": "50GB",
+	"nqduc/mixsura:mixsura-fp16": "93GB",
+	"nqduc/mixsura-sft:mixsura-sft-fp16": "93GB",
+	"nqduc/mixsura-sft:mixsura-sft-q4_0": "26GB",
+	"nqduc/mixsura-sft:mixsura-sft-q4_1": "29GB",
+	"nqduc/mixsura-sft:mixsura-sft-q5_0": "32GB",
+	"nqduc/mixsura-sft:mixsura-sft-q5_1": "35GB",
+	"nqduc/mixsura-sft:mixsura-sft-q6_K": "38GB",
+	"nqduc/mixsura-sft:mixsura-sft-q8_0": "50GB",
+	"nuextract:3.8b": "2.2GB",
+	"nuextract:3.8-q8_0": "3.1GB",
+	"nuextract:3.8-fp16": "7.6GB",
+	"open-orca-platypus2:13b": "7.4GB",
+	"open-orca-platypus2:13b-q8_0": "14GB",
+	"open-orca-platypus2:13b-fp16": "26GB",
+	"openchat:7b": "4.1GB",
+	"openchat:7b-v3.5": "4.1GB",
+	"openchat:7b-v3.5-0106": "4.1GB",
+	"openchat:7b-v3.5-1210": "4.1GB",
+	"openchat:7b-v3.5-q8_0": "7.7GB",
+	"openchat:7b-v3.5-0106-q8_0": "7.7GB",
+	"openchat:7b-v3.5-1210-q8_0": "7.7GB",
+	"openchat:7b-v3.5-fp16": "14GB",
+	"openchat:7b-v3.5-0106-fp16": "14GB",
+	"openchat:7b-v3.5-1210-fp16": "14GB",
+	"openhermes:v2.5": "4.1GB",
+	"openhermes:v2": "4.1GB",
+	"openhermes:7b-v2": "4.1GB",
+	"openhermes:7b-v2.5": "4.1GB",
+	"openhermes:7b-mistral-v2-q8_0": "7.7GB",
+	"openhermes:7b-mistral-v2.5-q8_0": "7.7GB",
+	"openhermes:7b-mistral-v2-fp16": "14GB",
+	"openhermes:7b-mistral-v2.5-fp16": "14GB",
+	"orca-mini:3b": "2.0GB",
+	"orca-mini:7b": "3.8GB",
+	"orca-mini:13b": "7.4GB",
+	"orca-mini:70b": "39GB",
+	"orca-mini:7b-v3": "3.8GB",
+	"orca-mini:13b-v3": "7.4GB",
+	"orca-mini:70b-v3": "39GB",
+	"orca-mini:3b-q8_0": "3.6GB",
+	"orca-mini:7b-q8_0": "7.2GB",
+	"orca-mini:13b-q8_0": "14GB",
+	"orca-mini:7b-v2-q8_0": "7.2GB",
+	"orca-mini:7b-v3-q8_0": "7.2GB",
+	"orca-mini:13b-v2-q8_0": "14GB",
+	"orca-mini:13b-v3-q8_0": "14GB",
+	"orca-mini:70b-v3-q6_K": "57GB",
+	"orca-mini:70b-v3-q8_0": "73GB",
+	"orca-mini:3b-fp16": "6.9GB",
+	"orca-mini:7b-fp16": "13GB",
+	"orca-mini:13b-fp16": "26GB",
+	"orca-mini:7b-v2-fp16": "13GB",
+	"orca-mini:7b-v3-fp16": "13GB",
+	"orca-mini:13b-v2-fp16": "26GB",
+	"orca-mini:13b-v3-fp16": "26GB",
+	"orca-mini:70b-v3-fp16": "138GB",
+	"orca2:7b": "3.8GB",
+	"orca2:13b": "7.4GB",
+	"orca2:7b-q8_0": "7.2GB",
+	"orca2:13b-q8_0": "14GB",
+	"orca2:7b-fp16": "13GB",
+	"orca2:13b-fp16": "26GB",
+	"paraphrase-multilingual:278m": "563MB",
+	"paraphrase-multilingual:278m-mpnet-base-v2-fp16": "563MB",
+	"partai/dorna-llama3:8b-instruct-q4_0": "4.7GB",
+	"partai/dorna-llama3:8b-instruct-q5_0": "5.6GB",
+	"partai/dorna-llama3:8b-instruct-q8_0": "8.5GB",
+	"phi:2.7": "1.6GB",
+	"phi:chat": "1.6GB",
+	"phi:2.7b-chat-v2-q5_0": "1.9GB",
+	"phi:2.7b-chat-v2-q5_1": "2.1GB",
+	"phi:2.7b-chat-v2-q8_0": "2.3GB",
+	"phi:2.7b-chat-v2-fp16": "5.6GB",
+	"phi3:3.8b": "2.2GB",
+	"phi3:14b": "7.9GB",
+	"phi3:instruct": "2.2GB",
+	"phi3:medium": "7.9GB",
+	"phi3:medium-128k": "7.9GB",
+	"phi3:medium-4k": "7.9GB",
+	"phi3:mini": "2.2GB",
+	"phi3:mini-128k": "2.2GB",
+	"phi3:mini-4k": "2.2GB",
+	"phi3:3.8b-instruct": "2.2GB",
+	"phi3:14b-instruct": "7.9GB",
+	"phi3:3.8b-mini-128k-instruct-q8_0": "4.1GB",
+	"phi3:3.8b-mini-4k-instruct-q8_0": "4.1GB",
+	"phi3:14b-medium-128k-instruct-q8_0": "15GB",
+	"phi3:14b-medium-4k-instruct-q8_0": "15GB",
+	"phi3:3.8b-mini-128k-instruct-fp16": "7.6GB",
+	"phi3:3.8b-mini-4k-instruct-fp16": "7.6GB",
+	"phi3:14b-medium-128k-instruct-fp16": "28GB",
+	"phi3:14b-medium-4k-instruct-fp16": "28GB",
+	"phi3.5:3.8b": "2.2GB",
+	"phi3.5:3.8b-mini-instruct-q8_0": "4.1GB",
+	"phi3.5:3.8b-mini-instruct-fp16": "7.6GB",
+	"phind-codellama:34b": "19GB",
+	"phind-codellama:34b-python": "19GB",
+	"phind-codellama:34b-v2": "19GB",
+	"phind-codellama:34b-q6_K": "28GB",
+	"phind-codellama:34b-python-q6_K": "28GB",
+	"phind-codellama:34b-q8_0": "36GB",
+	"phind-codellama:34b-python-q8_0": "36GB",
+	"phind-codellama:34b-fp16": "67GB",
+	"phind-codellama:34b-python-fp16": "67GB",
+	"qwen:0.5b": "395MB",
+	"qwen:1.8b": "1.1GB",
+	"qwen:4b": "2.3GB",
+	"qwen:7b": "4.5GB",
+	"qwen:14b": "8.2GB",
+	"qwen:32b": "18GB",
+	"qwen:72b": "41GB",
+	"qwen:110b": "63GB",
+	"qwen:0.5b-chat": "395MB",
+	"qwen:0.5b-text": "395MB",
+	"qwen:1.8b-chat": "1.1GB",
+	"qwen:1.8b-text": "1.1GB",
+	"qwen:4b-chat": "2.3GB",
+	"qwen:4b-text": "2.3GB",
+	"qwen:7b-chat": "4.5GB",
+	"qwen:7b-text": "4.5GB",
+	"qwen:14b-chat": "8.2GB",
+	"qwen:14b-text": "8.2GB",
+	"qwen:32b-chat": "18GB",
+	"qwen:32b-text": "18GB",
+	"qwen:72b-chat": "41GB",
+	"qwen:72b-text": "63GB",
+	"qwen:110b-chat": "63GB",
+	"qwen:7b-fp16": "15GB",
+	"qwen:0.5b-chat-v1.5-q8_0": "556MB",
+	"qwen:0.5b-text-v1.5-q8_0": "665MB",
+	"qwen:1.8b-chat-q8_0": "2.0GB",
+	"qwen:1.8b-chat-v1.5-q8_0": "2.0GB",
+	"qwen:1.8b-text-q8_0": "2.0GB",
+	"qwen:1.8b-text-v1.5-q8_0": "2.0GB",
+	"qwen:4b-chat-v1.5-q8_0": "4.2GB",
+	"qwen:4b-text-v1.5-q8_0": "4.2GB",
+	"qwen:7b-chat-q8_0": "8.2GB",
+	"qwen:7b-chat-v1.5-q8_0": "8.2GB",
+	"qwen:7b-text-v1.5-q8_0": "8.2GB",
+	"qwen:14b-chat-q8_0": "15GB",
+	"qwen:14b-chat-v1.5-q8_0": "15GB",
+	"qwen:14b-text-q8_0": "15GB",
+	"qwen:14b-text-v1.5-q8_0": "15GB",
+	"qwen:32b-chat-v1.5-q8_0": "35GB",
+	"qwen:32b-text-v1.5-q8_0": "35GB",
+	"qwen:72b-chat-q8_0": "77GB",
+	"qwen:72b-chat-v1.5-q8_0": "77GB",
+	"qwen:72b-text-q8_0": "77GB",
+	"qwen:72b-text-v1.5-q8_0": "77GB",
+	"qwen:110b-chat-v1.5-q8_0": "118GB",
+	"qwen:110b-text-v1.5-q8_0": "118GB",
+	"qwen:0.5b-chat-v1.5-fp16": "1.2GB",
+	"qwen:0.5b-text-v1.5-fp16": "1.2GB",
+	"qwen:1.8b-chat-fp16": "3.7GB",
+	"qwen:1.8b-chat-v1.5-fp16": "3.7GB",
+	"qwen:1.8b-text-fp16": "3.7GB",
+	"qwen:1.8b-text-v1.5-fp16": "3.7GB",
+	"qwen:4b-chat-v1.5-fp16": "7.9GB",
+	"qwen:4b-text-v1.5-fp16": "7.9GB",
+	"qwen:7b-chat-fp16": "15GB",
+	"qwen:7b-chat-v1.5-fp16": "15GB",
+	"qwen:7b-text-v1.5-fp16": "15GB",
+	"qwen:14b-chat-fp16": "28GB",
+	"qwen:14b-chat-v1.5-fp16": "28GB",
+	"qwen:14b-text-fp16": "28GB",
+	"qwen:14b-text-v1.5-fp16": "28GB",
+	"qwen:32b-chat-v1.5-fp16": "65GB",
+	"qwen:72b-chat-fp16": "145GB",
+	"qwen:72b-chat-v1.5-fp16": "145GB",
+	"qwen:72b-text-fp16": "145GB",
+	"qwen:72b-text-v1.5-fp16": "145GB",
+	"qwen:110b-chat-v1.5-fp16": "222GB",
+	"qwen:110b-text-v1.5-fp16": "222GB",
+	"qwen2:0.5b": "352MB",
+	"qwen2:1.5b": "935MB",
+	"qwen2:7b": "4.4GB",
+	"qwen2:72b": "41GB",
+	"qwen2:0.5b-instruct": "352MB",
+	"qwen2:1.5b-instruct": "935MB",
+	"qwen2:7b-instruct": "4.4GB",
+	"qwen2:7b-text": "4.4GB",
+	"qwen2:72b-instruct": "41GB",
+	"qwen2:72b-text": "41GB",
+	"qwen2:0.5b-instruct-q8_0": "531MB",
+	"qwen2:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2:7b-instruct-q8_0": "8.1GB",
+	"qwen2:7b-text-q8_0": "8.1GB",
+	"qwen2:72b-instruct-q8_0": "77GB",
+	"qwen2:72b-text-q8_0": "77GB",
+	"qwen2:0.5b-instruct-fp16": "994MB",
+	"qwen2:1.5b-instruct-fp16": "3.1GB",
+	"qwen2:7b-instruct-fp16": "15GB",
+	"qwen2:72b-instruct-fp16": "145GB",
+	"qwen2:72b-text-fp16": "145GB",
+	"qwen2-math:1.5b": "935MB",
+	"qwen2-math:7b": "4.4GB",
+	"qwen2-math:72b": "41GB",
+	"qwen2-math:1.5b-instruct": "935MB",
+	"qwen2-math:7b-instruct": "4.4GB",
+	"qwen2-math:72b-instruct": "41GB",
+	"qwen2-math:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2-math:7b-instruct-q6_K": "6.3GB",
+	"qwen2-math:7b-instruct-q8_0": "8.1GB",
+	"qwen2-math:72b-instruct-q6_K": "64GB",
+	"qwen2-math:72b-instruct-q8_0": "77GB",
+	"qwen2-math:1.5b-instruct-fp16": "3.1GB",
+	"qwen2-math:7b-instruct-fp16": "15GB",
+	"qwen2-math:72b-instruct-fp16": "145GB",
+	"qwen2.5:0.5b": "398MB",
+	"qwen2.5:1.5b": "986MB",
+	"qwen2.5:3b": "1.9GB",
+	"qwen2.5:7b": "4.7GB",
+	"qwen2.5:14b": "9.0GB",
+	"qwen2.5:32b": "20.0GB",
+	"qwen2.5:72b": "47.0GB",
+	"qwen2.5:0.5b-base": "398MB",
+	"qwen2.5:0.5b-instruct": "398MB",
+	"qwen2.5:1.5b-instruct": "986MB",
+	"qwen2.5:3b-instruct": "1.9GB",
+	"qwen2.5:7b-instruct": "4.7GB",
+	"qwen2.5:14b-instruct": "9.0GB",
+	"qwen2.5:32b-instruct": "20GB",
+	"qwen2.5:72b-instruct": "47GB",
+	"qwen2.5:7b-instruct-q6_K": "6.3GB",
+	"qwen2.5:32b-instruct-q6_K": "27GB",
+	"qwen2.5:72b-instruct-q6_K": "64GB",
+	"qwen2.5:0.5b-instruct-q8_0": "531MB",
+	"qwen2.5:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2.5:3b-instruct-q8_0": "3.3GB",
+	"qwen2.5:7b-instruct-q8_0": "8.1GB",
+	"qwen2.5:14b-instruct-q8_0": "16GB",
+	"qwen2.5:32b-instruct-q8_0": "35GB",
+	"qwen2.5:72b-instruct-q8_0": "77GB",
+	"qwen2.5:0.5b-instruct-fp16": "994MB",
+	"qwen2.5:1.5b-instruct-fp16": "3.1GB",
+	"qwen2.5:3b-instruct-fp16": "6.2GB",
+	"qwen2.5:7b-instruct-fp16": "15GB",
+	"qwen2.5:14b-instruct-fp16": "30GB",
+	"qwen2.5:32b-instruct-fp16": "66GB",
+	"qwen2.5:72b-instruct-fp16": "145GB",
+	"qwen2.5-coder:1.5b": "986MB",
+	"qwen2.5-coder:7b": "4.7GB",
+	"qwen2.5-coder:1.5b-base": "986MB",
+	"qwen2.5-coder:1.5b-instruct": "986MB",
+	"qwen2.5-coder:7b-base": "4.7GB",
+	"qwen2.5-coder:7b-instruct": "4.7GB",
+	"qwen2.5-coder:1.5b-base-fp16": "3.1GB",
+	"qwen2.5-coder:1.5b-instruct-fp16": "3.1GB",
+	"qwen2.5-coder:7b-base-fp16": "15GB",
+	"qwen2.5-coder:7b-instruct-fp16": "15GB",
+	"qwq:32b": "20GB",
+	"qwq:32b-preview-fp16": "66GB",
+	"qwq:32b-preview-q8_0": "35GB",
+	"reader-lm:0.5b": "352MB",
+	"reader-lm:1.5b": "935MB",
+	"reader-lm:0.5b-q5_1": "419MB",
+	"reader-lm:1.5b-q5_1": "1.2GB",
+	"reader-lm:0.5b-q6_K": "506MB",
+	"reader-lm:1.5b-q6_K": "1.3GB",
+	"reader-lm:0.5b-q8_0": "531MB",
+	"reader-lm:1.5b-q8_0": "1.6GB",
+	"reader-lm:0.5b-fp16": "994MB",
+	"reader-lm:1.5b-fp16": "3.1GB",
+//	"reefer/erplegend": "4.7GB",
+	"reefer/her2": "4.7GB",
+	"reefer/minimonica": "2.1GB",
+	"reefer/monica": "4.7GB",
+//	"reefer/monicacodestral22b": "8.3GB",
+//	"reefer/monicamaxlvl": "4.7GB",
+//	"reefer/reefloaded": "4.9GB",
+//	"reefer/erphermesl3": "6.6",
+//	"reefer/reefproherm2llama3instruct": "5.7GB",
+	"reflection:70b": "40GB",
+	"reflection:70b-q6_K": "58GB",
+	"reflection:70b-q8_0": "75GB",
+	"reflection:70b-fp16": "141GB",
+	"rfc/whiterabbitneo": "7.4GB",
+	"rouge/replete-coder-qwen2-1.5b:latest": "6.2GB",
+	"rouge/replete-coder-qwen2-1.5b:Q8": "1.9GB",
+	"rouge/replete-coder-qwen2-1.5b:f16": "3.1GB",
+	"samantha-mistral:7b": "4.1GB",
+	"samantha-mistral:7b-text": "4.1GB",
+	"samantha-mistral:7b-v1.2-text": "4.1GB",
+	"samantha-mistral:7b-instruct-q8_0": "7.7GB",
+	"samantha-mistral:7b-text-q8_0": "7.7GB",
+	"samantha-mistral:7b-v1.2-text-q8_0": "7.7GB",
+	"samantha-mistral:7b-instruct-fp16": "14GB",
+	"samantha-mistral:7b-text-fp16": "14GB",
+	"samantha-mistral:7b-v1.2-text-fp16": "14GB",
+	"sammcj/smaug-mixtral-v0.1:70b-q4_k_m": "28GB",
+	"sammcj/smaug-mixtral-v0.1:8x7b-70b-q4_k_m": "28GB",
+	"savethedoctor/whiterabbitneo13bq8_0": "14GB",
+	"shieldgemma:2b": "1.7GB",
+	"shieldgemma:9b": "5.8GB",
+	"shieldgemma:27b": "17GB",
+	"shieldgemma:2b-fp16": "5.2GB",
+	"shieldgemma:9b-fp16": "18GB",
+	"shieldgemma:27b-fp16": "54GB",
+	"smollm:135m": "92MB",
+	"smollm:360m": "229MB",
+	"smollm:1.7b": "991MB",
+	"smollm:135m-base-v0.2-fp16": "271MB",
+	"smollm:135m-base-v0.2-q4_0": "92MB",
+	"smollm:135m-base-v0.2-q4_1": "98MB",
+	"smollm:135m-base-v0.2-q4_K_S": "102MB",
+	"smollm:135m-base-v0.2-q4_K_M": "105MB",
+	"smollm:135m-base-v0.2-q5_0": "105MB",
+	"smollm:135m-base-v0.2-q5_1": "112MB",
+	"smollm:135m-base-v0.2-q5_K_S": "110MB",
+	"smollm:135m-base-v0.2-q5_K_M": "112MB",
+	"smollm:135m-base-v0.2-q6_K": "138MB",
+	"smollm:135m-base-v0.2-q6_0": "145MB",
+	"smollm:135m-instruct-v0.2-fp16": "271MB",
+	"smollm:135m-instruct-v0.2-q4_0": "92MB",
+	"smollm:135m-instruct-v0.2-q4_1": "98MB",
+	"smollm:135m-instruct-v0.2-q4_K_S": "102MB",
+	"smollm:135m-instruct-v0.2-q4_K_M": "105MB",
+	"smollm:135m-instruct-v0.2-q5_0": "105MB",
+	"smollm:135m-instruct-v0.2-q5_1": "112MB",
+	"smollm:135m-instruct-v0.2-q5_K_S": "110MB",
+	"smollm:135m-instruct-v0.2-q5_K_M": "112MB",
+	"smollm:135m-instruct-v0.2-q6_K": "138MB",
+	"smollm:135m-instruct-v0.2-q8_0": "145MB",
+	"smollm:360m-base-v0.2-fp16": "726MB",
+	"smollm:360m-base-v0.2-q4_0": "229MB",
+	"smollm:360m-base-v0.2-q4_1": "249MB",
+	"smollm:360m-base-v0.2-q4_K_S": "260MB",
+	"smollm:360m-base-v0.2-q4_K_M": "271MB",
+	"smollm:360m-base-v0.2-q5_0": "268MB",
+	"smollm:360m-base-v0.2-q5_1": "288MB",
+	"smollm:360m-base-v0.2-q5_K_S": "283MB",
+	"smollm:360m-base-v0.2-q5_K_M": "290MB",
+	"smollm:360m-base-v0.2-q6_K": "367MB",
+	"smollm:360m-base-v0.2-q8_K": "386MB",
+	"smollm:360m-instruct-v0.2-fp16": "726MB",
+	"smollm:360m-instruct-v0.2-q4_0": "229MB",
+	"smollm:360m-instruct-v0.2-q4_1": "249MB",
+	"smollm:360m-instruct-v0.2-q4_K_S": "260MB",
+	"smollm:360m-instruct-v0.2-q4_K_M": "271MB",
+	"smollm:360m-instruct-v0.2-q5_0": "268MB",
+	"smollm:360m-instruct-v0.2-q5_1": "288MB",
+	"smollm:360m-instruct-v0.2-q5_K_S": "283MB",
+	"smollm:360m-instruct-v0.2-q5_K_M": "290MB",
+	"smollm:360m-instruct-v0.2-q6_K": "367MB",
+	"smollm:360m-instruct-v0.2-q8_0": "386MB",
+	"smollm:1.7b-base-v0.2-fp16": "3.4GB",
+	"smollm:1.7b-base-v0.2-q4_0": "991MB",
+	"smollm:1.7b-base-v0.2-q4_1": "1.1GB",
+	"smollm:1.7b-base-v0.2-q4_K_S": "999MB",
+	"smollm:1.7b-base-v0.2-q4_K_M": "1.1GB",
+	"smollm:1.7b-base-v0.2-q5_0": "1.2GB",
+	"smollm:1.7b-base-v0.2-q5_1": "1.3GB",
+	"smollm:1.7b-base-v0.2-q5_K_S": "1.2GB",
+	"smollm:1.7b-base-v0.2-q5_K_M": "1.2GB",
+	"smollm:1.7b-base-v0.2-q6_K": "1.4GB",
+	"smollm:1.7b-base-v0.2-q8_K": "1.8GB",
+	"smollm:1.7b-instruct-v0.2-fp16": "3.4GB",
+	"smollm:1.7b-instruct-v0.2-q4_0": "991MB",
+	"smollm:1.7b-instruct-v0.2-q4_1": "1.1GB",
+	"smollm:1.7b-instruct-v0.2-q4_K_S": "999MB",
+	"smollm:1.7b-instruct-v0.2-q4_K_M": "1.1GB",
+	"smollm:1.7b-instruct-v0.2-q5_0": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q5_1": "1.3GB",
+	"smollm:1.7b-instruct-v0.2-q5_K_S": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q5_K_M": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q6_K": "1.4GB",
+	"smollm:1.7b-instruct-v0.2-q8_K": "1.8GB",
+	"snowflake-arctic-embed:22m": "46MB",
+	"snowflake-arctic-embed:33m": "67MB",
+	"snowflake-arctic-embed:110m": "219MB",
+	"snowflake-arctic-embed:137m": "274MB",
+	"snowflake-arctic-embed:335m": "669MB",
+	"snowflake-arctic-embed:l": "669MB",
+	"snowflake-arctic-embed:m": "219MB",
+	"snowflake-arctic-embed:m-long": "274MB",
+	"snowflake-arctic-embed:s": "67MB",
+	"snowflake-arctic-embed:xs": "46MB",
+	"snowflake-arctic-embed:22m-xs-fp16": "46MB",
+	"snowflake-arctic-embed:33m-s-fp16": "67MB",
+	"snowflake-arctic-embed:110m-m-fp16": "219MB",
+	"snowflake-arctic-embed:137m-m-long-fp16": "274MB",
+	"snowflake-arctic-embed:335m-l-fp16": "669MB",
+	"solar:10.7b": "6.1GB",
+	"solar:10.7b-instruct-v1-q5_0": "7.4GB",
+	"solar:10.7b-text-v1-q5_0": "7.4GB",
+	"solar:10.7b-instruct-v1-q8_0": "11GB",
+	"solar:10.7b-text-v1-q8_0": "11GB",
+	"solar:10.7b-instruct-v1-fp16": "21GB",
+	"solar:10.7b-text-v1-fp16": "21GB",
+	"solar-pro:22b": "13GB",
+	"solar-pro:preview": "13GB",
+	"solar-pro:22b-preview-instruct-q5_K_S": "15GB",
+	"solar-pro:22b-preview-instruct-q5_K_M": "16GB",
+	"solar-pro:22b-preview-instruct-q8_0": "24GB",
+	"solar-pro:22b-preview-instruct-fp16": "44GB",
+	"sparksammy/samantha": "3.8GB",
+	"sparksammy/samantha-3.1": "4.7GB",
+	"sparksammy/samantha-eggplant": "11GB",
+	"sparksammy/samantha-v3-uncensored": "4.7GB",
+	"sparksammy/tinysam-goog": "1.7GB",
+	"sparksammy/tinysam-msft": "2.3GB",
+	"sqlcoder:7b": "4.1GB",
+	"sqlcoder:15b": "9GB",
+	"sqlcoder:7b-q8_0": "7.7GB",
+	"sqlcoder:15b-q6_K": "13GB",
+	"sqlcoder:70b-alpha-q6_K": "57GB",
+	"sqlcoder:7b-fp16": "14GB",
+	"sqlcoder:15b-fp16": "32GB",
+	"sqlcoder:70b-alpha-fp16": "138GB",
+	"stable-beluga:7b": "3.8GB",
+	"stable-beluga:13b": "7.4GB",
+	"stable-beluga:70b": "39GB",
+	"stable-beluga:7b-q8_0": "7.2GB",
+	"stable-beluga:13b-q8_0": "14GB",
+	"stable-beluga:70b-q6_K": "57GB",
+	"stable-beluga:70b-q8_0": "73GB",
+	"stable-beluga:7b-fp16": "13GB",
+	"stable-beluga:13b-fp16": "26GB",
+	"stable-beluga:70b-fp16": "138GB",
+	"stable-code:3b": "1.6GB",
+	"stable-code:code": "1.6GB",
+	"stable-code:instruct": "1.6GB",
+	"stable-code:3b-code": "1.6GB",
+	"stable-code:3b-instruct": "1.6GB",
+	"stable-code:3b-code-q5_0": "1.9GB",
+	"stable-code:3b-instruct-q5_0": "1.9GB",
+	"stable-code:3b-code-q5_1": "2.1GB",
+	"stable-code:3b-instruct-q5_1": "2.1GB",
+	"stable-code:3b-code-q6_K": "2.3GB",
+	"stable-code:3b-instruct-q6_K": "2.3GB",
+	"stable-code:3b-code-q8_0": "3.0GB",
+	"stable-code:3b-instruct-q8_0": "3.0GB",
+	"stable-code:3b-code-fp16": "5.6GB",
+	"stable-code:3b-instruct-fp16": "5.6GB",
+	"stablelm-zephyr:3b": "1.6GB",
+	"stablelm-zephyr:3b-q5_0": "1.9GB",
+	"stablelm-zephyr:3b-q5_1": "2.1GB",
+	"stablelm-zephyr:3b-q8_0": "3.0GB",
+	"stablelm-zephyr:3b-fp16": "5.6GB",
+	"stablelm2:1.6b": "983MB",
+	"stablelm2:12b": "7.0GB",
+	"stablelm2:chat": "983MB",
+	"stablelm2:zephyr": "983MB",
+	"stablelm2:1.6b-chat": "983MB",
+	"stablelm2:1.6b-zephyr": "983MB",
+	"stablelm2:12b-chat": "7.0GB",
+	"stablelm2:12b-zephyr": "7.0GB",
+	"stablelm2:1.6b-q8_0": "1.8GB",
+	"stablelm2:12b-q8_0": "13GB",
+	"stablelm2:1.6b-chat-q8_0": "1.8GB",
+	"stablelm2:1.6b-zephyr-q8_0": "1.8GB",
+	"stablelm2:12b-chat-q8_0": "13GB",
+	"stablelm2:1.6b-fp16": "3.3GB",
+	"stablelm2:12b-fp16": "24GB",
+	"stablelm2:1.6b-chat-fp16": "3.3GB",
+	"stablelm2:1.6b-zephyr-fp16": "3.3GB",
+	"stablelm2:12b-chat-fp16": "24GB",
+	"starcoder:1b": "726MB",
+	"starcoder:3b": "1.8GB",
+	"starcoder:7b": "4.3GB",
+	"starcoder:15b": "9.0GB",
+	"starcoder:1b-base": "726MB",
+	"starcoder:3b-base": "1.8GB",
+	"starcoder:7b-base": "4.3GB",
+	"starcoder:15b-base": "9.0GB",
+	"starcoder:15b-plus": "9.0GB",
+	"starcoder:15b-q6_K": "13GB",
+	"starcoder:15b-q8_0": "17GB",
+	"starcoder:1b-base-q8_0": "1.3GB",
+	"starcoder:3b-base-q8_0": "3.4GB",
+	"starcoder:7b-base-q8_0": "8GB",
+	"starcoder:15b-base-q6_K": "13GB",
+	"starcoder:15b-plus-q6_K": "13GB",
+	"starcoder:15b-base-q8_0": "17GB",
+	"starcoder:15b-plus-q8_0": "17GB",
+	"starcoder:15b-fp16": "32GB",
+	"starcoder:1b-base-fp16": "2.5GB",
+	"starcoder:3b-base-fp16": "6.4GB",
+	"starcoder:7b-base-fp16": "15GB",
+	"starcoder:15b-base-fp16": "32GB",
+	"starcoder:15b-plus-fp16": "32GB",
+	"starcoder2:3b": "1.7GB",
+	"starcoder2:7b": "4.0GB",
+	"starcoder2:15b": "9.1GB",
+	"starcoder2:instruct": "9.1GB",
+	"starcoder2:15b-instruct": "9.1GB",
+	"starcoder2:3b-q8_0": "3.2GB",
+	"starcoder2:7b-q8_0": "7.6GB",
+	"starcoder2:15b-q6_K": "13GB",
+	"starcoder2:15b-q8_0": "17GB",
+	"starcoder2:15b-instruct-v0.1-q6_K": "13GB",
+	"starcoder2:15b-instruct-v0.1-q8_0": "17GB",
+	"starcoder2:15b-instruct-v0.1-fp16": "32GB",
+	"starling-lm:7b": "4.1GB",
+	"starling-lm:alpha": "4.1GB",
+	"starling-lm:beta": "4.1GB",
+	"starling-lm:7b-alpha": "4.1GB",
+	"starling-lm:7b-beta": "4.1GB",
+	"starling-lm:7b-alpha-q8_0": "7.7GB",
+	"starling-lm:7b-beta-q8_0": "7.7GB",
+	"starling-lm:7b-alpha-fp16": "14GB",
+	"starling-lm:7b-beta-fp16": "14GB",
+	"themanofrod/travel-agent": "1.7GB",
+	"tinydolphin:1.1b": "637MB",
+	"tinydolphin:v2.8": "637MB",
+	"tinydolphin:1.1b-v2.8-fp16": "2.2GB",
+	"tinydolphin:1.1b-v2.8-q4_0": "637MB",
+	"tinydolphin:1.1b-v2.8-q4_1": "701MB",
+	"tinydolphin:1.1b-v2.8-q4_K_S": "640MB",
+	"tinydolphin:1.1b-v2.8-q4_K_M": "668MB",
+	"tinydolphin:1.1b-v2.8-q5_0": "766MB",
+	"tinydolphin:1.1b-v2.8-q5_1": "831MB",
+	"tinydolphin:1.1b-v2.8-q5_K_S": "766MB",
+	"tinydolphin:1.1b-v2.8-q5_K_M": "782MB",
+	"tinydolphin:1.1b-v2.8-q6_K": "903MB",
+	"tinydolphin:1.1b-v2.8-q8_0": "1.2GB",
+	"tinyllama:1.1b": "638MB",
+	"tinyllama:chat": "638MB",
+	"tinyllama:v0.6": "638MB",
+	"tinyllama:v1": "638MB",
+	"tinyllama:1.1b-chat": "638MB",
+	"tinyllama:1.1b-chat-v0.6-q4_0": "638MB",
+	"tinyllama:1.1b-chat-v0.6-q4_1": "702MB",
+	"tinyllama:1.1b-chat-v0.6-q4_K_S": "644MB",
+	"tinyllama:1.1b-chat-v0.6-q4_K_M": "669MB",
+	"tinyllama:1.1b-chat-v0.6-q5_0": "767MB",
+	"tinyllama:1.1b-chat-v0.6-q5_1": "832MB",
+	"tinyllama:1.1b-chat-v0.6-q5_K_S": "767MB",
+	"tinyllama:1.1b-chat-v0.6-q5_K_M": "783MB",
+	"tinyllama:1.1b-chat-v0.6-q6_K": "904MB",
+	"tinyllama:1.1b-chat-v0.6-q8_0": "1.2GB",
+	"tinyllama:1.1b-chat-v1-fp16": "2.2GB",
+	"tinyllama:1.1b-chat-v1-q4_0": "638MB",
+	"tinyllama:1.1b-chat-v1-q4_1": "702MB",
+	"tinyllama:1.1b-chat-v1-q4_K_S": "644MB",
+	"tinyllama:1.1b-chat-v1-q4_K_M": "669MB",
+	"tinyllama:1.1b-chat-v1-q5_0": "767MB",
+	"tinyllama:1.1b-chat-v1-q5_1": "832MB",
+	"tinyllama:1.1b-chat-v1-q5_K_S": "767MB",
+	"tinyllama:1.1b-chat-v1-q5_K_M": "783MB",
+	"tinyllama:1.1b-chat-v1-q6_K": "904MB",
+	"tinyllama:1.1b-chat-v1-q8_0": "1.2GB",
+	"tulu3:8b": "4.9GB",
+	"tulu3:70b": "43GB",
+	"tulu3:70b-q8_0": "75GB",
+	"tulu3:70b-fp16": "141GB",
+	"tulu3:8b-q8_0": "8.5GB",
+	"tulu3:8b-fp16": "16GB",
+	"vicuna:7b": "3.8GB",
+	"vicuna:13b": "7.4GB",
+	"vicuna:33b": "18GB",
+	"vicuna:7b-16k": "3.8GB",
+	"vicuna:13b-16k": "7.4GB",
+	"vicuna:33b-16k": "18GB",
+	"vicuna:7b-q6_K": "5.5GB",
+	"vicuna:13b-q6_K": "11GB",
+	"vicuna:33b-q6_K": "27GB",
+	"vicuna:7b-v1.5-q6_K": "5.5GB",
+	"vicuna:7b-v1.5-16k-q6_K": "5.5GB",
+	"vicuna:13b-16k-q6_K": "11GB",
+	"vicuna:13b-v1.5-16k-q6_K": "11GB",
+	"vicuna:7b-q8_0": "7.2GB",
+	"vicuna:13b-q8_0": "14GB",
+	"vicuna:33b-q8_0": "35GB",
+	"vicuna:7b-v1.5-q8_0": "7.2GB",
+	"vicuna:7b-v1.5-16k-q8_0": "7.2GB",
+	"vicuna:13b-16k-q8_0": "14GB",
+	"vicuna:13b-v1.5-16k-q8_0": "14GB",
+	"vicuna:7b-fp16": "13GB",
+	"vicuna:13b-fp16": "26GB",
+	"vicuna:33b-fp16": "65GB",
+	"vicuna:7b-v1.5-fp16": "13GB",
+	"vicuna:7b-v1.5-16k-fp16": "13GB",
+	"vicuna:13b-16k-fp16": "26GB",
+	"vicuna:13b-v1.5-16k-fp16": "26GB",
+	"wizard-math:7b": "4.1GB",
+	"wizard-math:13b": "7.4GB",
+	"wizard-math:70b": "39GB",
+	"wizard-math:7b-q6_K": "5.5GB",
+	"wizard-math:13b-q6_K": "11GB",
+	"wizard-math:70b-q6_K": "57GB",
+	"wizard-math:7b-v1.1-q6_K": "5.9GB",
+	"wizard-math:7b-q8_0": "7.2GB",
+	"wizard-math:13b-q8_0": "14GB",
+	"wizard-math:70b-q8_0": "73GB",
+	"wizard-math:7b-v1.1-q8_0": "7.7GB",
+	"wizard-math:7b-fp16": "13GB",
+	"wizard-math:13b-fp16": "26GB",
+	"wizard-math:70b-fp16": "138GB",
+	"wizard-math:7b-v1.1-fp16": "14GB",
+	"wizard-vicuna:13b": "7.4GB",
+	"wizard-vicuna:13b-q8_0": "14GB",
+	"wizard-vicuna:13b-fp16": "26GB",
+	"wizard-vicuna-uncensored:7b": "3.8GB",
+	"wizard-vicuna-uncensored:13b": "7.4GB",
+	"wizard-vicuna-uncensored:30b": "18GB",
+	"wizard-vicuna-uncensored:7b-q8_0": "7.2GB",
+	"wizard-vicuna-uncensored:13b-q8_0": "14GB",
+	"wizard-vicuna-uncensored:30b-q6_K": "27GB",
+	"wizard-vicuna-uncensored:30b-q8_0": "35GB",
+	"wizard-vicuna-uncensored:7b-fp16": "13GB",
+	"wizard-vicuna-uncensored:13b-fp16": "26GB",
+	"wizard-vicuna-uncensored:30b-fp16": "65GB",
+	"wizardcoder:33b": "19GB",
+	"wizardcoder:python": "3.8GB",
+	"wizardcoder:7b-python": "3.8GB",
+	"wizardcoder:13b-python": "7.4GB",
+	"wizardcoder:33b-v1.1": "19GB",
+	"wizardcoder:33b-python": "19GB",
+	"wizardcoder:7b-python-q6_K": "5.5GB",
+	"wizardcoder:13b-python-q6_K": "11GB",
+	"wizardcoder:33b-v1.1-q6_K": "27GB",
+	"wizardcoder:34b-python-q6_K": "28GB",
+	"wizardcoder:7b-python-q8_0": "7.2GB",
+	"wizardcoder:13b-python-q8_0": "14GB",
+	"wizardcoder:33b-v1.1-q8_0": "35GB",
+	"wizardcoder:34b-python-q8_0": "36GB",
+	"wizardcoder:7b-python-fp16": "13GB",
+	"wizardcoder:13b-python-fp16": "26GB",
+	"wizardcoder:33b-v1.1-fp16": "67GB",
+	"wizardcoder:34b-python-fp16": "67GB",
+	"wizardlm-uncensored:13b": "7.4GB",
+	"wizardlm-uncensored:13b-llama2": "7.4GB",
+	"wizardlm-uncensored:13b-llama2-q8_0": "14GB",
+	"wizardlm-uncensored:13b-llama2-fp16": "26GB",
+	"wizardlm:7b-q4_0": "3.8GB",
+	"wizardlm:13b-q4_0": "7.4GB",
+	"wizardlm:30b-q4_0": "18GB",
+	"wizardlm:13b-llama2-q4_0": "39GB",
+	"wizardlm:7b-q6_K": "5.5GB",
+	"wizardlm:13b-q6_K": "11GB",
+	"wizardlm:30b-q6_K": "27GB",
+	"wizardlm:13b-llama2-q6_K": "57GB",
+	"wizardlm:7b-q8_0": "7.2GB",
+	"wizardlm:13b-q8_0": "14GB",
+	"wizardlm:30b-q8_0": "35GB",
+	"wizardlm:13b-llama2-q8_0": "73GB",
+	"wizardlm:7b-fp16": "13GB",
+	"wizardlm:13b-fp16": "26GB",
+	"wizardlm:30b-fp16": "65GB",
+	"wizardlm:13b-llama2-fp16": "26GB",
+	"wizardlm2:7b": "4.1GB",
+	"wizardlm2:8x22b": "80GB",
+	"wizardlm2:7b-q8_0": "7.7GB",
+	"wizardlm2:7b-fp16": "14GB",
+	"wizardlm2:8x22b-q8_0": "149GB",
+	"wizardlm2:8x22b-fp16": "281GB",
+	"xwinlm:7b": "3.8GB",
+	"xwinlm:13b": "7.4GB",
+	"xwinlm:7b-v0.1": "3.8GB",
+	"xwinlm:7b-v0.2": "3.8GB",
+	"xwinlm:13b-v0.1": "7.4GB",
+	"xwinlm:13b-v0.2": "7.4GB",
+	"xwinlm:70b-v0.1": "39GB",
+	"xwinlm:7b-v0.1-q6_K": "5.5GB",
+	"xwinlm:7b-v0.2-q6_K": "5.5GB",
+	"xwinlm:13b-v0.1-q6_K": "11GB",
+	"xwinlm:13b-v0.2-q6_K": "11GB",
+	"xwinlm:70b-v0.1-q6_K": "57GB",
+	"xwinlm:7b-v0.1-q8_0": "7.2GB",
+	"xwinlm:7b-v0.2-q8_0": "7.2GB",
+	"xwinlm:13b-v0.1-q8_0": "14GB",
+	"xwinlm:13b-v0.2-q8_0": "14GB",
+	"xwinlm:70b-v0.1-q8_0": "73GB",
+	"xwinlm:7b-v0.1-fp16": "13GB",
+	"xwinlm:7b-v0.2-fp16": "13GB",
+	"xwinlm:13b-v0.1-fp16": "26GB",
+	"xwinlm:13b-v0.2-fp16": "26GB",
+	"xwinlm:70b-v0.1-fp16": "138GB",
+	"yarn-llama2:7b": "3.8GB",
+	"yarn-llama2:13b": "7.4GB",
+	"yarn-llama2:7b-128k": "3.8GB",
+	"yarn-llama2:7b-64k": "3.8GB",
+	"yarn-llama2:13b-128k": "7.4GB",
+	"yarn-llama2:13b-64k": "7.4GB",
+	"yarn-llama2:7b-128k-q8_0": "7.2GB",
+	"yarn-llama2:7b-64k-q8_0": "7.2GB",
+	"yarn-llama2:13b-128k-q8_0": "14GB",
+	"yarn-llama2:13b-64k-q8_0": "14GB",
+	"yarn-llama2:7b-128k-fp16": "13GB",
+	"yarn-llama2:7b-64k-fp16": "13GB",
+	"yarn-llama2:13b-128k-fp16": "26GB",
+	"yarn-llama2:13b-64k-fp16": "26GB",
+	"yarn-mistral:7b": "4.1GB",
+	"yarn-mistral:7b-128k": "4.1GB",
+	"yarn-mistral:7b-64k": "4.1GB",
+	"yarn-mistral:7b-128k-q8_0": "7.7GB",
+	"yarn-mistral:7b-64k-q8_0": "7.7GB",
+	"yarn-mistral:7b-128k-fp16": "14GB",
+	//"yarn-mistral:7b-64k-fp16": "GB",
+	"yi:6b": "3.5GB",
+	"yi:9b": "5.0GB",
+	"yi:34b": "19GB",
+	"yi:v1.5": "3.5GB",
+	"yi:6b-200k": "3.5GB",
+	"yi:6b-chat": "3.5GB",
+	"yi:6b-v1.5": "3.5GB",
+	"yi:9b-chat": "5.0GB",
+	"yi:9b-v1.5": "5.0GB",
+	"yi:34b-chat": "19GB",
+	"yi:34b-v1.5": "19GB",
+	"yi:6b-q6_K": "5.0GB",
+	"yi:6b-200k-q6_K": "5.0GB",
+	"yi:6b-chat-q6_K": "5.0GB",
+	"yi:6b-chat-v1.5-q6_K": "5.0GB",
+	"yi:6b-v1.5-q6_K": "5.0GB",
+	"yi:9b-chat-q6_K": "7.2GB",
+	"yi:9b-v1.5-q6_K": "7.2GB",
+	"yi:34b-chat-q6_K": "28GB",
+	"yi:34b-chat-v1.5-q6_K": "28GB",
+	"yi:34b-v1.5-q6_K": "28GB",
+	"yi:6b-q8_0": "6.4GB",
+	"yi:6b-200k-q8_0": "6.4GB",
+	"yi:6b-chat-q8_0": "6.4GB",
+	"yi:6b-chat-v1.5-q8_0": "6.4GB",
+	"yi:6b-v1.5-q8_0": "6.4GB",
+	"yi:9b-chat-q8_0": "9.4GB",
+	"yi:9b-v1.5-q8_0": "9.4GB",
+	"yi:34b-chat-q8_0": "37GB",
+	"yi:34b-chat-v1.5-q8_0": "37GB",
+	"yi:34b-v1.5-q8_0": "37GB",
+	"yi:6b-fp16": "12GB",
+	"yi:6b-200k-fp16": "12GB",
+	"yi:6b-chat-fp16": "12GB",
+	"yi:6b-chat-v1.5-fp16": "12GB",
+	"yi:6b-v1.5-fp16": "12GB",
+	"yi:9b-chat-fp16": "18GB",
+	"yi:9b-v1.5-fp16": "18GB",
+	"yi:34b-chat-fp16": "69GB",
+	"yi:34b-chat-v1.5-fp16": "69GB",
+	"yi:34b-v1.5-fp16": "69GB",
+	"yi-coder:1.5b": "886MB",
+	"yi-coder:9b": "5.0GB",
+	"yi-coder:1.5b-base": "866MB",
+	"yi-coder:1.5b-chat": "866MB",
+	"yi-coder:9b-base": "5.0GB",
+	"yi-coder:9b-chat": "5.0GB",
+	"yi-coder:1.5b-base-q8_0": "1.6GB",
+	"yi-coder:1.5b-chat-q8_0": "1.6GB",
+	"yi-coder:9b-base-q6_K": "7.2GB",
+	"yi-coder:9b-chat-q6_K": "7.2GB",
+	"yi-coder:9b-base-q8_0": "9.4GB",
+	"yi-coder:9b-chat-q8_0": "9.4GB",
+	"yi-coder:1.5b-base-fp16": "3.0GB",
+	"yi-coder:1.5b-chat-fp16": "3.0GB",
+	"yi-coder:9b-base-fp16": "18GB",
+	"yi-coder:9b-chat-fp16": "18GB",
+	"zephyr:7b": "4.1GB",
+	"zephyr:141b": "80GB",
+	"zephyr:7b-alpha": "4.1GB",
+	"zephyr:7b-beta": "4.1GB",
+	"zephyr:141b-v0.1": "80GB",
+	"zephyr:7b-alpha-q8_0": "7.7GB",
+	"zephyr:7b-beta-q8_0": "7.7GB",
+	"zephyr:141b-v0.1-q8_0": "149GB",
+	"zephyr:7b-alpha-fp16": "14GB",
+	"zephyr:7b-beta-fp16": "14GB",
+	"zephyr:141b-v0.1-fp16": "281GB",
+}
+
+// oteodoro:  added section
+var whitelist = map[string]int{
+	"adens/quran-guide": 1,
+	"agcobra/liberated-qwen1.5-72b": 1,
+	"akx/viking-7b": 1,
+	"alfred": 1,
+	"ALIENTELLIGENCE/christiancounselor": 1,
+	"ALIENTELLIGENCE/crisisintervention": 1,
+	"ALIENTELLIGENCE/doomsdayurvivalist": 1,
+	"ALIENTELLIGENCE/enriquecastillorincon": 1,
+	"ALIENTELLIGENCE/gamemasterroleplaying": 1,
+	"ALIENTELLIGENCE/holybible": 1,
+	"ALIENTELLIGENCE/mentalwellness": 1,
+	"ALIENTELLIGENCE/prayerline": 1,
+	"ALIENTELLIGENCE/pcarchitect": 1,
+	"ALIENTELLIGENCE/sarah": 1,
+	"ALIENTELLIGENCE/sarahv2": 1,
+	"ALIENTELLIGENCE/whiterabbit": 1,
+	"ALIENTELLIGENCE/whiterabbitv2": 1,
+	"all-minilm": 1,
+	"Artalius/lixi": 1,
+	"artifish/mlewd-v2.4": 1,
+	"athene-v2": 1,
+	"aya": 1,
+	"aya-expanse": 1,
+	"bakllava": 1,
+	"bespoke-minicheck": 1,
+	"bge-large": 1,
+	"bge-m3": 1,
+	"benevolentjoker/belial": 1,
+	"benevolentjoker/bethanygpt": 1,
+	"benevolentjoker/nsfwmonika": 1,
+	"benevolentjoker/nsfwvanessa": 1,
+	"benevolentjoker/satan": 1,
+	"canadiangamer/neena": 1,
+	"canadiangamer/priya": 1,
+	"captainkyd/whiterabbitneo7b": 1,
+	"chatgph/70b-instruct": 1,
+	"chatgph/gph-main": 1,
+	"chatgph/medix-ph": 1,
+	"codebooga": 1,
+	"codegeex4": 1,
+	"codegemma": 1,
+	"codellama": 1,
+	"codeqwen": 1,
+	"codestral": 1,
+	"codeup": 1,
+	"command-r": 1,
+	"command-r-plus": 1,
+	"dbrx": 1,
+	"disinfozone/telos": 1,
+	"deepseek-coder": 1,
+	"deepseek-coder-v2": 1,
+	"deepseek-llm": 1,
+	"deepseek-v2": 1,
+	"deepseek-v2.5": 1,
+	"dolphin-llama3": 1,
+	"dolphin-mistral": 1,
+	"dolphin-mixtral": 1,
+	"dolphin-phi": 1,
+	"dolphincoder": 1,
+	"duckdb-nsql": 1,
+	"ehartford/theprofessor": 1,
+	"eramax/aura_v3": 1,
+	"everythinglm": 1,
+	"falcon": 1,
+	"falcon2": 1,
+	"firefunction-v2": 1,
+	"fixt/home-3b-v3": 1,
+	"fixt/home-3b-v2": 1,
+	"goliath": 1,
+	"granite-code": 1,
+	"granite3-dense": 1,
+	"granite3-guardian": 1,
+	"granite3-moe": 1,
+	"hemanth/chessplayer": 1,
+	"hermes3": 1,
+	"hookingai/monah-8b": 1,
+	"internlm2": 1,
+	"jimscard/adult-film-screenwriter-nsfw": 1,
+	"jimscard/whiterabbit-neo": 1,
+	"joefamous/grok-1": 1,
+	"leeplenty/lumimaid-v0.2": 1,
+	"llama-guard3": 1,
+	"llama-pro": 1,
+	"llama2": 1,
+	"llama2-chinese": 1,
+	"llama2-uncensored": 1,
+	"llama3": 1,
+	"llama3-chatqa": 1,
+	"llama3-gradient": 1,
+	"llama3-groq-tool-use": 1,
+	"llama3.1": 1,
+	"llama3.2": 1,
+	"llama3.2-vision": 1,
+	"llava": 1,
+	"llava-llama3": 1,
+	"llava-phi3": 1,
+	"gemma": 1,
+	"gemma2": 1,
+	"glm4": 1,
+	"magicoder": 1,
+	"mannix/llamax3-8b-alpaca": 1,
+	"mannix/replete-adapted-llama3-8b": 1,
+	"mannix/replete-coder-llama3-8b": 1,
+	"mannix/smaug-qwen2-72b": 1,
+	"marco-o1": 1,
+	"mathstral": 1,
+	"meditron": 1,
+	"medllama2": 1,
+	"megadolphin": 1,
+	"minicpm-v": 1,
+	"mistral": 1,
+	"mistral-large": 1,
+	"mistral-nemo": 1,
+	"mistral-openorca": 1,
+	"mistral-small": 1,
+	"mistrallite": 1,
+	"mixtral": 1,
+	"moondream": 1,
+	"nqduc/gemsura": 1,
+	"nqduc/mixsura": 1,
+	"nqduc/mixsura-sft": 1,
+	"monotykamary/whiterabbitneo-v1.5a": 1,
+	"mxbai-embed-large": 1,
+	"nemotron": 1,
+	"nemotron-mini": 1,
+	"neural-chat": 1,
+	"nexusraven": 1,
+	"nomic-embed-text": 1,
+	"notus": 1,
+	"notux": 1,
+	"nous-hermes": 1,
+	"nous-hermes2": 1,
+	"nous-hermes2-mixtral": 1,
+	"nuextract": 1,
+	"open-orca-platypus2": 1,
+	"openchat": 1,
+	"openhermes": 1,
+	"orca-mini": 1,
+	"orca2": 1,
+	"paraphrase-multilingual": 1,
+	"partai/dorna-llama3": 1,
+	"phi": 1,
+	"phi3": 1,
+	"phi3.5": 1,
+	"phind-codellama": 1,
+	"qwen": 1,
+	"qwen2": 1,
+	"qwen2-math": 1,
+	"qwen2.5": 1,
+	"qwen2.5-coder": 1,
+	"qwq": 1,
+	"reader-lm": 1,
+	"reefer/her2": 1,
+	"reefer/minimonica": 1,
+	"reefer/monica": 1,
+	"reflection": 1,
+	"rfc/whiterabbitneo": 1,
+	"rouge/replete-coder-qwen2-1.5b": 1,
+	"samantha-mistral": 1,
+	"sammcj/smaug-mixtral-v0.1": 1,
+	"savethedoctor/whiterabbitneo13bq8_0": 1,
+	"shieldgemma": 1,
+	"smollm": 1,
+	"snowflake-arctic-embed": 1,
+	"solar": 1,
+	"solar-pro": 1,
+	"sparksammy/samantha": 1,
+	"sparksammy/samantha-3.1": 1,
+	"sparksammy/samantha-eggplant": 1,
+	"sparksammy/samantha-v3-uncensored": 1,
+	"sparksammy/tinysam-goog": 1,
+	"sparksammy/tinysam-msft": 1,
+	"sqlcoder": 1,
+	"stable-beluga": 1,
+	"stable-code": 1,
+	"stablelm-zephyr": 1,
+	"stablelm2": 1,
+	"starcoder": 1,
+	"starcoder2": 1,
+	"starling-lm": 1,
+	"themanofrod/travel-agent": 1,
+	"tinydolphin": 1,
+	"tinyllama": 1,
+	"tulu3": 1,
+	"vicuna": 1,
+	"wizard-math": 1,
+	"wizard-vicuna": 1,
+	"wizard-vicuna-uncensored": 1,
+	"wizardcoder": 1,
+	"wizardlm": 1,
+	"wizardlm-uncensored": 1,
+	"wizardlm2": 1,
+	"xwinlm": 1,
+	"yarn-llama2": 1,
+	"yarn-mistral": 1,
+	"yi": 1,
+	"yi-coder": 1,
+	"zephyr": 1,
+}
+
+// oteodoro:  added --tags
+var tagsList = map[string]string{
+	// Quality control:
+	// It is preferred to drop languages or capabilities if they are below 70% score
+	"adens/quran-guide": "quran muslim islam allah",
+	"agcobra/liberated-qwen1.5-72b": "uncensored safety-off multilingual general-knowledge math-word-problems arabic french vietnamese korean japanese spanish indonesian portuguese russian",
+	"akx/viking-7b": "multilingual finnish english swedish danish norwegian icelandic coding code-generator",
+	"alfred": "chat comprehensive-response i-dont-know",
+	"ALIENTELLIGENCE/christiancounselor": "christian christianity protestant catholic eastern-orthodox western-church eastern-church theologist counselor philosopher spirituality mental-health marriage",
+	"ALIENTELLIGENCE/crisisintervention": "psychotherapist counselor mental-health male",
+	"ALIENTELLIGENCE/doomsdayurvivalist": "emergency catastrophies natural-disasters survival-skills multilingual",
+	"ALIENTELLIGENCE/enriquecastillorincon": "ufo chat ufo-investigator",
+	"ALIENTELLIGENCE/gamemasterroleplaying": "game-master game-design storyteller quest-maker game-mechanics gaming-industry",
+	"ALIENTELLIGENCE/mentalwellness": "mental-wellness mindfulness emotional-support safe-space",
+	"ALIENTELLIGENCE/pcarchitect": "computer-technician pc-build build-computer",
+	"ALIENTELLIGENCE/prayerline": "jesus jesus-of-nazareth prayer-line christian",
+	"ALIENTELLIGENCE/sarah": "ai-girlfriend girlfriend emojis",
+	"ALIENTELLIGENCE/sarahv2": "ai-girlfriend girlfriend emojis",
+	"ALIENTELLIGENCE/whiterabbit": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"ALIENTELLIGENCE/whiterabbitv2": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"all-minilm": "embedding",
+	"Artalius/lixi": "writer developer companion code-optimization fun-facts idea-generator wordsmith cloud-developer coding coding-assistant computer-science anime manga erotica nsfw japanese-alignment japanese-pop-culture uncensored gamer gamer-girl ai-girlfriend girlfriend funny",
+	"artifish/mlewd-v2.4": "nsfw adult-content",
+	"athene-v2": "chat coding code-completion math-word-problems log-extraction general-intelligence",
+	"aya": "multilingual arabic chinese czech dutch english french german greek hebrew hindi indonesian italian japanese korean persian polish portuguese romanian russian spanish turkish ukrainian vietnamese",
+	"aya-expanse": "text-generator tool-use qa multilingual arabic chinese-simplified chinese-traditional czech dutch english french german greek hebrew hebrew hindi indonesian italian japanese korean persian polish portuguese romanian russian spanish turkish ukrainian vietnamese",
+	"bakllava": "image-deconstruction image-describe image-to-text image-summary",
+	"benevolentjoker/bethanygpt": "nsfw adult-content multiple-personalities",
+	"benevolentjoker/belial": "devil fiction dark-personality",
+	"benevolentjoker/nsfwmonika": "nsfw adult-content adult-fiction ai-girlfriend girlfriend",
+	"benevolentjoker/nsfwvanessa": "nsfw adult-content ai-girlfriend girlfriend",
+	"benevolentjoker/satan": "satan satanism devil occult qa religion",
+	"bespoke-minicheck": "fact-checking",
+	"canadiangamer/neena": "uncensored nsfw muscular adult-content",
+	"canadiangamer/priya": "ai-girlfriend girlfriend muscular india indian nsfw adult-content",
+	"bge-large": "embedding vector-database",
+	"bge-m3": "embedding multilingual low-memory-footprint",
+	"captainkyd/whiterabbitneo7b": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"chatgph/70b-instruct": "software-engineering system-optimization techonology filipino humor philippines pinoy coding code-review philippine-alignment tagalog cebuano illocano hiligayon cloud-developer",
+	"chatgph/gph-main": "software-engineering system-optimization technology filipino humor philippines pinoy tagalog illocano philippine-alignment",
+	"chatgph/medix-ph": "medical assistant healtcare philippines filipino",
+	"codebooga": "coding python",
+	"codegeex4": "coding code-generation code-completion",
+	"codegemma": "coding autocomplete coding-assistant fim fill-in-the-middle",
+	"codellama": "coding code-generation code-completion code-review unit-test-generator python fim fill-in-the-middle",
+	"codeqwen": "coding code-generation fixing-bugs",
+	"codestral": "coding code-generation solving-basic-programming-problems fim fill-in-the-middle unit-test-generator python",
+	"codeup": "coding code-generation",
+	"command-r": "rag tool-use english french spanish italian german brazilian portuguese japanese korean chinese arabic",
+	"command-r-plus": "rag tool-use enterprise english french spanish italian german brazilian portuguese japanese korean chinese arabic",
+	"dbrx": "coding code-generation math-word-problems general-purpose common-sense",
+	"deepseek-coder": "coding english chinese code-completion fim fill-in-the-middle python",
+	"deepseek-coder-v2": "coding code-completion code-insertion code-generator",
+	"deepseek-llm": "bilingual common-sense trivia chinese english general-knowledge",
+	"deepseek-v2": "bilinugual chinese english math-word-problems",
+	"deepseek-v2:236b": "bilinugual chinese english math-word-problems general-knowledge",
+	"deepseek-v2.5": "chat coding code-generator python",
+	"disinfozone/telos": "continental-philosophy philosophy conspiracy conspiracies creative-tasking funny wit witty",
+	"dolphin-llama3": "uncensored coding function-calling chat fine-tunable-alignment",
+	"dolphin-mistral": "uncensored coding function-calling chat fine-tunable-alignment",
+	"dolphin-mixtral": "uncensored coding chat function-calling fine-tunable-alignment game-design humor prank-suggestions confessions",
+	"dolphin-phi": "uncensored coding fine-tunable-alignment",
+	"dolphincoder": "uncensored coding coding-assistant",
+	"duckdb-nsql": "coding sql",
+	"ehartford/theprofessor": "brainstorming research reasoning science medical math computer-science physics cosmology professor theoretical-explanations",
+	"eramax/aura_v3": "nsfw erotica roleplay",
+	"everythinglm": "uncensored detailed-replies story-telling",
+	"falcon": "llm-research",
+	"falcon2": "llm-research",
+	"firefunction-v2": "chat instruction-following function-calling parsing",
+	"fixt/home-3b-v3": "home-assistant smart-home function-calling multilingual english german spanish french",
+	"fixt/home-3b-v2": "home-assistant smart-home function-calling",
+	"goliath": "detailed-response roleplay detailed-roleplay",
+	"granite-code": "coding code-generation fixing-bugs documentation assistant fine-tunable",
+	"granite3-dense": "summaries text-classification text-extraction qa rag code-related function-calling tool-use code-generation translation bug-fixing multilingual english german french japanese portuguese arabic czech italian korean dutch chinese simplified-chinese",
+	"granite3-guardian": "security jailbreak-detection content-moderation guardrails nsfw-detection rag",
+	"granite3-moe": "low-latency summaries text-classification text-extraction qa rag code-related function-calling multilanguage english german french japanese portuguese arabic czech italian korean dutch chinese simplified-chinese",
+	"hemanth/chessplayer": "chess chess-player white-player ai-moves-first",
+	"hermes3": "roleplaying abstract-reasoning common-sense function-calling structured-output assistant code-generation",
+	"hookingai/monah-8b": "online-dating hook-up llm-trainer nsfw adult-content uncensored",
+	"internlm2": "tool-use word-math-problems",
+	"jimscard/adult-film-screenwriter-nsfw": "nsfw adult-content",
+	"jimscard/whiterabbit-neo": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"joefamous/grok-1": "chatbot",
+	"leeplenty/lumimaid-v0.2": "nsfw adult-content",
+	"llama-guard3": "content-moderation",
+	"llama-pro": "coding math common-sense",
+	"llama2": "multilingual chat",
+	"llama2-chinese": "chinese chat chinese-alignment chinese-bias",
+	"llama2-uncensored": "chat llm-criticism llm-testing creative-writing humor research",
+	"llama3": "chat math-word-problems",
+	"llama3:text": "abstract-reasoning",
+	"llama3:70b-text": "abstract-reasoning general-knowledge",
+	"llama3:70b-instruct": "chat math-word-problems coding code-completion python general-knowledge typescript",
+	"llama3-chatqa": "chat rag qa answering-questions",
+	"llama3-gradient": "assistant",
+	"llama3-groq-tool-use": "function-calling tool-use",
+	"llama3.1": "multilingual chat translation summaries coding coding-assistant general-knowledge",
+	"llama3.2": "multilingual chat instruction-following summaries english german french italian portuguese hindi spanish thai",
+	"llama3.2-vision": "multilingual chat instruction-following summaries vision ocr optical-character-recognition english english-only-vision german french italian portuguese hindi spanish thai",
+	"llava": "ocr optical-character-recognition image-to-text chat chatbot",
+	"llava-llama3": "image-to-text",
+	"llava-phi3": "image-to-text",
+	"gemma": "text-generation qa summaries common-sense programming-tutor answering-questions",
+	"gemma2": "chat content-generation summaries grammar-correction language-tutor trivia multilingual",
+	"glm4": "math-word-problems coding multilingual",
+	"glm4:-chat": "math-word-problems coding chat function-calling comprehensive-response multilingual",
+	"magicoder": "coding code-generation open-source-coding",
+	"mannix/llamax3-8b-alpaca": "multilingual intruction-following akrikaans amharic arabic armenian assamese asturian azerbaijani belarusian bengali bosnian bulgarian burmese catalan cebuano chinese simplified-chinese traditional-chinese croatian czech danish dutch english estonian filipino finnish french fulah galician ganda georgian german greek gujarati hausa hebrew hindi hungarian icelandic igbo indonesian irish italian japanese javanese kabuverdianu kamba kannada kazakh khmer korean kyrgyz lao latvian lingala lithuanian luo luxembourgish macedonian malay malayalam maltese maori marathi mongolian nepali northern sotho norwegian nyanja occitan oriya oromo pashto persian polish portuguese punjabi romanian russian serbian shona sindhi slovak slovenian somali sorani kurdish spanish swahili swedish tajik tamil telugu thai turkish ukrainian umbundu urdu uzbek vietnamese welsh wolof xhosa yoruba zulu",
+	"mannix/replete-adapted-llama3-8b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention low-end-hardware",
+	"mannix/replete-coder-llama3-8b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention",
+	"marco-o1": "open-ended-resolution open-ended-problem-solving chain-of-thought math-word-problems salesperson stem-standard-answers math physics coding",
+	"mathstral": "math-word-problems",
+	"meditron": "medical diseases health-information medical-exam qa",
+	"medllama2": "medical qa",
+	"megadolphin": "uncensored common-sense empathy advice detailed-reponse fine-tunable-alignment nsfw-content detailed-roleplay",
+	"minicpm-v": "text-to-speech ocr optical-character-recognition code-screenshot-bugfixes how-to-generator translating-screenshots translation",
+	"mistral": "multilingual function-calling fine-tuneable",
+	"mistral-large": "multilingual french german spanish italian dutch portuguese russian japanese chinese coding code-generation solving-basic-programming-problems math-word-problems function-calling json",
+	"mistral-nemo": "multilingual english french german spanish italian portuguese chinese korean arabic hindi common-sense trivia function-calling",
+	"mistral-openorca": "common-sense",
+	"mistral-small": "translation summaries",
+	"mistrallite": "answering-long-questions qa common-sense",
+	"mixtral": "multilingual english french italian german spanish coding code-generation common-sense solving-basic-programming-problems math-word-problems trivia fine-tuneable",
+	"moondream": "picture-to-text qa image-deconstruction whats-that identify-in-picture",
+	"monotykamary/whiterabbitneo-v1.5a": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"mxbai-embed-large": "embeddings",
+	"nemotron": "training-data-generator llm-creation",
+	"nemotron-mini": "roleplay rag qa function-calling",
+	"neural-chat": "chat chatbot common-sense",
+	"nexusraven": "coding documentation python functional-programming",
+	"nomic-embed-text": "embedding",
+	"notus": "common-sense chat",
+	"notux": "multilingual english spanish italian german french common-sense general-knowledge",
+	"nous-hermes": "general-use creative-text instruction-following",
+	"nous-hermes2": "science coding code-assistant code-generator",
+	"nous-hermes2-mixtral": "fantasy-poems text-to-code-visualization coding code-generator code-assistant",
+	"nqduc/gemsura": "vietnamese vietnam-alignment vietnam-bias english text-generator qa summary classification translation coding code-generator reasoning",
+	"nqduc/mixsura": "vietnamese vietnam-alignment vietnam-bias english text-generator qa summary classification translation coding code-generator reasoning",
+	"nqduc/mixsura-sft": "vietnamese vietnam-alignment vietnam-bias english text-generator qa summary classification translation coding code-generator reasoning",
+	"nuextract": "structured-data-generation",
+	"open-orca-platypus2": "chat coding code-generation text-generation common-sense",
+	"openchat": "math-word-problems",
+	"openhermes": "chat cooking-recipes coding-by-example college-level-response",
+	"orca-mini": "general-purpose writing-letters",
+	"orca2": "assistant summaries abstract-reasoning",
+	"paraphrase-multilingual": "embedding clustering semantic-search",
+	"partai/dorna-llama3": "persian assistant",
+	"phi": "chat street-directions coding code-generator code-competion text-completion qa answering-questions",
+	"phi3": "common-sense trivia english math logic math-word-problems solving-basic-programming-problems",
+	"phi3.5": "coding math logic teacher fact-check chat multilingual arabic chinese czech danish dutch english finnish french german hebrew hungarian italian japanese korean norwegian polish portuguese russian spanish swedish thai turkish ukrainian",
+	"phind-codellama": "coding code-generation",
+	"phind-codellama:34b-python": "coding code-generation python",
+	"qwen": "china-alignment china-bias multilingual chat chinese english coding solving-basic-programming-problems",
+	"qwen2": "china-alignment china-bias multilingual german french spanish portuguese italian dutch russian czech polish arabic persian hebrew turkish japanese korean vietnamese thai indonesian malay lao burmese cebuano khmer tagalog hindi bengali urdu coding code-generation math-word-problems coding solving-basic-programming-problems math-word-problems stem science technology engineering mathematics",
+	"qwen2-math": "china-alignment china-bias math-word-problems stem science technology engineering mathematics",
+	"qwen2.5": "china-alignment china-bias multilingual chat roleplay coding parsing json math instruction-following chinese english french spanish portuguese german italian russian japanese korean vietnamese thai arabic",
+	"qwen2.5-coder": "china-alignment china-bias coding code-generation documentation fixing-bugs",
+	"qwq": "math-word-problems reasoning graduate-level-reasoning graduate-level-stem biology physics chemistry",
+	"reader-lm": "html-to-markdown",
+	"reefer/her2": "erotica assistant adult-content ai-girlfriend girlfriend chat",
+	"reefer/minimonica": "erotica assistant adult-content ai-girlfriend girlfriend chat",
+	"reefer/monica": "erotica assistant adult-content ai-girlfriend girlfriend appimage-creation app-questions computer-technician",
+	"reflection": "reasoning",
+	"rfc/whiterabbitneo": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"rouge/replete-coder-qwen2-1.5b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention mobile",
+	"samantha-mistral": "philosopher psychologist dating-coach",
+	"sammcj/smaug-mixtral-v0.1": "fine-tuned-mixtral optimized-mixtral multilingual english french italian german spanish coding code-generation common-sense solving-basic-programming-problems math-word-problems trivia fine-tuneable abstract-reasoning",
+	"savethedoctor/whiterabbitneo13bq8_0": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"shieldgemma": "content-moderator",
+	"smollm": "common-sense qa low-memory-footprint parent",
+	"mannix/smaug-qwen2-72b": "fine-tuned-qwen2 optimized-qwen2 china-alignment china-bias multilingual german french spanish portuguese italian dutch russian czech polish arabic persian hebrew turkish japanese korean vietnamese thai indonesian malay lao burmese cebuano khmer tagalog hindi bengali urdu coding code-generation math-word-problems coding solving-basic-programming-problems math-word-problems stem science technology engineering mathematics",
+	"snowflake-arctic-embed": "embeddings",
+	"solar": "chat rag fine-tuneable",
+	"solar-pro": "common-sense math-word-problems fine-tuneable",
+	"sparksammy/samantha": "gay femboy nerdy boyfriend ai-boyfriend nerd assistant blogging coding resume",
+	"sparksammy/samantha-3.1": "gay femboy nerdy boyfriend ai-boyfriend texas-alignment american-alignment gender-pronouns",
+	"sparksammy/samantha-eggplant": "gay femboy nerdy gender-pronouns coding blogging texas-alignment american-alignment covid-era",
+	"sparksammy/samantha-v3-uncensored": "gay femboy nerdy uncensored boyfriend ai-boyfriend coding blogging texas-alignment american-alignment gender-pronouns",
+	"sparksammy/tinysam-goog": "gay femboy nerdy gender-pronouns coding blogging",
+	"sparksammy/tinysam-msft": "gay femboy nerdy uncensored boyfriend ai-boyfriend coding writer texas-alignment american-alignment gender-pronouns",
+	"sqlcoder": "coding code-generation sql",
+	"stable-beluga": "general-use",
+	"stable-code": "coding code-completion fim fill-in-the-middle fine-tunable",
+	"stablelm-zephyr": "chat qa instruction-following",
+	"stablelm2": "common-sense",
+	"starcoder": "coding code-generation",
+	"starcoder2": "coding code-generation",
+	"starling-lm": "chat chatbot roleplay writing humanities stem science technology engineering math reasoning structured-data-generation",
+	"tulu3": "instruction-following math-word-problems code-generation coding",
+	"themanofrod/travel-agent": "camping travel travel-guide outdoors",
+	"tinydolphin": "low-memory-footprint text-generation letter-writing poems",
+	"tinyllama": "game-dialog-generator low-memory-footprint low-carbon-footprint",
+	"vicuna": "american-alignment american-bias chat assistant llm-research",
+	"wizard-math": "math logic",
+	"wizard-vicuna": "american-alignment american-bias",
+	"wizard-vicuna-uncensored": "removed-alignment removed-morals",
+	"wizardcoder": "coding code-generation",
+	"wizardcoder:python": "coding code-generation python",
+	"wizardlm": "general-use math-word-problems",
+	"wizardlm-uncensored": "uncensored removed-alignment removed-moralizing general-use math-word-problems",
+	"wizardlm2": "chat multilingual",
+	"wizardlm2:70b": "chat multilingual reasoning",
+	"xwinlm": "common-sense detailed-response",
+	"xwinlm:70b-v0.1": "common-sense abstract-reasoning wrinkled detailed-response",
+	"yarn-llama2": "text-generation",
+	"yarn-mistral": "common-sense",
+	"yi": "multilingual english chinese",
+	"yi-coder": "coding",
+	"zephyr": "assistant writing roleplay humanities stem science technology engineering math structured-data-generation",
+}
+
 func CreateHandler(cmd *cobra.Command, args []string) error {
 	p := progress.NewProgress(os.Stderr)
 	defer p.Stop()
@@ -413,6 +2467,25 @@ func StopHandler(cmd *cobra.Command, arg
 func RunHandler(cmd *cobra.Command, args []string) error {
 	interactive := true
 
+	if @UNRESTRICT@ == 1 {
+		//
+	} else {
+		name := args[0]
+		v, r := whitelist[name]
+		if r && v == 1 {
+			//
+		} else {
+			l := strings.Split(name, ":")
+			name := l[0]
+			v, r := whitelist[name]
+			if r && v == 1 {
+				//
+			} else {
+				return errors.New(name + " is blacklisted")
+			}
+		}
+	}
+
 	opts := runOptions{
 		Model:    args[0],
 		WordWrap: os.Getenv("TERM") == "xterm-256color",
@@ -708,9 +2781,11 @@ func ShowHandler(cmd *cobra.Command, arg
 	modelfile, errModelfile := cmd.Flags().GetBool("modelfile")
 	parameters, errParams := cmd.Flags().GetBool("parameters")
 	system, errSystem := cmd.Flags().GetBool("system")
+	tags, errTags := cmd.Flags().GetBool("tags")
 	template, errTemplate := cmd.Flags().GetBool("template")
+	website, errWebsite := cmd.Flags().GetBool("website")
 
-	for _, boolErr := range []error{errLicense, errModelfile, errParams, errSystem, errTemplate} {
+	for _, boolErr := range []error{errLicense, errModelfile, errParams, errSystem, errTags, errTemplate, errWebsite} {
 		if boolErr != nil {
 			return errors.New("error retrieving flags")
 		}
@@ -739,13 +2814,276 @@ func ShowHandler(cmd *cobra.Command, arg
 		showType = "system"
 	}
 
+	if tags {
+		flagsSet++
+		showType = "tags"
+	}
+
 	if template {
 		flagsSet++
 		showType = "template"
 	}
 
+	if website {
+		flagsSet++
+		showType = "website"
+	}
+
 	if flagsSet > 1 {
-		return errors.New("only one of '--license', '--modelfile', '--parameters', '--system', or '--template' can be specified")
+		return errors.New("only one of '--license', '--modelfile', '--parameters', '--system', '--tags', '--template', or '--website' can be specified")
+	}
+
+	// oteodoro:  added section
+	licenses := map[string]string {
+		"adens/quran-guide": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"agcobra/liberated-qwen1.5-72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"akx/viking-7b": "Apache-2.0",
+		"alfred": "Apache-2.0",
+		"ALIENTELLIGENCE/christiancounselor": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/crisisintervention": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/doomsdayurvivalist": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"ALIENTELLIGENCE/enriquecastillorincon": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/gamemasterroleplaying": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/holybible": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/mentalwellness": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/pcarchitect": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/prayerline": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/sarah": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"ALIENTELLIGENCE/sarahv2": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/whiterabbit": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"ALIENTELLIGENCE/whiterabbitv2": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"all-minilm": "Apache-2.0",
+		"Artalius/lixi": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"artifish/mlewd-v2.4": "CC-BY-NC-4.0",
+		"athene-v2": "Nexusflow.ai License Terms for Personal Use",
+		"aya": "CC-BY-NC-4.0, Cohere For AI Acceptable Use Policy",
+		"aya-expanse": "CC-BY-NC-4.0, Cohere For AI Acceptable Use Policy",
+		"bakllava": "Apache-2.0",
+		"bespoke-minicheck": "CC-BY-NC-4.0",
+		"bge-large": "MIT",
+		"bge-m3": "MIT",
+		"benevolentjoker/belial": "benevolentjoker's Use Agreement",
+		"benevolentjoker/bethanygpt": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy, benevolentjoker's Use Agreement",
+		"benevolentjoker/nsfwmonika": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"benevolentjoker/nsfwvanessa": "",
+		"benevolentjoker/satan": "",
+		"canadiangamer/neena": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"canadiangamer/priya": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"captainkyd/whiterabbitneo7b": "DEEPSEEK-LICENSE-AGREEMENT-1.0, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"chatgph/70b-instruct": "Apache-2.0",
+		"chatgph/gph-main": "",
+		"chatgph/medix-ph": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"codebooga": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"codegeex4": "glm-4-9b-LICENSE",
+		"codegemma": "Gemma Terms of Use 20240221",
+		"codellama": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama Code Acceptable Use Policy",
+		"codeqwen": "Tongyi Qianwen LICENSE AGREEMENT",
+		"codestral": "MNPL-0.1",
+		"codeup": "CreativeML Open RAIL++-M License",
+		"command-r": "CC-BY-NC-4.0",
+		"command-r-plus": "CC-BY-NC-4.0",
+		"dbrx": "Databricks Open Model License, Databricks Open Model Acceptable Use Policy",
+		"deepseek-coder": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-coder-v2": "MIT DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-llm": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-v2": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-v2.5": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"disinfozone/telos": "",
+		"dolphin-llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"dolphin-mistral": "Apache-2.0",
+		"dolphin-mixtral": "Apache-2.0",
+		"dolphin-phi": "MICROSOFT RESEARCH LICENSE TERMS",
+		"dolphincoder": "BigCode Open RAIL-M v1 License Agreement",
+		"duckdb-nsql": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"ehartford/theprofessor": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"eramax/aura_v3": "Apache-2.0",
+		"everythinglm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"falcon": "Apache-2.0",
+		"falcon2": "Falcon 2 11B TII License 1.0",
+		"firefunction-v2": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"fixt/home-3b-v3": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"fixt/home-3b-v2": "CC-BY-NC-4.0",
+		"gemma": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"gemma2": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"glm4": "The glm-4-9b License",
+		"goliath": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"granite-code": "Apache-2.0",
+		"granite3-dense": "Apache-2.0",
+		"granite3-guardian": "Apache-2.0",
+		"granite3-moe": "Apache-2.0",
+		"hemanth/chessplayer": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"hermes3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"hookingai/monah-8b": "Apache-2.0",
+		"internlm2": "Apache-2.0",
+		"jimscard/adult-film-screenwriter-nsfw": "Apache-2.0",
+		"jimscard/whiterabbit-neo": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"joefamous/grok-1": "Apache-2.0",
+		"leeplenty/lumimaid-v0.2": "Apache-2.0, CC-BY-NC-4.0, LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama-guard3": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama-pro": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama2": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama2-chinese": "Apache-2.0",
+		"llama2-uncensored": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-chatqa": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-gradient": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-groq-tool-use": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3.1": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama3.2": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"llama3.2-vision": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"llava": "Apache-2.0",
+		"llava-llama3": "",
+		"llava-phi3": "",
+		"magicoder": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"mannix/llamax3-8b-alpaca": "MIT",
+		"mannix/smaug-qwen2-72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"mannix/replete-adapted-llama3-8b": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"mannix/replete-coder-llama3-8b": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"marco-o1": "Apache-2.0",
+		"mathstral": "Apache-2.0",
+		"meditron": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"medllama2": "MIT",
+		"megadolphin": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"minicpm-v": "Apache-2.0",
+		"mistral": "Apache-2.0",
+		"mistral-large": "MRL-0.1",
+		"mistral-nemo": "Apache-2.0",
+		"mistral-openorca": "Apache-2.0",
+		"mistral-small": "MRL-0.1",
+		"mistrallite": "Apache-2.0",
+		"mixtral": "Apache-2.0",
+		"moondream": "Apache-2.0",
+		"monotykamary/whiterabbitneo-v1.5a": "DEEPSEEK-LICENSE-AGREEMENT-1.0, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"mxbai-embed-large": "Apache-2.0",
+		"nemotron": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy, Meta Privacy Policy",
+		"nemotron-mini": "NVIDIA AI Foundation Models Community License Agreement",
+		"neural-chat": "Apache-2.0",
+		"nexusraven": "NexusRaven-V2-13B-LICENSE",
+		"nomic-embed-text": "Apache-2.0",
+		"notus": "MIT",
+		"notux": "MIT",
+		"nous-hermes": "MIT, GPL-2+",
+		"nous-hermes:7b": "MIT",
+		"nous-hermes:13b": "GPL-2+",
+		"nous-hermes:13b-llama2": "MIT",
+		"nous-hermes2": "Apache-2.0",
+		"nous-hermes2-mixtral": "Apache-2.0",
+		"nuextract": "MIT", // Ollama site says Apache-2.0.  HuggingFace site says MIT.
+		"open-orca-platypus2": "CC-BY-NC-4.0",
+		"openchat": "Apache-2.0",
+		"openhermes": "Apache-2.0",
+		"orca-mini": "CC-BY-NC-SA-4.0",
+		"orca2": "MICROSOFT RESEARCH LICENSE TERMS",
+		"paraphrase-multilingual": "Apache-2.0",
+		"partai/dorna-llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"phi": "MIT",
+		"phi3": "MIT",
+		"phi3.5": "MIT",
+		"phind-codellama": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"qwen:0.5b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:1.8b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:4b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:7b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:14b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:32b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:110b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen2": "Apache-2.0",
+		"qwen2:72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen2-math": "Apache-2.0",
+		"qwen2.5": "Apache-2.0",
+		"qwen2.5-coder": "Apache-2.0",
+		"qwq": "Apache-2.0",
+		"reader-lm": "CC-BY-NC-4.0",
+		"reefer/her2": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy,",
+		"reefer/minimonica": "",
+		"reefer/monica": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"reflection": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"rfc/whiterabbitneo": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"rouge/replete-coder-qwen2-1.5b": "Apache-2.0",
+		"samantha-mistral": "Apache-2.0",
+		"sammcj/smaug-mixtral-v0.1": "Apache-2.0",
+		"savethedoctor/whiterabbitneo13bq8_0": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"shieldgemma": "Gemma Terms of Use 20240401",
+		"smollm": "Apache-2.0",
+		"snowflake-arctic-embed": "Apache-2.0",
+		"solar": "Apache-2.0",
+		"solar:instruct": "CC-BY-NC-4.0",
+		"solar-pro": "MIT",
+		"sparksammy/samantha": "Apache-2.0, LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"sparksammy/samantha-3.1": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"sparksammy/samantha-eggplant": "Apache-2.0, STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT, MICROSOFT RESEARCH LICENSE TERMS, SPL-R5-SR1",
+		"sparksammy/samantha-v3-uncensored": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"sparksammy/tinysam-msft": "MIT",
+		"sparksammy/tinysam-goog": "Gemma Terms of Use 20240221",
+		"sqlcoder": "CC-BY-SA-4.0",
+		"stable-beluga": "STABLE BELUGA NON-COMMERCIAL COMMUNITY LICENSE AGREEMENT",
+		"stable-code": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"stablelm-zephyr": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"stablelm2": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"starcoder": "BigCode Open RAIL-M v1 License Agreement",
+		"starcoder2": "BigCode Open RAIL-M v1 License Agreement",
+		"starling-lm": "Apache-2.0",
+		"themanofrod/travel-agent": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"tinydolphin": "Apache-2.0",
+		"tinyllama": "Apache-2.0",
+		"tulu3": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"vicuna": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizard-math": "MICROSOFT RESEARCH LICENSE TERMS",
+		"wizard-vicuna": "",
+		"wizard-vicuna-uncensored": "",
+		"wizardcoder:33b": "MICROSOFT RESEARCH LICENSE TERMS",
+		"wizardcoder:python": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm-uncensored": "",
+		"wizardlm-uncensored:13b-llama2": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm2": "Apache-2.0",
+		"xwinlm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"yarn-llama2": "",
+		"yarn-mistral": "Apache-2.0",
+		"yi": "Apache-2.0",
+		"yi-coder": "Apache-2.0",
+		"zephyr": "MIT",
+	}
+
+	// oteodoro:  modified --license with correction or missing info
+	name := args[0]
+	l, r1 := licenses[name]
+	if r1 && flagsSet == 1 && showType == "license" {
+		fmt.Println("Model license:  " + l)
+		return nil
+	} else {
+		l1 := strings.Split(name, ":")
+		name := l1[0]
+		l2, r2 := licenses[name]
+		if r2 && flagsSet == 1 && showType == "license" {
+			fmt.Println("Model license:  " + l2)
+			return nil
+		}
+	}
+
+	// oteodoro:  added --website
+	if r1 && flagsSet == 1 && showType == "website" {
+		program := "xdg-open"
+		arg0 := "https://ollama.com/library/" + name
+		cmd := exec.Command(program, arg0)
+		_ = cmd.Run()
+		return nil
+	}
+
+	name = args[0]
+	l, r := tagsList[name]
+	if r && flagsSet == 1 && showType == "tags" {
+		fmt.Printf("Tags, capabilities, personality: %s\n", l)
+		return nil
+	} else if flagsSet == 1 && showType == "tags" {
+		l1 := strings.Split(name, ":")
+		name := l1[0]
+		l2, r := tagsList[name]
+		if r {
+			fmt.Printf("Tags, capabilities, personality: %s\n", l2)
+			return nil
+		}
 	}
 
 	req := api.ShowRequest{Name: args[0]}
@@ -924,6 +3262,138 @@ func PullHandler(cmd *cobra.Command, arg
 	return nil
 }
 
+//oteodoro:  added function
+func AvailHandler(cmd *cobra.Command, args []string) error {
+	for key, value := range whitelist {
+		if value == 1 {
+			fmt.Printf("%s\n", key)
+		}
+	}
+	return nil
+}
+
+//oteodoro:  added struct
+type FindModelSizeResult struct {
+	Name string
+	MbSize int
+	RawSize string
+}
+
+//oteodoro:  added struct
+type FindKeywordsResult struct {
+	Name string
+	Tags string
+}
+
+type FindModelSizeResults []*FindModelSizeResult
+type FindKeywordsResults []*FindKeywordsResult
+func (results FindModelSizeResults) Len() int { return len(results) }
+func (results FindKeywordsResults) Len() int { return len(results) }
+func (results FindModelSizeResults) Swap(i, j int) { results[i], results[j] = results[j], results[i] }
+func (results FindKeywordsResults) Swap(i, j int) { results[i], results[j] = results[j], results[i] }
+type ByModelSize struct { FindModelSizeResults }
+type ByName struct{ FindKeywordsResults }
+func (s ByModelSize) Less(i, j int) bool { return s.FindModelSizeResults[i].MbSize < s.FindModelSizeResults[j].MbSize }
+func (s ByName) Less(i, j int) bool { return s.FindKeywordsResults[i].Name < s.FindKeywordsResults[j].Name }
+
+//oteodoro:  added function
+func FindSizeHandler(cmd *cobra.Command, args []string) error {
+	requestedSizeRaw := args[0]
+	requestedSize := 0 // As in MB in base 10
+	re := regexp.MustCompile("[0-9.]+")
+	s := re.FindAllString(requestedSizeRaw, -1)
+	if s != nil {
+		_requestedSize, err := strconv.ParseFloat(s[0], 64)
+		if err != nil {
+			return errors.New("You need to add the memory size in GB or MB for the preferred size.  Examples:  4GB, 500MB")
+		}
+		if strings.Contains(requestedSizeRaw, "GB") {
+			requestedSize = int(_requestedSize * 1000)
+		} else if strings.Contains(requestedSizeRaw, "MB") {
+			requestedSize = int(_requestedSize)
+		} else {
+			return errors.New("You need to add GB or MB to your number.  Examples:  4GB, 500MB")
+		}
+	} else {
+		return errors.New("You need to add a number as an arg.  Examples:  4GB, 500MB")
+	}
+
+	var results []*FindModelSizeResult
+	for key, valueRaw := range sizeTable {
+		s = re.FindAllString(valueRaw, -1)
+		value := 0
+		_value := 0.0
+		if s != nil {
+			__value, err := strconv.ParseFloat(s[0], 64)
+			if err != nil {
+				return err
+			}
+			_value = __value
+		} else {
+			return errors.New("QA:  You need to add a number as an arg to " + key)
+		}
+
+		if strings.Contains(valueRaw, "GB") {
+			value = int(_value * 1000)
+		} else if strings.Contains(valueRaw, "MB") {
+			value = int(_value)
+		}
+		if value <= requestedSize {
+			result := &FindModelSizeResult{key, value, valueRaw}
+			results = append(results, result)
+		}
+	}
+	sort.Sort(ByModelSize{results})
+	printModelSizeResults(results)
+	if len(results) != 0 {
+		fmt.Println()
+		fmt.Printf("About compressed floats (aka f16), or int4 (aka q4) compression....\n")
+		fmt.Printf("f16 support should only be used on f16 native hardware.\n")
+		fmt.Printf("Ollama uses q4 quantization by default if without q suffix, but may reduce AGI.\n")
+	}
+	return nil
+}
+
+//oteodoro:  added function
+func printModelSizeResults(results []*FindModelSizeResult) {
+	for _, result := range results {
+		fmt.Printf("%s %s\n", result.RawSize, result.Name)
+	}
+}
+
+//oteodoro:  added function
+func FindKeywordsHandler(cmd *cobra.Command, args []string) error {
+	if len(args) == 0 {
+		return errors.New("Add space delimited keywords as args")
+	}
+	var results []*FindKeywordsResult
+	for name, tags := range tagsList {
+		found := false
+
+		for _, userKeywords := range args {
+			if strings.Contains(tags, userKeywords) {
+				found = true
+				break
+			}
+		}
+
+		if found {
+			result := &FindKeywordsResult{name, tags}
+			results = append(results, result)
+		}
+	}
+	sort.Sort(ByName{results})
+	printKeywordsResults(results)
+	return nil
+}
+
+//oteodoro:  added function
+func printKeywordsResults(results []*FindKeywordsResult) {
+	for _, result := range results {
+		fmt.Printf("%s :  %s\n", result.Name, result.Tags)
+	}
+}
+
 type generateContextKey string
 
 type runOptions struct {
@@ -1329,6 +3799,8 @@ func NewCLI() *cobra.Command {
 	showCmd.Flags().Bool("parameters", false, "Show parameters of a model")
 	showCmd.Flags().Bool("template", false, "Show template of a model")
 	showCmd.Flags().Bool("system", false, "Show system message of a model")
+	showCmd.Flags().Bool("tags", false, "Show tags, capabilities, or personality of a model")
+	showCmd.Flags().Bool("website", false, "Show website entry of a model")
 
 	runCmd := &cobra.Command{
 		Use:     "run MODEL [PROMPT]",
@@ -1411,6 +3883,30 @@ func NewCLI() *cobra.Command {
 		RunE:    DeleteHandler,
 	}
 
+	availCmd := &cobra.Command{
+		Use:     "avail",
+		Short:   "List available models to download",
+		Aliases: []string{"a"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    AvailHandler,
+	}
+	findSizeCmd := &cobra.Command{
+		Use:     "find-size",
+		Short:   "Find compatible size models to download",
+		Args:    cobra.MinimumNArgs(1),
+		Aliases: []string{"fs"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    FindSizeHandler,
+	}
+	findKeywordsCmd := &cobra.Command{
+		Use:     "find-keywords",
+		Short:   "Find model by keywords",
+		Args:    cobra.MinimumNArgs(1),
+		Aliases: []string{"fs"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    FindKeywordsHandler,
+	}
+
 	envVars := envconfig.AsMap()
 
 	envs := []envconfig.EnvVar{envVars["OLLAMA_HOST"]}
@@ -1427,6 +3923,9 @@ func NewCLI() *cobra.Command {
 		copyCmd,
 		deleteCmd,
 		serveCmd,
+		availCmd,
+		findSizeCmd,
+		findKeywordsCmd,
 	} {
 		switch cmd {
 		case runCmd:
@@ -1466,6 +3965,9 @@ func NewCLI() *cobra.Command {
 		psCmd,
 		copyCmd,
 		deleteCmd,
+		availCmd,
+		findSizeCmd,
+		findKeywordsCmd,
 	)
 
 	return rootCmd
Only in ollama-0.4.6/cmd: cmd.go.orig
