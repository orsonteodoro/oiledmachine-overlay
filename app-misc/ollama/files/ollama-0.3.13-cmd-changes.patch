diff '--color=auto' -urp ollama-0.3.13.orig/cmd/cmd.go ollama-0.3.13/cmd/cmd.go
--- ollama-0.3.13.orig/cmd/cmd.go	2024-10-10 11:21:51.000000000 -0700
+++ ollama-0.3.13/cmd/cmd.go	2024-10-21 07:58:51.462495489 -0700
@@ -17,11 +17,13 @@ import (
 	"net"
 	"net/http"
 	"os"
+	"os/exec" // oteodoro:  added line
 	"os/signal"
 	"path/filepath"
 	"regexp"
 	"runtime"
 	"slices"
+	"sort"
 	"strconv"
 	"strings"
 	"sync/atomic"
@@ -47,6 +49,1282 @@ import (
 	"github.com/ollama/ollama/version"
 )
 
+var sizeTable = map[string]string{
+	"adens/quran-guide": "2.0GB",
+	"akx/viking-7b": "4.6GB",
+	"ALIENTELLIGENCE/christiancounselor": "4.7GB",
+	"ALIENTELLIGENCE/crisisintervention": "4.7GB",
+	"ALIENTELLIGENCE/enriquecastillorincon": "4.7GB",
+	"ALIENTELLIGENCE/gamemasterroleplaying": "4.7GB",
+	"ALIENTELLIGENCE/holybible": "4.7GB",
+	"ALIENTELLIGENCE/mentalwellness": "4.7GB",
+	"ALIENTELLIGENCE/pcarchitect": "4.7GB",
+	"ALIENTELLIGENCE/prayerline": "4.7GB",
+	"ALIENTELLIGENCE/sarah": "4.7GB",
+	"ALIENTELLIGENCE/sarahv2": "4.7GB",
+	"ALIENTELLIGENCE/whiterabbit": "4.7GB",
+	"ALIENTELLIGENCE/whiterabbitv2": "4.7GB",
+	"all-minilm:22m": "46MB",
+	"all-minilm:33m": "67MB",
+	"all-minilm:l12": "67MB",
+	"all-minilm:l12-v2": "67MB",
+	"all-minilm:l6": "46MB",
+	"all-minilm:l6-v2": "46MB",
+	"all-minilm:v2": "46MB",
+	"all-minilm:22m-l6-v2-fp16": "46MB",
+	"all-minilm:33m-l12-v2-fp16": "67MB",
+	"Artalius/lixi": "2.0GB",
+	"aya:8b": "4.8GB",
+	"aya:35b": "20GB",
+	"aya:8b-23": "4.8GB",
+	"aya:35b-23": "20GB",
+	"aya:8b-23-q6_K": "6.6GB",
+	"aya:8b-23-q8_0": "8.5GB",
+	"aya:35b-23-q6_K": "29GB",
+	"aya:35b-23-q8_0": "37GB",
+	"benevolentjoker/belial": "4.9GB",
+	"benevolentjoker/bethanygpt": "4.7GB",
+	"benevolentjoker/nsfwmonika": "4.7GB",
+	"benevolentjoker/nsfwvanessa": "4.9GB",
+	"benevolentjoker/satan": "4.9GB",
+	"bge-m3:567m": "1.2GB",
+	"bge-m3:567m-fp16": "1.2GB",
+	"canadiangamer/neena": "3.8GB",
+	"canadiangamer/priya": "3.8GB",
+	"captainkyd/whiterabbitneo7b": "7.2GB",
+	"chatgph/70b-instruct": "53GB",
+	"chatgph/gph-main": "5.5GB",
+	"chatgph/medix-ph": "3.8GB",
+	"codegeex4:9b": "5.5GB",
+	"codegeex4:9b-all-q6_K": "8.3GB",
+	"codegeex4:9b-all-q8_0": "10.0GB",
+	"codegeex4:9b-all-fp16": "19GB",
+	"codegemma:2b": "1.6GB",
+	"codegemma:7b": "5.0GB",
+	"codegemma:code": "1.6GB",
+	"codegemma:instruct": "5.0GB",
+	"codegemma:2b-code": "1.6GB",
+	"codegemma:2b-v1.1": "1.6GB",
+	"codegemma:7b-code": "5.0GB",
+	"codegemma:7b-instruct": "5.0GB",
+	"codegemma:7b-v1.1": "5.0GB",
+	"codegemma:2b-code-q8_0": "2.7GB",
+	"codegemma:2b-code-v1.1-q8_0": "2.7GB",
+	"codegemma:7b-code-q6_K": "7.0GB",
+	"codegemma:7b-instruct-q6_K": "7.0GB",
+	"codegemma:7b-instruct-v1.1-q6_K": "7.0GB",
+	"codegemma:7b-code-q8_0": "9.1GB",
+	"codegemma:7b-instruct-q8_0": "9.1GB",
+	"codegemma:7b-instruct-v1.1-q8_0": "9.1GB",
+	"codegemma:2b-code-fp16": "5.0GB",
+	"codegemma:2b-code-v1.1-fp16": "5.0GB",
+	"codegemma:7b-code-fp16": "17GB",
+	"codegemma:7b-instruct-fp16": "17GB",
+	"codegemma:7b-instruct-v1.1-fp16": "17GB",
+	"codellama:7b": "3.8GB",
+	"codellama:13b": "7.4GB",
+	"codellama:34b": "19GB",
+	"codellama:70b": "39GB",
+	"codellama:code": "3.8GB",
+	"codellama:instruct": "3.8GB",
+	"codellama:python": "3.8GB",
+	"codellama:7b-code": "3.8GB",
+	"codellama:7b-instruct": "3.8GB",
+	"codellama:7b-python": "3.8GB",
+	"codellama:13b-code": "7.4GB",
+	"codellama:13b-instruct": "7.4GB",
+	"codellama:13b-python": "7.4GB",
+	"codellama:34b-code": "19GB",
+	"codellama:34b-instruct": "19GB",
+	"codellama:34b-python": "19GB",
+	"codellama:70b-code": "39GB",
+	"codellama:70b-instruct": "39GB",
+	"codellama:70b-python": "39GB",
+	"codellama:7b-code-q8_0": "7.2GB",
+	"codellama:7b-instruct-q8_0": "7.2GB",
+	"codellama:7b-python-q8_0": "7.2GB",
+	"codellama:13b-code-q8_0": "14GB",
+	"codellama:13b-instruct-q8_0": "14GB",
+	"codellama:13b-python-q8_0": "14GB",
+	"codellama:34b-instruct-q6_K": "28GB",
+	"codellama:34b-python-q6_K": "28GB",
+	"codellama:34b-instruct-q8_0": "36GB",
+	"codellama:34b-python-q8_0": "36GB",
+	"codellama:70b-code-q8_0": "73GB",
+	"codellama:70b-instruct-q8_0": "73GB",
+	"codellama:70b-python-q8_0": "73GB",
+	"codellama:7b-code-fp16": "13GB",
+	"codellama:7b-instruct-fp16": "13GB",
+	"codellama:7b-python-fp16": "13GB",
+	"codellama:13b-code-fp16": "26GB",
+	"codellama:13b-instruct-fp16": "26GB",
+	"codellama:13b-python-fp16": "26GB",
+	"codellama:34b-instruct-fp16": "67GB",
+	"codellama:34b-python-fp16": "67GB",
+	"codellama:70b-code-fp16": "138GB",
+	"codellama:70b-instruct-fp16": "138GB",
+	"codellama:70b-python-fp16": "138GB",
+	"codeqwen:7b": "4.2GB",
+	"codeqwen:chat": "4.2GB",
+	"codeqwen:code": "4.2GB",
+	"codeqwen:v1.5": "4.2GB",
+	"codeqwen:v1.5-chat": "4.2GB",
+	"codeqwen:v1.5-code": "4.2GB",
+	"codeqwen:7b-chat": "4.2GB",
+	"codeqwen:7b-code": "4.2GB",
+	"codeqwen:7b-chat-v1.5-q8_0": "7.7GB",
+	"codeqwen:7b-code-v1.5-q8_0": "7.7GB",
+	"codeqwen:7b-chat-v1.5-fp16": "15GB",
+	"codeqwen:7b-code-v1.5-fp16": "15GB",
+	"codeup:13b": "7.4GB",
+	"codeup:13b-llama2": "7.4GB",
+	"codeup:13b-llama2-chat": "7.4GB",
+	"codeup:13b-llama2-chat-q8_0": "14GB",
+	"codeup:13b-llama2-chat-fp16": "26GB",
+	"command-r:35b": "19GB",
+	"command-r:35b-08-2024-q6_K": "27GB",
+	"command-r:35b-v0.1-q6_K": "29GB",
+	"command-r:35b-08-2024-q8_0": "34GB",
+	"command-r:35b-v0.1-q8_0": "37GB",
+	"command-r:35b-08-2024-fp16": "65GB",
+	"command-r:35b-v0.1-fp16": "70GB",
+	"command-r:v0.1": "20GB",
+	"command-r-plus:104b": "59GB",
+	"command-r-plus:104b-08-2024-q8_0": "110GB",
+	"command-r-plus:104b-08-2024-fp16": "208GB",
+	"deepseek-coder-v2:16b": "8.9GB",
+	"deepseek-coder-v2:236b": "133GB",
+	"deepseek-coder-v2:lite": "8.9GB",
+	"deepseek-coder-v2:16b-lite-base-q8_0": "17GB",
+	"deepseek-coder-v2:16b-lite-instruct-q8_0": "17GB",
+	"deepseek-coder-v2:236b-lite-base-q8_0": "251GB",
+	"deepseek-coder-v2:236b-lite-instruct-q8_0": "251GB",
+	"deepseek-coder-v2:16b-lite-base-fp16": "31GB",
+	"deepseek-coder-v2:16b-lite-instruct-fp16": "31GB",
+	"deepseek-coder-v2:236b-lite-base-fp16": "472GB",
+	"deepseek-coder-v2:236b-lite-instruct-fp16": "472GB",
+	"disinfozone/telos": "5.1GB",
+	"eramax/aura_v3:Q5": "5.1GB",
+	"gemma:2b": "1.7GB",
+	"gemma:7b": "5.0GB",
+	"gemma:instruct": "5.0GB",
+	"gemma:text": "5.2GB",
+	"gemma:v1.1": "5.0GB",
+	"gemma:2b-instruct": "1.6GB",
+	"gemma:2b-text": "1.7GB",
+	"gemma:2b-v1.1": "1.6GB",
+	"gemma:7b-instruct": "5.0GB",
+	"gemma:7b-text": "5.2GB",
+	"gemma:7b-v1.1": "5.0GB",
+	"gemma:2b-instruct-q8_0": "2.7GB",
+	"gemma:2b-instruct-v1.1-q8_0": "2.7GB",
+	"gemma:2b-text-q8_0": "2.7GB",
+	"gemma:7b-instruct-q8_0": "9.1GB",
+	"gemma:7b-instruct-v1.1-q8_0": "9.1GB",
+	"gemma:7b-text-q8_0": "9.1GB",
+	"gemma:2b-instruct-fp16": "4.5GB",
+	"gemma:2b-instruct-v1.1-fp16": "5.0GB",
+	"gemma:2b-text-fp16": "4.5GB",
+	"gemma:7b-instruct-fp16": "17GB",
+	"gemma:7b-instruct-v1.1-fp16": "17GB",
+	"gemma:7b-text-fp16": "16GB",
+	"gemma2:2b": "1.6GB",
+	"gemma2:9b": "5.4GB",
+	"gemma2:27b": "16GB",
+	"gemma2:2b-instruct-q8_0": "2.8GB",
+	"gemma2:2b-text-q8_0": "2.8GB",
+	"gemma2:9b-instruct-q8_0": "9.8GB",
+	"gemma2:9b-text-q8_0": "9.8GB",
+	"gemma2:27b-instruct-q8_0": "29GB",
+	"gemma2:27b-text-q8_0": "29GB",
+	"gemma2:2b-instruct-fp16": "5.2GB",
+	"gemma2:2b-text-fp16": "5.2GB",
+	"gemma2:9b-instruct-fp16": "18GB",
+	"gemma2:9b-text-fp16": "18GB",
+	"gemma2:27b-instruct-fp16": "54GB",
+	"gemma2:27b-text-fp16": "54GB",
+	"granite-code:3b": "2.0GB",
+	"granite-code:8b": "4.6GB",
+	"granite-code:20b": "12GB",
+	"granite-code:34b": "19GB",
+	"granite-code:3b-base": "2.0GB",
+	"granite-code:3b-instruct": "2.0GB",
+	"granite-code:8b-base": "4.6GB",
+	"granite-code:8b-instruct": "4.6GB",
+	"granite-code:20b-base": "12GB",
+	"granite-code:34b-base": "19GB",
+	"granite-code:3b-base-q8_0": "3.7GB",
+	"granite-code:3b-instruct-q8_0": "3.7GB",
+	"granite-code:3b-128k-instruct-q8_0": "3.7GB",
+	"granite-code:8b-base-q6_K": "6.6GB",
+	"granite-code:8b-base-q8_0": "8.6GB",
+	"granite-code:8b-instruct-q6_K": "6.6GB",
+	"granite-code:8b-instruct-q8_0": "8.6GB",
+	"granite-code:8b-instruct-128k-q4_0": "4.6GB",
+	"granite-code:8b-instruct-128k-q4_1": "5.1GB",
+	"granite-code:20b-base-q5_K_M": "15GB",
+	"granite-code:20b-base-q8_0": "21GB",
+	"granite-code:20b-instruct-8k-q6_K": "15GB",
+	"granite-code:20b-instruct-8k-q8_0": "21GB",
+	"granite-code:34b-base-q6_K": "28GB",
+	"granite-code:34b-base-q8_0": "36GB",
+	"granite-code:34b-instruct-q6_K": "28GB",
+	"granite-code:34b-instruct-q8_0": "36GB",
+	"granite-code:3b-base-fp16": "7.0GB",
+	"granite-code:3b-instruct-fp16": "7.0GB",
+	"granite-code:3b-128k-instruct-fp16": "7.0GB",
+	"granite-code:8b-base-fp16": "16GB",
+	"granite-code:8b-instruct-fp16": "16GB",
+	"granite-code:20b-base-fp16": "40GB",
+	"granite-code:20b-instruct-8k-fp16": "40GB",
+	"jimscard/adult-film-screenwriter-nsfw": "4.1GB",
+	"jimscard/whiterabbit-neo:13b": "9.2GB",
+	"jimscard/whiterabbit-neo:13b-q5": "9.2GB",
+	"jimscard/whiterabbit-neo:13b-q5_K_M": "9.2GB",
+	"llava:7b": "4.7GB",
+	"llava:13b": "8.0GB",
+	"llava:34b": "20.0GB",
+	"llava:v1.6": "4.7GB",
+	"llava:7b-v1.6": "4.7GB",
+	"llava:13b-v1.6": "8.0GB",
+	"llava:34b-v1.6": "20.0GB",
+	"llava:7b-v1.5-q8_0": "7.8GB",
+	"llava:7b-v1.6-mistral-q6_K": "6.6GB",
+	"llava:7b-v1.6-mistral-q8_0": "8.3GB",
+	"llava:7b-v1.6-vicuna-q8_0": "7.8GB",
+	"llava:13b-v1.5-q8_0": "14GB",
+	"llava:13b-v1.6-vicuna-q8_0": "14GB",
+	"llava:34b-v1.6-q6_K": "29GB",
+	"llava:34b-v1.6-q8_0": "37GB",
+	"llava:7b-v1.5-fp16": "14GB",
+	"llava:7b-v1.6-mistral-fp16": "15GB",
+	"llava:7b-v1.6-vicuna-fp16": "14GB",
+	"llava:13b-v1.5-fp16": "27GB",
+	"llava:13b-v1.6-vicuna-fp16": "27GB",
+	"llava:34b-v1.6-fp16": "69GB",
+	"llama2:7b": "3.8GB",
+	"llama2:13b": "7.4GB",
+	"llama2:70b": "39GB",
+	"llama2:chat": "3.8GB",
+	"llama2:text": "3.8GB",
+	"llama2:7b-chat": "3.8GB",
+	"llama2:7b-text": "3.8GB",
+	"llama2:70b-chat": "39GB",
+	"llama2:70b-text": "39GB",
+	"llama2:7b-chat-q8_0": "7.2GB",
+	"llama2:7b-text-q8_0": "7.2GB",
+	"llama2:13b-chat-q8_0": "14GB",
+	"llama2:13b-text-q8_0": "14GB",
+	"llama2:70b-chat-q6_K": "57GB",
+	"llama2:70b-text-q6_K": "57GB",
+	"llama2:70b-chat-q8_0": "73GB",
+	"llama2:70b-text-q8_0": "73GB",
+	"llama2:7b-chat-fp16": "13GB",
+	"llama2:7b-text-fp16": "13GB",
+	"llama2:13b-chat-fp16": "26GB",
+	"llama2:13b-text-fp16": "26GB",
+	"llama2:70b-chat-fp16": "138GB",
+	"llama2:70b-text-fp16": "138GB",
+	"llama2-uncensored:7b": "3.8GB",
+	"llama2-uncensored:70b": "39GB",
+	"llama2-uncensored:7b-chat": "3.8GB",
+	"llama2-uncensored:70b-chat": "39GB",
+	"llama2-uncensored:7b-chat-q8_0":"7.2GB",
+	"llama2-uncensored:70b-chat-q6_K":"57GB",
+	"llama2-uncensored:70b-chat-q8_0":"73GB",
+	"llama2-uncensored:7b-chat-fp16": "13GB",
+	"llama3:8b": "4.7GB",
+	"llama3:70b": "40GB",
+	"llama3:instruct": "4.7GB",
+	"llama3:text": "4.7GB",
+	"llama3:8b-text": "4.7GB",
+	"llama3:70b-instruct": "40GB",
+	"llama3:70b-text": "40GB",
+	"llama3:8b-instruct-q6_K": "6.6GB",
+	"llama3:8b-text-q6_K": "6.6GB",
+	"llama3:8b-instruct-q8_0": "8.5GB",
+	"llama3:8b-text-q8_0": "8.5GB",
+	"llama3:70b-instruct-q6_K": "58GB",
+	"llama3:70b-text-q6_K": "58GB",
+	"llama3:70b-instruct-q8_0": "75GB",
+	"llama3:70b-text-q8_0": "75GB",
+	"llama3:8b-instruct-fp16": "16GB",
+	"llama3:8b-text-fp16": "16GB",
+	"llama3:70b-instruct-fp16": "141GB",
+	"llama3:70b-text-fp16": "141GB",
+	"llama3.1:8b": "4.7GB",
+	"llama3.1:70b": "40GB",
+	"llama3.1:405b": "229GB",
+	"llama3.1:8b-instruct-q6_K": "6.6GB",
+	"llama3.1:8b-text-q6_K": "6.6GB",
+	"llama3.1:8b-instruct-q8_0": "8.5GB",
+	"llama3.1:8b-text-q8_0": "8.5GB",
+	"llama3.1:70b-instruct-q6_K": "58GB",
+	"llama3.1:70b-text-q6_K": "58GB",
+	"llama3.1:70b-instruct-q8_0": "75GB",
+	"llama3.1:70b-text-q8_0": "75GB",
+	"llama3.1:405b-instruct-q8_0": "431GB",
+	"llama3.1:405b-text-q8_0": "431GB",
+	"llama3.1:8b-instruct-fp16": "16GB",
+	"llama3.1:8b-text-fp16": "16GB",
+	"llama3.1:70b-instruct-fp16": "141GB",
+	"llama3.1:70b-text-fp16": "141GB",
+	"llama3.1:405b-instruct-fp16": "812GB",
+	"llama3.1:405b-text-fp16": "812GB",
+	"llama3.2:3b": "2.0GB",
+	"llama3.2:1b": "1.3GB",
+	"llama3.2:1b-instruct-q5_1": "953MB",
+	"llama3.2:1b-text-q5_1": "953MB",
+	"llama3.2:1b-instruct-q6_K": "1.0GB",
+	"llama3.2:1b-text-q6_K": "1.0GB",
+	"llama3.2:1b-instruct-q8.0": "1.3GB",
+	"llama3.2:1b-text-q8_0": "1.3GB",
+	"llama3.2:3b-instruct-q8_0": "3.4GB",
+	"llama3.2:3b-text-q8_0": "3.4GB",
+	"llama3.2:1b-instruct-fp16": "2.5GB",
+	"llama3.2:1b-text-fp16": "2.5GB",
+	"llama3.2:3b-instruct-fp16": "6.4GB",
+	"llama3.2:3b-text-fp16": "6.4GB",
+	"llama-guard3:1b": "1.6GB",
+	"llama-guard3:8b": "4.9GB",
+	"llama-guard3:1b-q4_1": "996GB",
+	"llama-guard3:1b-q8_0": "1.6GB",
+	"llama-guard3:8b-q6_K": "6.6GB",
+	"llama-guard3:8b-q8_0": "8.5GB",
+	"llama-guard3:1b-fp16": "3.0GB",
+	"llama-guard3:8b-fp16": "16GB",
+	"magicoder:7b": "3.8GB",
+	"magicoder:7b-s-cl-q8_0": "7.2GB",
+	"magicoder:7b-s-cl-fp16": "13GB",
+	"mannix/replete-adapted-llama3-8b:iq4_xs": "4.4GB",
+	"mannix/replete-adapted-llama3-8b:iq4_nl": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_0": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_k_s": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_k_m": "4.9GB",
+	"mannix/replete-adapted-llama3-8b:q4_1": "5.1GB",
+	"mannix/replete-adapted-llama3-8b:q5_0": "5.6GB",
+	"mannix/replete-adapted-llama3-8b:q5_1": "6.1GB",
+	"mannix/replete-adapted-llama3-8b:q5_k_s": "6.1GB",
+	"mannix/replete-adapted-llama3-8b:q6_k": "6.6GB",
+	"mannix/replete-adapted-llama3-8b:q8_0": "8.5GB",
+	"mannix/replete-adapted-llama3-8b:fp16": "16GB",
+	"mannix/replete-coder-llama3-8b:q8_0": "8.5GB",
+	"mannix/replete-coder-llama3-8b:fp16": "16GB",
+	"mistral:7b": "4.1GB",
+	"mistral:instruct": "4.1GB",
+	"mistral:text": "4.1GB",
+	"mistral:v0.1": "4.1GB",
+	"mistral:v0.2": "4.1GB",
+	"mistral:v0.3": "4.1GB",
+	"mistral:7b-instruct": "4.1GB",
+	"mistral:7b-text": "4.1GB",
+	"mistral:7b-instruct-q6_K": "5.9GB",
+	"mistral:7b-instruct-v0.2-q6_K": "5.9GB",
+	"mistral:7b-instruct-v0.3-q6_K": "5.9GB",
+	"mistral:7b-text-q6_K": "5.9GB",
+	"mistral:7b-text-v0.2-q6_K": "5.9GB",
+	"mistral:7b-instruct-q8_0": "7.7GB",
+	"mistral:7b-instruct-v0.2-q8_0": "7.7GB",
+	"mistral:7b-instruct-v0.3-q8_0": "7.7GB",
+	"mistral:7b-text-q8_0": "7.7GB",
+	"mistral:7b-text-v0.2-q8_0": "7.7GB",
+	"mistral:7b-instruct-fp16": "14GB",
+	"mistral:7b-instruct-v0.2-fp16": "14GB",
+	"mistral:7b-instruct-v0.3-fp16": "14GB",
+	"mistral:7b-text-fp16": "14GB",
+	"mistral:7b-text-v0.2-fp16": "14GB",
+	"mistral-large:123b": "69GB",
+	"mistral-large:123b-instruct-2407-q6_K": "101GB",
+	"mistral-large:123b-instruct-2407-q8_0": "130GB",
+	"mistral-large:123b-instruct-2407-fp16": "245GB",
+	"mistral-nemo:12b": "7.1GB",
+	"mistral-nemo:12b-instruct-2407-q8_0": "13GB",
+	"mistral-nemo:12b-instruct-2407-fp16": "25GB",
+	"mistral-small:22b": "13GB",
+	"mistral-small:22b-instruct-2409-q5_0": "15GB",
+	"mistral-small:22b-instruct-2409-q5_K_S": "15GB",
+	"mistral-small:22b-instruct-2409-q5_K_M": "16GB",
+	"mistral-small:22b-instruct-2409-q8_0": "24GB",
+	"mistral-small:22b-instruct-2409-fp16": "44GB",
+	"mixtral:8x7b": "26GB",
+	"mixtral:8x22b": "80GB",
+	"mixtral:instruct": "26GB",
+	"mixtral:text": "26GB",
+	"mixtral:v0.1": "80GB",
+	"mixtral:v0.1-instruct": "80GB",
+	"mixtral:8x22b-instruct": "80GB",
+	"mixtral:8x22b-text": "80GB",
+	"mixtral:8x7b-instruct-v0.1-q8_0": "50GB",
+	"mixtral:8x7b-text-v0.1-q8_0": "50GB",
+	"mixtral:8x22b-instruct-v0.1-q6_K": "115GB",
+	"mixtral:8x22b-text-v0.1-q6_K": "115GB",
+	"mixtral:8x22b-instruct-v0.1-q8_0": "149GB",
+	"mixtral:8x22b-text-v0.1-q8_0": "149GB",
+	"mixtral:8x7b-instruct-v0.1-fp16": "93GB",
+	"mixtral:8x7b-text-v0.1-fp16": "93GB",
+	"mixtral:8x22b-instruct-v0.1-fp16": "281GB",
+	"mixtral:8x22b-text-v0.1-fp16": "281GB",
+	"monotykamary/whiterabbitneo-v1.5a:7b": "4.1GB",
+	"monotykamary/whiterabbitneo-v1.5a:7b_q4_K_M": "4.1GB",
+	"nemotron:70b": "43GB",
+	"nemotron:70b-instruct-q6_K": "58GB",
+	"nemotron:70b-instruct-q8_0": "75GB",
+	"nemotron:70b-instruct-fp16": "141GB",
+	"nemotron-mini:4b": "2.7GB",
+	"nemotron-mini:4b-instruct-q6_K": "3.4GB",
+	"nemotron-mini:4b-instruct-q8_0": "4.5GB",
+	"nemotron-mini:4b-instruct-fp16": "8.4GB",
+	"meditron:7b": "3.8GB",
+	"meditron:70b": "39GB",
+	"meditron:7b-q8_0": "7.2GB",
+	"meditron:70b-q5_1": "52GB",
+	"meditron:7b-fp16": "13GB",
+	"medllama2:7b": "3.8GB",
+	"medllama2:7b-q8_0": "7.2GB",
+	"medllama2:7b-fp16": "13GB",
+	"moondream:1.8b": "1.7GB",
+	"moondream:v2": "1.7GB",
+	"moondream:1.8b-v2-q5_0": "1.9GB",
+	"moondream:1.8b-v2-q5_1": "2.0GB",
+	"moondream:1.8b-v2-q8_0": "2.4GB",
+	"moondream:1.8b-v2-fp16": "3.7GB",
+	"nomic-embed-text:v1.5": "274MB",
+	"nomic-embed-text:137m-v1.5-fp16": "274MB",
+	"nqduc/gemsura:2b": "5.0GB",
+	"nqduc/gemsura:7b": "17.0GB",
+	"nqduc/gemsura:2b-q4_0": "1.6GB",
+	"nqduc/gemsura:2b-q8_0": "2.7GB",
+	"nqduc/gemsura:7b-q4_0": "5.0GB",
+	"nqduc/gemsura:7b-q8_0": "9.1GB",
+	"nqduc/mixsura:mixsura-q4_0": "26GB",
+	"nqduc/mixsura:mixsura-q4_1": "29GB",
+	"nqduc/mixsura:mixsura-q5_0": "32GB",
+	"nqduc/mixsura:mixsura-q5_1": "35GB",
+	"nqduc/mixsura:mixsura-q6_K": "38GB",
+	"nqduc/mixsura:mixsura-q8_0": "50GB",
+	"nqduc/mixsura:mixsura-fp16": "93GB",
+	"nqduc/mixsura-sft:mixsura-sft-fp16": "93GB",
+	"nqduc/mixsura-sft:mixsura-sft-q4_0": "26GB",
+	"nqduc/mixsura-sft:mixsura-sft-q4_1": "29GB",
+	"nqduc/mixsura-sft:mixsura-sft-q5_0": "32GB",
+	"nqduc/mixsura-sft:mixsura-sft-q5_1": "35GB",
+	"nqduc/mixsura-sft:mixsura-sft-q6_K": "38GB",
+	"nqduc/mixsura-sft:mixsura-sft-q8_0": "50GB",
+	"nxbai-embed-large:335m": "670MB",
+	"nxbai-embed-large:v1": "670MB",
+	"nxbai-embed-large:335m-v1-fp16": "670MB",
+	"orca2:7b": "3.8GB",
+	"orca2:13b": "7.4GB",
+	"orca2:7b-q8_0": "7.2GB",
+	"orca2:13b-q8_0": "14GB",
+	"orca2:7b-fp16": "13GB",
+	"orca2:13b-fp16": "26GB",
+	"partai/dorna-llama3:8b-instruct-q4_0": "4.7GB",
+	"partai/dorna-llama3:8b-instruct-q5_0": "5.6GB",
+	"partai/dorna-llama3:8b-instruct-q8_0": "8.5GB",
+	"phi3:3.8b": "2.2GB",
+	"phi3:14b": "7.9GB",
+	"phi3:instruct": "2.2GB",
+	"phi3:medium": "7.9GB",
+	"phi3:medium-128k": "7.9GB",
+	"phi3:medium-4k": "7.9GB",
+	"phi3:mini": "2.2GB",
+	"phi3:mini-128k": "2.2GB",
+	"phi3:mini-4k": "2.2GB",
+	"phi3:3.8b-instruct": "2.2GB",
+	"phi3:14b-instruct": "7.9GB",
+	"phi3:3.8b-mini-128k-instruct-q8_0": "4.1GB",
+	"phi3:3.8b-mini-4k-instruct-q8_0": "4.1GB",
+	"phi3:14b-medium-128k-instruct-q8_0": "15GB",
+	"phi3:14b-medium-4k-instruct-q8_0": "15GB",
+	"phi3:3.8b-mini-128k-instruct-fp16": "7.6GB",
+	"phi3:3.8b-mini-4k-instruct-fp16": "7.6GB",
+	"phi3:14b-medium-128k-instruct-fp16": "28GB",
+	"phi3:14b-medium-4k-instruct-fp16": "28GB",
+	"phi3.5:3.8b": "2.2GB",
+	"phi3.5:3.8b-mini-instruct-q8_0": "4.1GB",
+	"phi3.5:3.8b-mini-instruct-fp16": "7.6GB",
+	"qwen:0.5b": "395MB",
+	"qwen:1.8b": "1.1GB",
+	"qwen:4b": "2.3GB",
+	"qwen:7b": "4.5GB",
+	"qwen:14b": "8.2GB",
+	"qwen:32b": "18GB",
+	"qwen:72b": "41GB",
+	"qwen:110b": "63GB",
+	"qwen:0.5b-chat": "395MB",
+	"qwen:0.5b-text": "395MB",
+	"qwen:1.8b-chat": "1.1GB",
+	"qwen:1.8b-text": "1.1GB",
+	"qwen:4b-chat": "2.3GB",
+	"qwen:4b-text": "2.3GB",
+	"qwen:7b-chat": "4.5GB",
+	"qwen:7b-text": "4.5GB",
+	"qwen:14b-chat": "8.2GB",
+	"qwen:14b-text": "8.2GB",
+	"qwen:32b-chat": "18GB",
+	"qwen:32b-text": "18GB",
+	"qwen:72b-chat": "41GB",
+	"qwen:72b-text": "63GB",
+	"qwen:110b-chat": "63GB",
+	"qwen:7b-fp16": "15GB",
+	"qwen:0.5b-chat-v1.5-q8_0": "556MB",
+	"qwen:0.5b-text-v1.5-q8_0": "665MB",
+	"qwen:1.8b-chat-q8_0": "2.0GB",
+	"qwen:1.8b-chat-v1.5-q8_0": "2.0GB",
+	"qwen:1.8b-text-q8_0": "2.0GB",
+	"qwen:1.8b-text-v1.5-q8_0": "2.0GB",
+	"qwen:4b-chat-v1.5-q8_0": "4.2GB",
+	"qwen:4b-text-v1.5-q8_0": "4.2GB",
+	"qwen:7b-chat-q8_0": "8.2GB",
+	"qwen:7b-chat-v1.5-q8_0": "8.2GB",
+	"qwen:7b-text-v1.5-q8_0": "8.2GB",
+	"qwen:14b-chat-q8_0": "15GB",
+	"qwen:14b-chat-v1.5-q8_0": "15GB",
+	"qwen:14b-text-q8_0": "15GB",
+	"qwen:14b-text-v1.5-q8_0": "15GB",
+	"qwen:32b-chat-v1.5-q8_0": "35GB",
+	"qwen:32b-text-v1.5-q8_0": "35GB",
+	"qwen:72b-chat-q8_0": "77GB",
+	"qwen:72b-chat-v1.5-q8_0": "77GB",
+	"qwen:72b-text-q8_0": "77GB",
+	"qwen:72b-text-v1.5-q8_0": "77GB",
+	"qwen:110b-chat-v1.5-q8_0": "118GB",
+	"qwen:110b-text-v1.5-q8_0": "118GB",
+	"qwen:0.5b-chat-v1.5-fp16": "1.2GB",
+	"qwen:0.5b-text-v1.5-fp16": "1.2GB",
+	"qwen:1.8b-chat-fp16": "3.7GB",
+	"qwen:1.8b-chat-v1.5-fp16": "3.7GB",
+	"qwen:1.8b-text-fp16": "3.7GB",
+	"qwen:1.8b-text-v1.5-fp16": "3.7GB",
+	"qwen:4b-chat-v1.5-fp16": "7.9GB",
+	"qwen:4b-text-v1.5-fp16": "7.9GB",
+	"qwen:7b-chat-fp16": "15GB",
+	"qwen:7b-chat-v1.5-fp16": "15GB",
+	"qwen:7b-text-v1.5-fp16": "15GB",
+	"qwen:14b-chat-fp16": "28GB",
+	"qwen:14b-chat-v1.5-fp16": "28GB",
+	"qwen:14b-text-fp16": "28GB",
+	"qwen:14b-text-v1.5-fp16": "28GB",
+	"qwen:32b-chat-v1.5-fp16": "65GB",
+	"qwen:72b-chat-fp16": "145GB",
+	"qwen:72b-chat-v1.5-fp16": "145GB",
+	"qwen:72b-text-fp16": "145GB",
+	"qwen:72b-text-v1.5-fp16": "145GB",
+	"qwen:110b-chat-v1.5-fp16": "222GB",
+	"qwen:110b-text-v1.5-fp16": "222GB",
+	"qwen2:0.5b": "352MB",
+	"qwen2:1.5b": "935MB",
+	"qwen2:7b": "4.4GB",
+	"qwen2:72b": "41GB",
+	"qwen2:0.5b-instruct": "352MB",
+	"qwen2:1.5b-instruct": "935MB",
+	"qwen2:7b-instruct": "4.4GB",
+	"qwen2:7b-text": "4.4GB",
+	"qwen2:72b-instruct": "41GB",
+	"qwen2:72b-text": "41GB",
+	"qwen2:0.5b-instruct-q8_0": "531MB",
+	"qwen2:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2:7b-instruct-q8_0": "8.1GB",
+	"qwen2:7b-text-q8_0": "8.1GB",
+	"qwen2:72b-instruct-q8_0": "77GB",
+	"qwen2:72b-text-q8_0": "77GB",
+	"qwen2:0.5b-instruct-fp16": "994MB",
+	"qwen2:1.5b-instruct-fp16": "3.1GB",
+	"qwen2:7b-instruct-fp16": "15GB",
+	"qwen2:72b-instruct-fp16": "145GB",
+	"qwen2:72b-text-fp16": "145GB",
+	"qwen2-math:1.5b": "935MB",
+	"qwen2-math:7b": "4.4GB",
+	"qwen2-math:72b": "41GB",
+	"qwen2-math:1.5b-instruct": "935MB",
+	"qwen2-math:7b-instruct": "4.4GB",
+	"qwen2-math:72b-instruct": "41GB",
+	"qwen2-math:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2-math:7b-instruct-q6_K": "6.3GB",
+	"qwen2-math:7b-instruct-q8_0": "8.1GB",
+	"qwen2-math:72b-instruct-q6_K": "64GB",
+	"qwen2-math:72b-instruct-q8_0": "77GB",
+	"qwen2-math:1.5b-instruct-fp16": "3.1GB",
+	"qwen2-math:7b-instruct-fp16": "15GB",
+	"qwen2-math:72b-instruct-fp16": "145GB",
+	"qwen2.5:0.5b": "398MB",
+	"qwen2.5:1.5b": "986MB",
+	"qwen2.5:3b": "1.9GB",
+	"qwen2.5:7b": "4.7GB",
+	"qwen2.5:14b": "9.0GB",
+	"qwen2.5:32b": "20.0GB",
+	"qwen2.5:72b": "47.0GB",
+	"qwen2.5:0.5b-base": "398MB",
+	"qwen2.5:0.5b-instruct": "398MB",
+	"qwen2.5:1.5b-instruct": "986MB",
+	"qwen2.5:3b-instruct": "1.9GB",
+	"qwen2.5:7b-instruct": "4.7GB",
+	"qwen2.5:14b-instruct": "9.0GB",
+	"qwen2.5:32b-instruct": "20GB",
+	"qwen2.5:72b-instruct": "47GB",
+	"qwen2.5:7b-instruct-q6_K": "6.3GB",
+	"qwen2.5:32b-instruct-q6_K": "27GB",
+	"qwen2.5:72b-instruct-q6_K": "64GB",
+	"qwen2.5:0.5b-instruct-q8_0": "531MB",
+	"qwen2.5:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2.5:3b-instruct-q8_0": "3.3GB",
+	"qwen2.5:7b-instruct-q8_0": "8.1GB",
+	"qwen2.5:14b-instruct-q8_0": "16GB",
+	"qwen2.5:32b-instruct-q8_0": "35GB",
+	"qwen2.5:72b-instruct-q8_0": "77GB",
+	"qwen2.5:0.5b-instruct-fp16": "994MB",
+	"qwen2.5:1.5b-instruct-fp16": "3.1GB",
+	"qwen2.5:3b-instruct-fp16": "6.2GB",
+	"qwen2.5:7b-instruct-fp16": "15GB",
+	"qwen2.5:14b-instruct-fp16": "30GB",
+	"qwen2.5:32b-instruct-fp16": "66GB",
+	"qwen2.5:72b-instruct-fp16": "145GB",
+	"qwen2.5-coder:1.5b": "986MB",
+	"qwen2.5-coder:7b": "4.7GB",
+	"qwen2.5-coder:1.5b-base": "986MB",
+	"qwen2.5-coder:1.5b-instruct": "986MB",
+	"qwen2.5-coder:7b-base": "4.7GB",
+	"qwen2.5-coder:7b-instruct": "4.7GB",
+	"qwen2.5-coder:1.5b-base-fp16": "3.1GB",
+	"qwen2.5-coder:1.5b-instruct-fp16": "3.1GB",
+	"qwen2.5-coder:7b-base-fp16": "15GB",
+	"qwen2.5-coder:7b-instruct-fp16": "15GB",
+//	"reefer/erplegend": "4.7GB",
+	"reefer/her2": "4.7GB",
+	"reefer/minimonica": "2.1GB",
+	"reefer/monica": "4.7GB",
+//	"reefer/monicacodestral22b": "8.3GB",
+//	"reefer/monicamaxlvl": "4.7GB",
+//	"reefer/reefloaded": "4.9GB",
+//	"reefer/erphermesl3": "6.6",
+//	"reefer/reefproherm2llama3instruct": "5.7GB",
+	"rfc/whiterabbitneo": "7.4GB",
+	"rouge/replete-coder-qwen2-1.5b:latest": "6.2GB",
+	"rouge/replete-coder-qwen2-1.5b:Q8": "1.9GB",
+	"rouge/replete-coder-qwen2-1.5b:f16": "3.1GB",
+	"samantha-mistral:7b": "4.1GB",
+	"samantha-mistral:7b-text": "4.1GB",
+	"samantha-mistral:7b-v1.2-text": "4.1GB",
+	"samantha-mistral:7b-instruct-q8_0": "7.7GB",
+	"samantha-mistral:7b-text-q8_0": "7.7GB",
+	"samantha-mistral:7b-v1.2-text-q8_0": "7.7GB",
+	"samantha-mistral:7b-instruct-fp16": "14GB",
+	"samantha-mistral:7b-text-fp16": "14GB",
+	"samantha-mistral:7b-v1.2-text-fp16": "14GB",
+	"savethedoctor/whiterabbitneo13bq8_0": "14GB",
+	"shieldgemma:2b": "1.7GB",
+	"shieldgemma:9b": "5.8GB",
+	"shieldgemma:27b": "17GB",
+	"shieldgemma:2b-fp16": "5.2GB",
+	"shieldgemma:9b-fp16": "18GB",
+	"shieldgemma:27b-fp16": "54GB",
+	"smollm:135m": "92MB",
+	"smollm:360m": "229MB",
+	"smollm:1.7b": "991MB",
+	"smollm:135m-base-v0.2-fp16": "271MB",
+	"smollm:135m-base-v0.2-q2_K": "88MB",
+	"smollm:135m-base-v0.2-q3_K_S": "88MB",
+	"smollm:135m-base-v0.2-q3_K_M": "88MB",
+	"smollm:135m-base-v0.2-q3_K_L": "94MB",
+	"smollm:135m-base-v0.2-q4_0": "92MB",
+	"smollm:135m-base-v0.2-q4_1": "98MB",
+	"smollm:135m-base-v0.2-q4_K_S": "102MB",
+	"smollm:135m-base-v0.2-q4_K_M": "105MB",
+	"smollm:135m-base-v0.2-q5_0": "105MB",
+	"smollm:135m-base-v0.2-q5_1": "112MB",
+	"smollm:135m-base-v0.2-q5_K_S": "110MB",
+	"smollm:135m-base-v0.2-q5_K_M": "112MB",
+	"smollm:135m-base-v0.2-q6_K": "138MB",
+	"smollm:135m-base-v0.2-q6_0": "145MB",
+	"smollm:135m-instruct-v0.2-fp16": "271MB",
+	"smollm:135m-instruct-v0.2-q2_K": "88MB",
+	"smollm:135m-instruct-v0.2-q3_K_S": "88MB",
+	"smollm:135m-instruct-v0.2-q3_K_M": "94MB",
+	"smollm:135m-instruct-v0.2-q3_K_L": "98MB",
+	"smollm:135m-instruct-v0.2-q4_0": "92MB",
+	"smollm:135m-instruct-v0.2-q4_1": "98MB",
+	"smollm:135m-instruct-v0.2-q4_K_S": "102MB",
+	"smollm:135m-instruct-v0.2-q4_K_M": "105MB",
+	"smollm:135m-instruct-v0.2-q5_0": "105MB",
+	"smollm:135m-instruct-v0.2-q5_1": "112MB",
+	"smollm:135m-instruct-v0.2-q5_K_S": "110MB",
+	"smollm:135m-instruct-v0.2-q5_K_M": "112MB",
+	"smollm:135m-instruct-v0.2-q6_K": "138MB",
+	"smollm:135m-instruct-v0.2-q8_0": "145MB",
+	"smollm:360m-base-v0.2-fp16": "726MB",
+	"smollm:360m-base-v0.2-q2_K": "219MB",
+	"smollm:360m-base-v0.2-q3_K_S": "219MB",
+	"smollm:360m-base-v0.2-q3_K_M": "219MB",
+	"smollm:360m-base-v0.2-q3_K_L": "246MB",
+	"smollm:360m-base-v0.2-q4_0": "229MB",
+	"smollm:360m-base-v0.2-q4_1": "249MB",
+	"smollm:360m-base-v0.2-q4_K_S": "260MB",
+	"smollm:360m-base-v0.2-q4_K_M": "271MB",
+	"smollm:360m-base-v0.2-q5_0": "268MB",
+	"smollm:360m-base-v0.2-q5_1": "288MB",
+	"smollm:360m-base-v0.2-q5_K_S": "283MB",
+	"smollm:360m-base-v0.2-q5_K_M": "290MB",
+	"smollm:360m-base-v0.2-q6_K": "367MB",
+	"smollm:360m-base-v0.2-q8_K": "386MB",
+	"smollm:360m-instruct-v0.2-fp16": "726MB",
+	"smollm:360m-instruct-v0.2-q2_K": "219MB",
+	"smollm:360m-instruct-v0.2-q3_K_S": "219MB",
+	"smollm:360m-instruct-v0.2-q3_K_M": "235MB",
+	"smollm:360m-instruct-v0.2-q3_K_L": "246MB",
+	"smollm:360m-instruct-v0.2-q4_0": "229MB",
+	"smollm:360m-instruct-v0.2-q4_1": "249MB",
+	"smollm:360m-instruct-v0.2-q4_K_S": "260MB",
+	"smollm:360m-instruct-v0.2-q4_K_M": "271MB",
+	"smollm:360m-instruct-v0.2-q5_0": "268MB",
+	"smollm:360m-instruct-v0.2-q5_1": "288MB",
+	"smollm:360m-instruct-v0.2-q5_K_S": "283MB",
+	"smollm:360m-instruct-v0.2-q5_K_M": "290MB",
+	"smollm:360m-instruct-v0.2-q6_K": "367MB",
+	"smollm:360m-instruct-v0.2-q8_0": "386MB",
+	"smollm:1.7b-base-v0.2-fp16": "3.4GB",
+	"smollm:1.7b-base-v0.2-q2_K": "675MB",
+	"smollm:1.7b-base-v0.2-q3_K_S": "777MB",
+	"smollm:1.7b-base-v0.2-q3_K_M": "860MB",
+	"smollm:1.7b-base-v0.2-q3_K_L": "933MB",
+	"smollm:1.7b-base-v0.2-q4_0": "991MB",
+	"smollm:1.7b-base-v0.2-q4_1": "1.1GB",
+	"smollm:1.7b-base-v0.2-q4_K_S": "999MB",
+	"smollm:1.7b-base-v0.2-q4_K_M": "1.1GB",
+	"smollm:1.7b-base-v0.2-q5_0": "1.2GB",
+	"smollm:1.7b-base-v0.2-q5_1": "1.3GB",
+	"smollm:1.7b-base-v0.2-q5_K_S": "1.2GB",
+	"smollm:1.7b-base-v0.2-q5_K_M": "1.2GB",
+	"smollm:1.7b-base-v0.2-q6_K": "1.4GB",
+	"smollm:1.7b-base-v0.2-q8_K": "1.8GB",
+	"smollm:1.7b-instruct-v0.2-fp16": "3.4GB",
+	"smollm:1.7b-instruct-v0.2-q2_K": "675MB",
+	"smollm:1.7b-instruct-v0.2-q3_K_S": "777MB",
+	"smollm:1.7b-instruct-v0.2-q3_K_M": "860MB",
+	"smollm:1.7b-instruct-v0.2-q3_K_L": "933MB",
+	"smollm:1.7b-instruct-v0.2-q4_0": "991MB",
+	"smollm:1.7b-instruct-v0.2-q4_1": "1.1GB",
+	"smollm:1.7b-instruct-v0.2-q4_K_S": "999MB",
+	"smollm:1.7b-instruct-v0.2-q4_K_M": "1.1GB",
+	"smollm:1.7b-instruct-v0.2-q5_0": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q5_1": "1.3GB",
+	"smollm:1.7b-instruct-v0.2-q5_K_S": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q5_K_M": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q6_K": "1.4GB",
+	"smollm:1.7b-instruct-v0.2-q8_K": "1.8GB",
+	"solar:10.7b": "6.1GB",
+	"solar:10.7b-instruct-v1-q5_0": "7.4GB",
+	"solar:10.7b-text-v1-q5_0": "7.4GB",
+	"solar:10.7b-instruct-v1-q8_0": "11GB",
+	"solar:10.7b-text-v1-q8_0": "11GB",
+	"solar:10.7b-instruct-v1-fp16": "21GB",
+	"solar:10.7b-text-v1-fp16": "21GB",
+	"solar-pro:22b": "13GB",
+	"solar-pro:preview": "13GB",
+	"solar-pro:22b-preview-instruct-q5_K_S": "15GB",
+	"solar-pro:22b-preview-instruct-q5_K_M": "16GB",
+	"solar-pro:22b-preview-instruct-q8_0": "24GB",
+	"solar-pro:22b-preview-instruct-fp16": "44GB",
+	"sparksammy/samantha": "3.8GB",
+	"sparksammy/samantha-3.1": "4.7GB",
+	"sparksammy/samantha-eggplant": "11GB",
+	"sparksammy/samantha-v3-uncensored": "4.7GB",
+	"sparksammy/tinysam-goog": "1.7GB",
+	"sparksammy/tinysam-msft": "2.3GB",
+	"sqlcoder:7b": "4.1GB",
+	"sqlcoder:15b": "9GB",
+	"sqlcoder:7b-q8_0": "7.7GB",
+	"sqlcoder:15b-q6_K": "13GB",
+	"sqlcoder:70b-alpha-q6_K": "57GB",
+	"sqlcoder:7b-fp16": "14GB",
+	"sqlcoder:15b-fp16": "32GB",
+	"sqlcoder:70b-alpha-fp16": "138GB",
+	"starcoder:1b": "726MB",
+	"starcoder:3b": "1.8GB",
+	"starcoder:7b": "4.3GB",
+	"starcoder:15b": "9.0GB",
+	"starcoder:1b-base": "726MB",
+	"starcoder:3b-base": "1.8GB",
+	"starcoder:7b-base": "4.3GB",
+	"starcoder:15b-base": "9.0GB",
+	"starcoder:15b-plus": "9.0GB",
+	"starcoder:15b-q6_K": "13GB",
+	"starcoder:15b-q8_0": "17GB",
+	"starcoder:1b-base-q8_0": "1.3GB",
+	"starcoder:3b-base-q8_0": "3.4GB",
+	"starcoder:7b-base-q8_0": "8GB",
+	"starcoder:15b-base-q6_K": "13GB",
+	"starcoder:15b-plus-q6_K": "13GB",
+	"starcoder:15b-base-q8_0": "17GB",
+	"starcoder:15b-plus-q8_0": "17GB",
+	"starcoder:15b-fp16": "32GB",
+	"starcoder:1b-base-fp16": "2.5GB",
+	"starcoder:3b-base-fp16": "6.4GB",
+	"starcoder:7b-base-fp16": "15GB",
+	"starcoder:15b-base-fp16": "32GB",
+	"starcoder:15b-plus-fp16": "32GB",
+	"starcoder2:3b": "1.7GB",
+	"starcoder2:7b": "4.0GB",
+	"starcoder2:15b": "9.1GB",
+	"starcoder2:instruct": "9.1GB",
+	"starcoder2:15b-instruct": "9.1GB",
+	"starcoder2:3b-q8_0": "3.2GB",
+	"starcoder2:7b-q8_0": "7.6GB",
+	"starcoder2:15b-q6_K": "13GB",
+	"starcoder2:15b-q8_0": "17GB",
+	"starcoder2:15b-instruct-v0.1-q6_K": "13GB",
+	"starcoder2:15b-instruct-v0.1-q8_0": "17GB",
+	"starcoder2:15b-instruct-v0.1-fp16": "32GB",
+	"tinydolphin:1.1b": "637MB",
+	"tinydolphin:v2.8": "637MB",
+	"tinydolphin:1.1b-v2.8-fp16": "2.2GB",
+	"tinydolphin:1.1b-v2.8-q2_K": "432MB",
+	"tinydolphin:1.1b-v2.8-q3_K_S": "499MB",
+	"tinydolphin:1.1b-v2.8-q3_K_M": "548MB",
+	"tinydolphin:1.1b-v2.8-q3_K_L": "592MB",
+	"tinydolphin:1.1b-v2.8-q4_0": "637MB",
+	"tinydolphin:1.1b-v2.8-q4_1": "701MB",
+	"tinydolphin:1.1b-v2.8-q4_K_S": "640MB",
+	"tinydolphin:1.1b-v2.8-q4_K_M": "668MB",
+	"tinydolphin:1.1b-v2.8-q5_0": "766MB",
+	"tinydolphin:1.1b-v2.8-q5_1": "831MB",
+	"tinydolphin:1.1b-v2.8-q5_K_S": "766MB",
+	"tinydolphin:1.1b-v2.8-q5_K_M": "782MB",
+	"tinydolphin:1.1b-v2.8-q6_K": "903MB",
+	"tinydolphin:1.1b-v2.8-q8_0": "1.2GB",
+	"tinyllama:1.1b": "638MB",
+	"tinyllama:chat": "638MB",
+	"tinyllama:v0.6": "638MB",
+	"tinyllama:v1": "638MB",
+	"tinyllama:1.1b-chat": "638MB",
+	"tinyllama:1.1b-chat-v0.6-q2_K": "483MB",
+	"tinyllama:1.1b-chat-v0.6-q3_K_S": "500MB",
+	"tinyllama:1.1b-chat-v0.6-q3_K_M": "551MB",
+	"tinyllama:1.1b-chat-v0.6-q3_K_L": "593MB",
+	"tinyllama:1.1b-chat-v0.6-q4_0": "638MB",
+	"tinyllama:1.1b-chat-v0.6-q4_1": "702MB",
+	"tinyllama:1.1b-chat-v0.6-q4_K_S": "644MB",
+	"tinyllama:1.1b-chat-v0.6-q4_K_M": "669MB",
+	"tinyllama:1.1b-chat-v0.6-q5_0": "767MB",
+	"tinyllama:1.1b-chat-v0.6-q5_1": "832MB",
+	"tinyllama:1.1b-chat-v0.6-q5_K_S": "767MB",
+	"tinyllama:1.1b-chat-v0.6-q5_K_M": "783MB",
+	"tinyllama:1.1b-chat-v0.6-q6_K": "904MB",
+	"tinyllama:1.1b-chat-v0.6-q8_0": "1.2GB",
+	"tinyllama:1.1b-chat-v1-fp16": "2.2GB",
+	"tinyllama:1.1b-chat-v1-q2_K": "483MB",
+	"tinyllama:1.1b-chat-v1-q3_K_S": "500MB",
+	"tinyllama:1.1b-chat-v1-q3_K_M": "551MB",
+	"tinyllama:1.1b-chat-v1-q3_K_L": "593MB",
+	"tinyllama:1.1b-chat-v1-q4_0": "638MB",
+	"tinyllama:1.1b-chat-v1-q4_1": "702MB",
+	"tinyllama:1.1b-chat-v1-q4_K_S": "644MB",
+	"tinyllama:1.1b-chat-v1-q4_K_M": "669MB",
+	"tinyllama:1.1b-chat-v1-q5_0": "767MB",
+	"tinyllama:1.1b-chat-v1-q5_1": "832MB",
+	"tinyllama:1.1b-chat-v1-q5_K_S": "767MB",
+	"tinyllama:1.1b-chat-v1-q5_K_M": "783MB",
+	"tinyllama:1.1b-chat-v1-q6_K": "904MB",
+	"tinyllama:1.1b-chat-v1-q8_0": "1.2GB",
+	"themanofrod/travel-agent": "1.7GB",
+	"wizard-vicuna-uncensored:7b": "3.8GB",
+	"wizard-vicuna-uncensored:13b": "7.4GB",
+	"wizard-vicuna-uncensored:30b": "18GB",
+	"wizard-vicuna-uncensored:7b-q8_0": "7.2GB",
+	"wizard-vicuna-uncensored:13b-q8_0": "14GB",
+	"wizard-vicuna-uncensored:30b-q6_K": "27GB",
+	"wizard-vicuna-uncensored:30b-q8_0": "35GB",
+	"wizard-vicuna-uncensored:7b-fp16": "13GB",
+	"wizard-vicuna-uncensored:13b-fp16": "26GB",
+	"wizard-vicuna-uncensored:30b-fp16": "65GB",
+	"wizardlm-uncensored:13b": "7.4GB",
+	"wizardlm-uncensored:13b-llama2": "7.4GB",
+	"wizardlm-uncensored:13b-llama2-q8_0": "14GB",
+	"wizardlm-uncensored:13b-llama2-fp16": "26GB",
+	"yi-coder:1.5b": "886MB",
+	"yi-coder:9b": "5.0GB",
+	"yi-coder:1.5b-base": "866MB",
+	"yi-coder:1.5b-chat": "866MB",
+	"yi-coder:9b-base": "5.0GB",
+	"yi-coder:9b-chat": "5.0GB",
+	"yi-coder:1.5b-base-q8_0": "1.6GB",
+	"yi-coder:1.5b-chat-q8_0": "1.6GB",
+	"yi-coder:9b-base-q6_K": "7.2GB",
+	"yi-coder:9b-chat-q6_K": "7.2GB",
+	"yi-coder:9b-base-q8_0": "9.4GB",
+	"yi-coder:9b-chat-q8_0": "9.4GB",
+	"yi-coder:1.5b-base-fp16": "3.0GB",
+	"yi-coder:1.5b-chat-fp16": "3.0GB",
+	"yi-coder:9b-base-fp16": "18GB",
+	"yi-coder:9b-chat-fp16": "18GB",
+}
+
+// oteodoro:  added section
+var whitelist = map[string]int{
+	"adens/quran-guide": 1,
+	"akx/viking-7b": 1,
+	"alfred": 1,
+	"ALIENTELLIGENCE/christiancounselor": 1,
+	"ALIENTELLIGENCE/crisisintervention": 1,
+	"ALIENTELLIGENCE/enriquecastillorincon": 1,
+	"ALIENTELLIGENCE/gamemasterroleplaying": 1,
+	"ALIENTELLIGENCE/holybible": 1,
+	"ALIENTELLIGENCE/mentalwellness": 1,
+	"ALIENTELLIGENCE/prayerline": 1,
+	"ALIENTELLIGENCE/pcarchitect": 1,
+	"ALIENTELLIGENCE/sarah": 1,
+	"ALIENTELLIGENCE/sarahv2": 1,
+	"ALIENTELLIGENCE/whiterabbit": 1,
+	"ALIENTELLIGENCE/whiterabbitv2": 1,
+	"all-minilm": 1,
+	"Artalius/lixi": 1,
+	"aya": 1,
+	"bakllava": 1,
+	"bespoke-minicheck": 1,
+	"bge-large": 1,
+	"bge-m3": 1,
+	"benevolentjoker/belial": 1,
+	"benevolentjoker/bethanygpt": 1,
+	"benevolentjoker/nsfwmonika": 1,
+	"benevolentjoker/nsfwvanessa": 1,
+	"benevolentjoker/satan": 1,
+	"canadiangamer/neena": 1,
+	"canadiangamer/priya": 1,
+	"captainkyd/whiterabbitneo7b": 1,
+	"chatgph/70b-instruct": 1,
+	"chatgph/gph-main": 1,
+	"chatgph/medix-ph": 1,
+	"codebooga": 1,
+	"codegeex4": 1,
+	"codegemma": 1,
+	"codellama": 1,
+	"codeqwen": 1,
+	"codestral": 1,
+	"codeup": 1,
+	"command-r": 1,
+	"command-r-plus": 1,
+	"dbrx": 1,
+	"disinfozone/telos": 1,
+	"deepseek-coder": 1,
+	"deepseek-coder-v2": 1,
+	"deepseek-llm": 1,
+	"deepseek-v2": 1,
+	"deepseek-v2.5": 1,
+	"dolphin-llama3": 1,
+	"dolphin-mistral": 1,
+	"dolphin-mixtral": 1,
+	"dolphin-phi": 1,
+	"dolphincoder": 1,
+	"duckdb-nsql": 1,
+	"eramax/aura_v3": 1,
+	"everythinglm": 1,
+	"falcon": 1,
+	"falcon2": 1,
+	"firefunction-v2": 1,
+	"goliath": 1,
+	"granite-code": 1,
+	"hermes3": 1,
+	"internlm2": 1,
+	"jimscard/adult-film-screenwriter-nsfw": 1,
+	"jimscard/whiterabbit-neo": 1,
+	"llama-guard3": 1,
+	"llama-pro": 1,
+	"llama2": 1,
+	"llama2-chinese": 1,
+	"llama2-uncensored": 1,
+	"llama3": 1,
+	"llama3-chatqa": 1,
+	"llama3-gradient": 1,
+	"llama3-groq-tool-use": 1,
+	"llama3.1": 1,
+	"llama3.2": 1,
+	"llava": 1,
+	"llava-llama3": 1,
+	"llava-phi3": 1,
+	"gemma": 1,
+	"gemma2": 1,
+	"glm4": 1,
+	"magicoder": 1,
+	"mannix/replete-adapted-llama3-8b": 1,
+	"mannix/replete-coder-llama3-8b": 1,
+	"mathstral": 1,
+	"meditron": 1,
+	"medllama2": 1,
+	"megadolphin": 1,
+	"minicpm-v": 1,
+	"mistral": 1,
+	"mistral-large": 1,
+	"mistral-nemo": 1,
+	"mistral-openorca": 1,
+	"mistral-small": 1,
+	"mistrallite": 1,
+	"mixtral": 1,
+	"moondream": 1,
+	"nqduc/gemsura": 1,
+	"nqduc/mixsura": 1,
+	"nqduc/mixsura-sft": 1,
+	"monotykamary/whiterabbitneo-v1.5a": 1,
+	"mxbai-embed-large": 1,
+	"nemotron": 1,
+	"nemotron-mini": 1,
+	"neural-chat": 1,
+	"nexusraven": 1,
+	"nomic-embed-text": 1,
+	"notus": 1,
+	"notux": 1,
+	"nous-hermes": 1,
+	"nous-hermes2": 1,
+	"nous-hermes2-mixtral": 1,
+	"nuextract": 1,
+	"open-orca-platypus2": 1,
+	"openchat": 1,
+	"openhermes": 1,
+	"orca-mini": 1,
+	"orca2": 1,
+	"paraphrase-multilingual": 1,
+	"partai/dorna-llama3": 1,
+	"phi": 1,
+	"phi3": 1,
+	"phi3.5": 1,
+	"phind-codellama": 1,
+	"qwen": 1,
+	"qwen2": 1,
+	"qwen2-math": 1,
+	"qwen2.5": 1,
+	"qwen2.5-coder": 1,
+	"reader-lm": 1,
+	"reefer/minimonica": 1,
+	"reefer/monica": 1,
+	"reflection": 1,
+	"rfc/whiterabbitneo": 1,
+	"rouge/replete-coder-qwen2-1.5b": 1,
+	"samantha-mistral": 1,
+	"savethedoctor/whiterabbitneo13bq8_0": 1,
+	"shieldgemma": 1,
+	"smollm": 1,
+	"snowflake-arctic-embed": 1,
+	"solar": 1,
+	"solar-pro": 1,
+	"sparksammy/samantha": 1,
+	"sparksammy/samantha-3.1": 1,
+	"sparksammy/samantha-eggplant": 1,
+	"sparksammy/samantha-v3-uncensored": 1,
+	"sparksammy/tinysam-goog": 1,
+	"sparksammy/tinysam-msft": 1,
+	"sqlcoder": 1,
+	"stable-beluga": 1,
+	"stable-code": 1,
+	"stablelm-zephyr": 1,
+	"stablelm2": 1,
+	"starcoder": 1,
+	"starcoder2": 1,
+	"starling-lm": 1,
+	"themanofrod/travel-agent": 1,
+	"tinydolphin": 1,
+	"tinyllama": 1,
+	"vicuna": 1,
+	"wizard-math": 1,
+	"wizard-vicuna": 1,
+	"wizard-vicuna-uncensored": 1,
+	"wizardcoder": 1,
+	"wizardlm": 1,
+	"wizardlm-uncensored": 1,
+	"wizardlm2": 1,
+	"xwinlm": 1,
+	"yarn-llama2": 1,
+	"yarn-mistral": 1,
+	"yi": 1,
+	"yi-coder": 1,
+	"zephyr": 1,
+}
+
+// oteodoro:  added --tags
+var tagsList = map[string]string{
+	"adens/quran-guide": "quran muslim islam allah",
+	"akx/viking-7b": "multilingual finnish english swedish danish norwegian icelandic coding code-generator",
+	"alfred": "chat comprehensive-response i-dont-know",
+	"ALIENTELLIGENCE/christiancounselor": "christian christianity protestant catholic eastern-orthodox western-church eastern-church theologist counselor philosopher spirituality mental-health marriage",
+	"ALIENTELLIGENCE/crisisintervention": "psychotherapist counselor mental-health male",
+	"ALIENTELLIGENCE/enriquecastillorincon": "ufo chat ufo-investigator",
+	"ALIENTELLIGENCE/gamemasterroleplaying": "game-master game-design storyteller quest-maker game-mechanics gaming-industry",
+	"ALIENTELLIGENCE/mentalwellness": "mental-wellness mindfulness emotional-support safe-space",
+	"ALIENTELLIGENCE/pcarchitect": "computer-technician pc-build build-computer",
+	"ALIENTELLIGENCE/prayerline": "jesus jesus-of-nazareth prayer-line christian",
+	"ALIENTELLIGENCE/sarah": "ai-girlfriend girlfriend emojis",
+	"ALIENTELLIGENCE/sarahv2": "ai-girlfriend girlfriend emojis",
+	"ALIENTELLIGENCE/whiterabbit": "computer-security how-to security-research open-source-tools vulnerability-checks",
+	"ALIENTELLIGENCE/whiterabbitv2": "computer-security how-to security-research open-source-tools vulnerability-checks",
+	"all-minilm": "embedding",
+	"Artalius/lixi": "writer developer companion code-optimization fun-facts idea-generator wordsmith cloud-developer coding coding-assistant computer-science anime manga erotica nsfw japanese-alignment japanese-pop-culture uncensored gamer gamer-girl ai-girlfriend girlfriend funny",
+	"aya": "multilingual arabic chinese czech dutch english french german greek hebrew hindi indonesian italian japanese korean persian polish portuguese romanian russian spanish turkish ukrainian vietnamese",
+	"bakllava": "image-deconstruction image-describe image-to-text image-summary",
+	"benevolentjoker/bethanygpt": "nsfw adult-content multiple-personalities",
+	"benevolentjoker/belial": "devil fiction dark-personality",
+	"benevolentjoker/nsfwmonika": "nsfw adult-content adult-fiction ai-girlfriend girlfriend",
+	"benevolentjoker/nsfwvanessa": "nsfw adult-content ai-girlfriend girlfriend",
+	"benevolentjoker/satan": "satan satanism devil occult qa religion",
+	"bespoke-minicheck": "fact-checking",
+	"canadiangamer/neena": "uncensored nsfw muscular adult-content",
+	"canadiangamer/priya": "ai-girlfriend girlfriend muscular india indian nsfw adult-content",
+	"bge-large": "embedding vector-database",
+	"bge-m3": "embedding multilingual low-memory-footprint",
+	"captainkyd/whiterabbitneo7b": "computer-security how-to security-research open-source-tools vulnerability-checks",
+	"chatgph/70b-instruct": "software-engineering system-optimization techonology filipino humor philippines pinoy coding code-review philippine-alignment tagalog cebuano illocano hiligayon cloud-developer",
+	"chatgph/gph-main": "software-engineering system-optimization technology filipino humor philippines pinoy tagalog illocano philippine-alignment",
+	"chatgph/medix-ph": "medical assistant healtcare philippines filipino",
+	"codebooga": "coding python",
+	"codegeex4": "coding code-generation code-completion",
+	"codegemma": "coding autocomplete coding-assistant fim fill-in-the-middle",
+	"codellama": "coding code-generation code-completion code-review unit-test-generator python fim fill-in-the-middle",
+	"codeqwen": "coding code-generation fixing-bugs",
+	"codestral": "coding code-generation solving-basic-programming-problems fim fill-in-the-middle unit-test-generator python",
+	"codeup": "coding code-generation",
+	"command-r": "rag tool-use english french spanish italian german brazilian portuguese japanese korean chinese arabic",
+	"command-r-plus": "rag tool-use enterprise english french spanish italian german brazilian portuguese japanese korean chinese arabic",
+	"dbrx": "coding code-generation math-word-problems general-purpose common-sense",
+	"deepseek-coder": "coding english chinese code-completion fim fill-in-the-middle python",
+	"deepseek-coder-v2": "coding code-completion code-insertion code-generator",
+	"deepseek-llm": "bilingual common-sense trivia chinese english general-knowledge",
+	"deepseek-v2": "bilinugual chinese english math-word-problems",
+	"deepseek-v2:236b": "bilinugual chinese english math-word-problems general-knowledge",
+	"deepseek-v2.5": "chat coding code-generator python",
+	"disinfozone/telos": "continental-philosophy philosophy conspiracy conspiracies creative-tasking funny wit witty",
+	"dolphin-llama3": "uncensored coding function-calling chat fine-tunable-alignment",
+	"dolphin-mistral": "uncensored coding function-calling chat fine-tunable-alignment",
+	"dolphin-mixtral": "uncensored coding chat function-calling fine-tunable-alignment game-design humor prank-suggestions confessions",
+	"dolphin-phi": "uncensored coding fine-tunable-alignment",
+	"dolphincoder": "uncensored coding coding-assistant",
+	"duckdb-nsql": "coding sql",
+	"eramax/aura_v3": "nsfw erotica roleplay",
+	"everythinglm": "uncensored detailed-replies story-telling",
+	"falcon": "llm-research",
+	"falcon2": "llm-research",
+	"firefunction-v2": "chat instruction-following function-calling parsing",
+	"goliath": "detailed-response roleplay detailed-roleplay",
+	"granite-code": "coding code-generation fixing-bugs documentation assistant fine-tunable",
+	"hermes3": "roleplaying abstract-reasoning common-sense function-calling structured-output assistant code-generation",
+	"internlm2": "tool-use word-math-problems",
+	"jimscard/adult-film-screenwriter-nsfw": "nsfw adult-content",
+	"jimscard/whiterabbit-neo": "computer-security how-to security-research open-source-tools vulnerability-checks",
+	"llama-guard3": "content-moderation",
+	"llama-pro": "coding math common-sense",
+	"llama2": "multilingual chat",
+	"llama2-chinese": "chinese chat chinese-alignment chinese-bias",
+	"llama2-uncensored": "chat llm-criticism llm-testing creative-writing humor research",
+	"llama3": "chat math-word-problems",
+	"llama3:text": "abstract-reasoning",
+	"llama3:70b-text": "abstract-reasoning general-knowledge",
+	"llama3:70b-instruct": "chat math-word-problems coding code-completion python general-knowledge typescript",
+	"llama3-chatqa": "chat rag qa answering-questions",
+	"llama3-gradient": "assistant",
+	"llama3-groq-tool-use": "function-calling tool-use",
+	"llama3.1": "multilingual chat translation summaries coding coding-assistant general-knowledge",
+	"llama3.2": "multilingual chat instruction-following summaries",
+	"llava": "ocr optical-character-recognition image-to-text chat chatbot",
+	"llava-llama3": "image-to-text",
+	"llava-phi3": "image-to-text",
+	"gemma": "text-generation qa summaries common-sense programming-tutor answering-questions",
+	"gemma2": "chat content-generation summaries grammar-correction language-tutor trivia multilingual",
+	"glm4": "math-word-problems coding multilingual",
+	"glm4:-chat": "math-word-problems coding chat function-calling comprehensive-response multilingual",
+	"magicoder": "coding code-generation open-source-coding",
+	"mannix/replete-adapted-llama3-8b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention low-end-hardware",
+	"mannix/replete-coder-llama3-8b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention",
+	"mathstral": "math-word-problems",
+	"meditron": "medical diseases health-information medical-exam qa",
+	"medllama2": "medical qa",
+	"megadolphin": "uncensored common-sense empathy advice detailed-reponse fine-tunable-alignment nsfw-content detailed-roleplay",
+	"minicpm-v": "text-to-speech ocr optical-character-recognition code-screenshot-bugfixes how-to-generator translating-screenshots translation",
+	"mistral": "multilingual function-calling fine-tuneable",
+	"mistral-large": "multilingual french german spanish italian dutch portuguese russian japanese chinese coding code-generation solving-basic-programming-problems math-word-problems function-calling json",
+	"mistral-nemo": "multilingual english french german spanish italian portuguese chinese korean arabic hindi common-sense trivia function-calling",
+	"mistral-openorca": "common-sense",
+	"mistral-small": "translation summaries",
+	"mistrallite": "answering-long-questions qa common-sense",
+	"mixtral": "multilingual english french italian german spanish coding code-generation common-sense solving-basic-programming-problems math-word-problems trivia fine-tuneable",
+	"moondream": "picture-to-text qa image-deconstruction whats-that identify-in-picture",
+	"monotykamary/whiterabbitneo-v1.5a": "computer-security how-to security-research open-source-tools vulnerability-checks",
+	"mxbai-embed-large": "embeddings",
+	"nemotron": "training-data-generator llm-creation",
+	"nemotron-mini": "roleplay rag qa function-calling",
+	"neural-chat": "chat chatbot common-sense",
+	"nexusraven": "coding documentation python functional-programming",
+	"nomic-embed-text": "embedding",
+	"notus": "common-sense chat",
+	"notux": "multilingual english spanish italian german french common-sense general-knowledge",
+	"nous-hermes": "general-use creative-text instruction-following",
+	"nous-hermes2": "science coding code-assistant code-generator",
+	"nous-hermes2-mixtral": "fantasy-poems text-to-code-visualization coding code-generator code-assistant",
+	"nqduc/gemsura": "vietnamese vietnam-alignment english text-generator qa summary classification translation coding code-generator reasoning",
+	"nqduc/mixsura": "vietnamese vietnam-alignment english text-generator qa summary classification translation coding code-generator reasoning",
+	"nqduc/mixsura-sft": "vietnamese vietnam-alignment english text-generator qa summary classification translation coding code-generator reasoning",
+	"nuextract": "structured-data-generation",
+	"open-orca-platypus2": "chat coding code-generation text-generation common-sense",
+	"openchat": "math-word-problems",
+	"openhermes": "chat cooking-recipes coding-by-example college-level-response",
+	"orca-mini": "general-purpose writing-letters",
+	"orca2": "assistant summaries abstract-reasoning",
+	"paraphrase-multilingual": "embedding",
+	"partai/dorna-llama3": "persian assistant",
+	"phi": "chat street-directions coding code-generator code-competion text-completion qa answering-questions",
+	"phi3": "common-sense trivia english math logic math-word-problems solving-basic-programming-problems",
+	"phi3.5": "coding math logic teacher fact-check chat multilingual arabic chinese czech danish dutch english finnish french german hebrew hungarian italian japanese korean norwegian polish portuguese russian spanish swedish thai turkish ukrainian",
+	"phind-codellama": "coding code-generation",
+	"phind-codellama:34b-python": "coding code-generation python",
+	"qwen": "china-alignment china-bias multilingual chat chinese english coding solving-basic-programming-problems",
+	"qwen2": "china-alignment china-bias multilingual german french spanish portuguese italian dutch russian czech polish arabic persian hebrew turkish japanese korean vietnamese thai indonesian malay lao burmese cebuano khmer tagalog hindi bengali urdu coding code-generation math-word-problems coding solving-basic-programming-problems math-word-problems stem science technology engineering mathematics",
+	"qwen2-math": "china-alignment china-bias math-word-problems stem science technology engineering mathematics",
+	"qwen2.5": "china-alignment china-bias multilingual chat roleplay coding parsing json math instruction-following chinese english french spanish portuguese german italian russian japanese korean vietnamese thai arabic",
+	"qwen2.5-coder": "china-alignment china-bias coding code-generation documentation fixing-bugs",
+	"reader-lm": "html-to-markdown",
+	"reefer/minimonica": "erotica assistant adult-content ai-girlfriend girlfriend chat",
+	"reefer/monica": "erotica assistant adult-content ai-girlfriend girlfriend appimage-creation app-questions computer-technician",
+	"reflection": "reasoning",
+	"rfc/whiterabbitneo": "computer-security how-to security-research open-source-tools vulnerability-checks",
+	"rouge/replete-coder-qwen2-1.5b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention mobile",
+	"samantha-mistral": "philosopher psychologist dating-coach",
+	"savethedoctor/whiterabbitneo13bq8_0": "computer-security how-to security-research open-source-tools vulnerability-checks",
+	"shieldgemma": "content-moderator",
+	"smollm": "common-sense qa low-memory-footprint parent",
+	"snowflake-arctic-embed": "embeddings",
+	"solar": "chat rag fine-tuneable",
+	"solar-pro": "common-sense math-word-problems fine-tuneable",
+	"sparksammy/samantha": "gay femboy nerdy boyfriend ai-boyfriend nerd assistant blogging coding resume",
+	"sparksammy/samantha-3.1": "gay femboy nerdy boyfriend ai-boyfriend texas-alignment american-alignment gender-pronouns",
+	"sparksammy/samantha-eggplant": "gay femboy nerdy gender-pronouns coding blogging texas-alignment american-alignment covid-era",
+	"sparksammy/samantha-v3-uncensored": "gay femboy nerdy uncensored boyfriend ai-boyfriend coding blogging texas-alignment american-alignment gender-pronouns",
+	"sparksammy/tinysam-goog": "gay femboy nerdy gender-pronouns coding blogging",
+	"sparksammy/tinysam-msft": "gay femboy nerdy uncensored boyfriend ai-boyfriend coding writer texas-alignment american-alignment gender-pronouns",
+	"sqlcoder": "coding code-generation sql",
+	"stable-beluga": "general-use",
+	"stable-code": "coding code-completion fim fill-in-the-middle fine-tunable",
+	"stablelm-zephyr": "chat qa instruction-following",
+	"stablelm2": "common-sense",
+	"starcoder": "coding code-generation",
+	"starcoder2": "coding code-generation",
+	"starling-lm": "chat chatbot roleplay writing humanities stem science technology engineering math reasoning structured-data-generation",
+	"themanofrod/travel-agent": "camping travel travel-guide outdoors",
+	"tinydolphin": "low-memory-footprint text-generation letter-writing poems",
+	"tinyllama": "game-dialog-generator low-memory-footprint",
+	"vicuna": "american-alignment american-bias chat assistant",
+	"wizard-math": "math logic",
+	"wizard-vicuna": "american-alignment american-bias",
+	"wizard-vicuna-uncensored": "removed-alignment removed-morals",
+	"wizardcoder": "coding code-generation",
+	"wizardcoder:python": "coding code-generation python",
+	"wizardlm": "general-use math-word-problems",
+	"wizardlm-uncensored": "uncensored removed-alignment removed-moralizing general-use math-word-problems",
+	"wizardlm2": "chat multilingual",
+	"wizardlm2:70b": "chat multilingual reasoning",
+	"xwinlm": "common-sense detailed-response",
+	"xwinlm:70b-v0.1": "common-sense abstract-reasoning wrinkled detailed-response",
+	"yarn-llama2": "text-generation",
+	"yarn-mistral": "common-sense",
+	"yi": "multilingual english chinese",
+	"yi-coder": "coding",
+	"zephyr": "assistant writing roleplay humanities stem science technology engineering math structured-data-generation",
+}
+
 func CreateHandler(cmd *cobra.Command, args []string) error {
 	filename, _ := cmd.Flags().GetString("file")
 	filename, err := filepath.Abs(filename)
@@ -382,6 +1660,25 @@ func StopHandler(cmd *cobra.Command, arg
 func RunHandler(cmd *cobra.Command, args []string) error {
 	interactive := true
 
+	if @UNRESTRICT@ == 1 {
+		//
+	} else {
+		name := args[0]
+		v, r := whitelist[name]
+		if r && v == 1 {
+			//
+		} else {
+			l := strings.Split(name, ":")
+			name := l[0]
+			v, r := whitelist[name]
+			if r && v == 1 {
+				//
+			} else {
+				return errors.New(name + " is blacklisted")
+			}
+		}
+	}
+
 	opts := runOptions{
 		Model:    args[0],
 		WordWrap: os.Getenv("TERM") == "xterm-256color",
@@ -711,9 +2008,11 @@ func ShowHandler(cmd *cobra.Command, arg
 	modelfile, errModelfile := cmd.Flags().GetBool("modelfile")
 	parameters, errParams := cmd.Flags().GetBool("parameters")
 	system, errSystem := cmd.Flags().GetBool("system")
+	tags, errTags := cmd.Flags().GetBool("tags")
 	template, errTemplate := cmd.Flags().GetBool("template")
+	website, errWebsite := cmd.Flags().GetBool("website")
 
-	for _, boolErr := range []error{errLicense, errModelfile, errParams, errSystem, errTemplate} {
+	for _, boolErr := range []error{errLicense, errModelfile, errParams, errSystem, errTags, errTemplate, errWebsite} {
 		if boolErr != nil {
 			return errors.New("error retrieving flags")
 		}
@@ -742,13 +2041,253 @@ func ShowHandler(cmd *cobra.Command, arg
 		showType = "system"
 	}
 
+	if tags {
+		flagsSet++
+		showType = "tags"
+	}
+
 	if template {
 		flagsSet++
 		showType = "template"
 	}
 
+	if website {
+		flagsSet++
+		showType = "website"
+	}
+
 	if flagsSet > 1 {
-		return errors.New("only one of '--license', '--modelfile', '--parameters', '--system', or '--template' can be specified")
+		return errors.New("only one of '--license', '--modelfile', '--parameters', '--system', '--tags', '--template', or '--website' can be specified")
+	}
+
+	// oteodoro:  added section
+	licenses := map[string]string {
+		"adens/quran-guide": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"akx/viking-7b": "Apache-2.0",
+		"alfred": "Apache-2.0",
+		"ALIENTELLIGENCE/christiancounselor": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/crisisintervention": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/enriquecastillorincon": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/gamemasterroleplaying": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/holybible": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/mentalwellness": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/pcarchitect": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/prayerline": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/sarah": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"ALIENTELLIGENCE/sarahv2": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/whiterabbit": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"ALIENTELLIGENCE/whiterabbitv2": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"all-minilm": "Apache-2.0",
+		"Artalius/lixi": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"aya": "CC-BY-NC-4.0, Cohere For AI Acceptable Use Policy",
+		"bakllava": "Apache-2.0",
+		"bespoke-minicheck": "CC-BY-NC-4.0",
+		"bge-large": "MIT",
+		"bge-m3": "MIT",
+		"benevolentjoker/belial": "benevolentjoker's Use Agreement",
+		"benevolentjoker/bethanygpt": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy, benevolentjoker's Use Agreement",
+		"benevolentjoker/nsfwmonika": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"benevolentjoker/nsfwvanessa": "",
+		"benevolentjoker/satan": "",
+		"canadiangamer/neena": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"canadiangamer/priya": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"captainkyd/whiterabbitneo7b": "DEEPSEEK-LICENSE-AGREEMENT-1.0, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"chatgph/70b-instruct": "Apache-2.0",
+		"chatgph/gph-main": "",
+		"chatgph/medix-ph": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"codebooga": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"codegeex4": "glm-4-9b-LICENSE",
+		"codegemma": "Gemma Terms of Use 20240221",
+		"codellama": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama Code Acceptable Use Policy",
+		"codeqwen": "Tongyi Qianwen LICENSE AGREEMENT",
+		"codestral": "MNPL-0.1",
+		"codeup": "CreativeML Open RAIL++-M License",
+		"command-r": "CC-BY-NC-4.0",
+		"command-r-plus": "CC-BY-NC-4.0",
+		"dbrx": "Databricks Open Model License, Databricks Open Model Acceptable Use Policy",
+		"deepseek-coder": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-coder-v2": "MIT DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-llm": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-v2": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-v2.5": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"disinfozone/telos": "",
+		"dolphin-llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"dolphin-mistral": "Apache-2.0",
+		"dolphin-mixtral": "Apache-2.0",
+		"dolphin-phi": "MICROSOFT RESEARCH LICENSE TERMS",
+		"dolphincoder": "BigCode Open RAIL-M v1 License Agreement",
+		"duckdb-nsql": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"eramax/aura_v3": "Apache-2.0",
+		"everythinglm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"falcon": "Apache-2.0",
+		"falcon2": "Falcon 2 11B TII License 1.0",
+		"firefunction-v2": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"goliath": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"granite-code": "Apache-2.0",
+		"hermes3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"internlm2": "Apache-2.0",
+		"jimscard/adult-film-screenwriter-nsfw": "Apache-2.0",
+		"jimscard/whiterabbit-neo": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"llama-guard3": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama-pro": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama2": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama2-chinese": "Apache-2.0",
+		"llama2-uncensored": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-chatqa": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-gradient": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-groq-tool-use": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3.1": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama3.2": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"llava": "Apache-2.0",
+		"llava-llama3": "",
+		"llava-phi3": "",
+		"gemma": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"gemma2": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"glm4": "The glm-4-9b License",
+		"magicoder": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"mannix/replete-adapted-llama3-8b": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"mannix/replete-coder-llama3-8b": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"mathstral": "Apache-2.0",
+		"meditron": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"medllama2": "MIT",
+		"megadolphin": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"minicpm-v": "Apache-2.0",
+		"mistral": "Apache-2.0",
+		"mistral-large": "MRL-0.1",
+		"mistral-nemo": "Apache-2.0",
+		"mistral-openorca": "Apache-2.0",
+		"mistral-small": "MRL-0.1",
+		"mistrallite": "Apache-2.0",
+		"mixtral": "Apache-2.0",
+		"moondream": "Apache-2.0",
+		"monotykamary/whiterabbitneo-v1.5a": "DEEPSEEK-LICENSE-AGREEMENT-1.0, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"mxbai-embed-large": "Apache-2.0",
+		"nemotron": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy, Meta Privacy Policy",
+		"nemotron-mini": "NVIDIA AI Foundation Models Community License Agreement",
+		"neural-chat": "Apache-2.0",
+		"nexusraven": "NexusRaven-V2-13B-LICENSE",
+		"nomic-embed-text": "Apache-2.0",
+		"notus": "MIT",
+		"notux": "MIT",
+		"nous-hermes": "MIT, GPL-2+",
+		"nous-hermes:7b": "MIT",
+		"nous-hermes:13b": "GPL-2+",
+		"nous-hermes:13b-llama2": "MIT",
+		"nous-hermes2": "Apache-2.0",
+		"nous-hermes2-mixtral": "Apache-2.0",
+		"nuextract": "MIT", // Ollama site says Apache-2.0.  HuggingFace site says MIT.
+		"open-orca-platypus2": "CC-BY-NC-4.0",
+		"openchat": "Apache-2.0",
+		"openhermes": "Apache-2.0",
+		"orca-mini": "CC-BY-NC-SA-4.0",
+		"orca2": "MICROSOFT RESEARCH LICENSE TERMS",
+		"paraphrase-multilingual": "Apache-2.0",
+		"partai/dorna-llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"phi": "MIT",
+		"phi3": "MIT",
+		"phi3.5": "MIT",
+		"phind-codellama": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"qwen:0.5b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:1.8b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:4b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:7b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:14b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:32b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:110b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen2": "Apache-2.0",
+		"qwen2:72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen2-math": "Apache-2.0",
+		"qwen2.5": "Apache-2.0",
+		"qwen2.5-coder": "Apache-2.0",
+		"reader-lm": "CC-BY-NC-4.0",
+		"reefer/minimonica": "",
+		"reefer/monica": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"reflection": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"rfc/whiterabbitneo": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"rouge/replete-coder-qwen2-1.5b": "Apache-2.0",
+		"samantha-mistral": "Apache-2.0",
+		"savethedoctor/whiterabbitneo13bq8_0": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"shieldgemma": "Gemma Terms of Use 20240401",
+		"smollm": "Apache-2.0",
+		"snowflake-arctic-embed": "Apache-2.0",
+		"solar": "Apache-2.0",
+		"solar:instruct": "CC-BY-NC-4.0",
+		"solar-pro": "MIT",
+		"sparksammy/samantha": "Apache-2.0, LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"sparksammy/samantha-3.1": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"sparksammy/samantha-eggplant": "Apache-2.0, STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT, MICROSOFT RESEARCH LICENSE TERMS, SPL-R5-SR1",
+		"sparksammy/samantha-v3-uncensored": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"sparksammy/tinysam-msft": "MIT",
+		"sparksammy/tinysam-goog": "Gemma Terms of Use 20240221",
+		"sqlcoder": "CC-BY-SA-4.0",
+		"stable-beluga": "STABLE BELUGA NON-COMMERCIAL COMMUNITY LICENSE AGREEMENT",
+		"stable-code": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"stablelm-zephyr": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"stablelm2": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"starcoder": "BigCode Open RAIL-M v1 License Agreement",
+		"starcoder2": "BigCode Open RAIL-M v1 License Agreement",
+		"starling-lm": "Apache-2.0",
+		"themanofrod/travel-agent": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"tinydolphin": "Apache-2.0",
+		"tinyllama": "Apache-2.0",
+		"vicuna": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizard-math": "MICROSOFT RESEARCH LICENSE TERMS",
+		"wizard-vicuna": "",
+		"wizard-vicuna-uncensored": "",
+		"wizardcoder:33b": "MICROSOFT RESEARCH LICENSE TERMS",
+		"wizardcoder:python": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm-uncensored": "",
+		"wizardlm-uncensored:13b-llama2": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm2": "Apache-2.0",
+		"xwinlm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"yarn-llama2": "",
+		"yarn-mistral": "Apache-2.0",
+		"yi": "Apache-2.0",
+		"yi-coder": "Apache-2.0",
+		"zephyr": "MIT",
+	}
+
+	// oteodoro:  modified --license with correction or missing info
+	name := args[0]
+	l, r1 := licenses[name]
+	if r1 && flagsSet == 1 && showType == "license" {
+		fmt.Println("Model license:  " + l)
+		return nil
+	} else {
+		l1 := strings.Split(name, ":")
+		name := l1[0]
+		l2, r2 := licenses[name]
+		if r2 && flagsSet == 1 && showType == "license" {
+			fmt.Println("Model license:  " + l2)
+			return nil
+		}
+	}
+
+	// oteodoro:  added --website
+	if r1 && flagsSet == 1 && showType == "website" {
+		program := "xdg-open"
+		arg0 := "https://ollama.com/library/" + name
+		cmd := exec.Command(program, arg0)
+		_ = cmd.Run()
+		return nil
+	}
+
+	name = args[0]
+	l, r := tagsList[name]
+	if r && flagsSet == 1 && showType == "tags" {
+		fmt.Printf("Tags, capabilities, personality: %s\n", l)
+		return nil
+	} else if flagsSet == 1 && showType == "tags" {
+		l1 := strings.Split(name, ":")
+		name := l1[0]
+		l2, r := tagsList[name]
+		if r {
+			fmt.Printf("Tags, capabilities, personality: %s\n", l2)
+			return nil
+		}
 	}
 
 	req := api.ShowRequest{Name: args[0]}
@@ -927,6 +2466,138 @@ func PullHandler(cmd *cobra.Command, arg
 	return nil
 }
 
+//oteodoro:  added function
+func AvailHandler(cmd *cobra.Command, args []string) error {
+	for key, value := range whitelist {
+		if value == 1 {
+			fmt.Printf("%s\n", key)
+		}
+	}
+	return nil
+}
+
+//oteodoro:  added struct
+type FindModelSizeResult struct {
+	Name string
+	MbSize int
+	RawSize string
+}
+
+//oteodoro:  added struct
+type FindKeywordsResult struct {
+	Name string
+	Tags string
+}
+
+type FindModelSizeResults []*FindModelSizeResult
+type FindKeywordsResults []*FindKeywordsResult
+func (results FindModelSizeResults) Len() int { return len(results) }
+func (results FindKeywordsResults) Len() int { return len(results) }
+func (results FindModelSizeResults) Swap(i, j int) { results[i], results[j] = results[j], results[i] }
+func (results FindKeywordsResults) Swap(i, j int) { results[i], results[j] = results[j], results[i] }
+type ByModelSize struct { FindModelSizeResults }
+type ByName struct{ FindKeywordsResults }
+func (s ByModelSize) Less(i, j int) bool { return s.FindModelSizeResults[i].MbSize < s.FindModelSizeResults[j].MbSize }
+func (s ByName) Less(i, j int) bool { return s.FindKeywordsResults[i].Name < s.FindKeywordsResults[j].Name }
+
+//oteodoro:  added function
+func FindSizeHandler(cmd *cobra.Command, args []string) error {
+	requestedSizeRaw := args[0]
+	requestedSize := 0 // As in MB in base 10
+	re := regexp.MustCompile("[0-9.]+")
+	s := re.FindAllString(requestedSizeRaw, -1)
+	if s != nil {
+		_requestedSize, err := strconv.ParseFloat(s[0], 64)
+		if err != nil {
+			return errors.New("You need to add the memory size in GB or MB for the preferred size.  Examples:  4GB, 500MB")
+		}
+		if strings.Contains(requestedSizeRaw, "GB") {
+			requestedSize = int(_requestedSize * 1000)
+		} else if strings.Contains(requestedSizeRaw, "MB") {
+			requestedSize = int(_requestedSize)
+		} else {
+			return errors.New("You need to add GB or MB to your number.  Examples:  4GB, 500MB")
+		}
+	} else {
+		return errors.New("You need to add a number as an arg.  Examples:  4GB, 500MB")
+	}
+
+	var results []*FindModelSizeResult
+	for key, valueRaw := range sizeTable {
+		s = re.FindAllString(valueRaw, -1)
+		value := 0
+		_value := 0.0
+		if s != nil {
+			__value, err := strconv.ParseFloat(s[0], 64)
+			if err != nil {
+				return err
+			}
+			_value = __value
+		} else {
+			return errors.New("QA:  You need to add a number as an arg to " + key)
+		}
+
+		if strings.Contains(valueRaw, "GB") {
+			value = int(_value * 1000)
+		} else if strings.Contains(valueRaw, "MB") {
+			value = int(_value)
+		}
+		if value <= requestedSize {
+			result := &FindModelSizeResult{key, value, valueRaw}
+			results = append(results, result)
+		}
+	}
+	sort.Sort(ByModelSize{results})
+	printModelSizeResults(results)
+	if len(results) != 0 {
+		fmt.Println()
+		fmt.Printf("About compressed floats (aka f16), or int4 (aka q4) compression....\n")
+		fmt.Printf("f16 support should only be used on f16 native hardware.\n")
+		fmt.Printf("Ollama uses q4 quantization by default if without q suffix.\n")
+	}
+	return nil
+}
+
+//oteodoro:  added function
+func printModelSizeResults(results []*FindModelSizeResult) {
+	for _, result := range results {
+		fmt.Printf("%s %s\n", result.RawSize, result.Name)
+	}
+}
+
+//oteodoro:  added function
+func FindKeywordsHandler(cmd *cobra.Command, args []string) error {
+	if len(args) == 0 {
+		return errors.New("Add space delimited keywords as args")
+	}
+	var results []*FindKeywordsResult
+	for name, tags := range tagsList {
+		found := false
+
+		for _, userKeywords := range args {
+			if strings.Contains(tags, userKeywords) {
+				found = true
+				break
+			}
+		}
+
+		if found {
+			result := &FindKeywordsResult{name, tags}
+			results = append(results, result)
+		}
+	}
+	sort.Sort(ByName{results})
+	printKeywordsResults(results)
+	return nil
+}
+
+//oteodoro:  added function
+func printKeywordsResults(results []*FindKeywordsResult) {
+	for _, result := range results {
+		fmt.Printf("%s :  %s\n", result.Name, result.Tags)
+	}
+}
+
 type generateContextKey string
 
 type runOptions struct {
@@ -1332,6 +2991,8 @@ func NewCLI() *cobra.Command {
 	showCmd.Flags().Bool("parameters", false, "Show parameters of a model")
 	showCmd.Flags().Bool("template", false, "Show template of a model")
 	showCmd.Flags().Bool("system", false, "Show system message of a model")
+	showCmd.Flags().Bool("tags", false, "Show tags, capabilities, or personality of a model")
+	showCmd.Flags().Bool("website", false, "Show website entry of a model")
 
 	runCmd := &cobra.Command{
 		Use:     "run MODEL [PROMPT]",
@@ -1414,6 +3075,30 @@ func NewCLI() *cobra.Command {
 		RunE:    DeleteHandler,
 	}
 
+	availCmd := &cobra.Command{
+		Use:     "avail",
+		Short:   "List available models to download",
+		Aliases: []string{"a"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    AvailHandler,
+	}
+	findSizeCmd := &cobra.Command{
+		Use:     "find-size",
+		Short:   "Find compatible size models to download",
+		Args:    cobra.MinimumNArgs(1),
+		Aliases: []string{"fs"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    FindSizeHandler,
+	}
+	findKeywordsCmd := &cobra.Command{
+		Use:     "find-keywords",
+		Short:   "Find model by keywords",
+		Args:    cobra.MinimumNArgs(1),
+		Aliases: []string{"fs"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    FindKeywordsHandler,
+	}
+
 	envVars := envconfig.AsMap()
 
 	envs := []envconfig.EnvVar{envVars["OLLAMA_HOST"]}
@@ -1430,6 +3115,9 @@ func NewCLI() *cobra.Command {
 		copyCmd,
 		deleteCmd,
 		serveCmd,
+		availCmd,
+		findSizeCmd,
+		findKeywordsCmd,
 	} {
 		switch cmd {
 		case runCmd:
@@ -1469,6 +3157,9 @@ func NewCLI() *cobra.Command {
 		psCmd,
 		copyCmd,
 		deleteCmd,
+		availCmd,
+		findSizeCmd,
+		findKeywordsCmd,
 	)
 
 	return rootCmd
