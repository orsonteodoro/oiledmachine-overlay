--- ollama-0.11.4.orig/cmd/cmd.go	2025-08-07 14:23:55.000000000 -0700
+++ ollama-0.11.4/cmd/cmd.go	2025-08-10 20:14:58.187458145 -0700
@@ -15,8 +15,10 @@ import (
 	"net"
 	"net/http"
 	"os"
+	"os/exec" // oteodoro:  added line
 	"os/signal"
 	"path/filepath"
+	"regexp" // oteodoro:  added line
 	"runtime"
 	"slices"
 	"sort"
@@ -86,6 +88,2350 @@ func getModelfileName(cmd *cobra.Command
 	return absName, nil
 }
 
+var sizeTable = map[string]string{
+	// Quality control notes:
+	// q6*, q5* for round downs for 16MB, 32MB, 64MB, 128MB, 256MB, 512MB, 1GB, 2GB, 4GB, 8GB, 16GB, 32GB, 64GB, 128GB, 256GB, 512GB boundary
+	// fp16, q8_0 for max AGI
+	// q4_0 is balanced but preference for speed over AGI (default)
+	// For security based LLMs where quality is important >= q5
+
+	// Generally the following are listed
+	// 1. The general facade flavors.
+	// 2. The uncompressed full version (f16).
+	// 3. The compressed full version (q8_0).
+	// 4. The memory aligned versions (from round downs above) that are >= q4 and above and below the memory boundaries.
+	// 5. Interesting tagged variations if fingerprint is different.
+
+	"adens/quran-guide": "2.0GB",
+	"akx/viking-7b": "4.6GB",
+	"agcobra/liberated-qwen1.5-72b": "44GB",
+	"alfred:40b": "24GB",
+	"alfred:40b-1023-q5_0": "29GB",
+	"alfred:40b-1023-q5_1": "32GB",
+	"alfred:40b-1023-q8_0": "44GB",
+	"ALIENTELLIGENCE/christiancounselor": "4.7GB",
+	"ALIENTELLIGENCE/crisisintervention": "4.7GB",
+	"ALIENTELLIGENCE/doomsdayurvivalist": "4.7GB",
+	"ALIENTELLIGENCE/enriquecastillorincon": "4.7GB",
+	"ALIENTELLIGENCE/gamemasterroleplaying": "4.7GB",
+	"ALIENTELLIGENCE/holybible": "4.7GB",
+	"ALIENTELLIGENCE/mentalwellness": "4.7GB",
+	"ALIENTELLIGENCE/pcarchitect": "4.7GB",
+	"ALIENTELLIGENCE/prayerline": "4.7GB",
+	"ALIENTELLIGENCE/sarah": "4.7GB",
+	"ALIENTELLIGENCE/sarahv2": "4.7GB",
+	"ALIENTELLIGENCE/whiterabbit": "4.7GB",
+	"ALIENTELLIGENCE/whiterabbitv2": "4.7GB",
+	"all-minilm:22m": "46MB",
+	"all-minilm:33m": "67MB",
+	"all-minilm:l12": "67MB",
+	"all-minilm:l12-v2": "67MB",
+	"all-minilm:l6": "46MB",
+	"all-minilm:l6-v2": "46MB",
+	"all-minilm:v2": "46MB",
+	"all-minilm:22m-l6-v2-fp16": "46MB",
+	"all-minilm:33m-l12-v2-fp16": "67MB",
+	"Artalius/lixi": "2.0GB",
+	"artifish/mlewd-v2.4": "7.9GB",
+	"athene-v2": "72GB",
+	"aya:8b": "4.8GB",
+	"aya:35b": "20GB",
+	"aya:8b-23": "4.8GB",
+	"aya:35b-23": "20GB",
+	"aya:8b-23-q6_K": "6.6GB",
+	"aya:8b-23-q8_0": "8.5GB",
+	"aya:35b-23-q6_K": "29GB",
+	"aya:35b-23-q8_0": "37GB",
+	"aya-expanse:8b": "5.1GB",
+	"aya-expanse:32b": "20GB",
+	"aya-expanse:8b-fp16": "16GB",
+	"aya-expanse:32b-fp16": "65GB",
+	"aya-expanse:8b-q6_K": "6.6GB",
+	"aya-expanse:8b-q8_0": "8.5GB",
+	"aya-expanse:32b-q6_K": "27GB",
+	"aya-expanse:32b-q8_0": "34GB",
+	"bakllava:7b": "4.7GB",
+	"bakllava:7b-v1-q6_K": "6.6GB",
+	"bakllava:7b-v1-q8_0": "8.3GB",
+	"bakllava:7b-v1-fp16": "15GB",
+	"bge-large:335m": "671MB",
+	"bge-large:335m-en-v1.5-fp16": "671MB",
+	"bge-m3:567m": "1.2GB",
+	"bge-m3:567m-fp16": "1.2GB",
+	"benevolentjoker/belial": "4.9GB",
+	"benevolentjoker/bethanygpt": "4.7GB",
+	"benevolentjoker/nsfwmonika": "4.7GB",
+	"benevolentjoker/nsfwvanessa": "4.9GB",
+	"benevolentjoker/satan": "4.9GB",
+	"bespoke-minicheck:7b": "4.7GB",
+	"bespoke-minicheck:7b-q6_K": "6.4GB",
+	"bespoke-minicheck:7b-q8_0": "8.2GB",
+	"bespoke-minicheck:7b-fp16": "15GB",
+	"canadiangamer/neena": "3.8GB",
+	"canadiangamer/priya": "3.8GB",
+	"captainkyd/whiterabbitneo7b": "7.2GB",
+	"chatgph/70b-instruct": "53GB",
+	"chatgph/gph-main": "5.5GB",
+	"chatgph/medix-ph": "3.8GB",
+	"codebooga:34b": "19GB",
+	"codebooga:34b-v0.1-q6_K": "28GB",
+	"codebooga:34b-v0.1-q8_0": "36GB",
+	"codebooga:34b-v0.1-fp16": "67GB",
+	"codegeex4:9b": "5.5GB",
+	"codegeex4:9b-all-q5_1": "7.1GB",
+	"codegeex4:9b-all-q6_K": "8.3GB",
+	"codegeex4:9b-all-q8_0": "10.0GB",
+	"codegeex4:9b-all-fp16": "19GB",
+	"codegemma:2b": "1.6GB",
+	"codegemma:7b": "5.0GB",
+	"codegemma:code": "1.6GB",
+	"codegemma:instruct": "5.0GB",
+	"codegemma:2b-code": "1.6GB",
+	"codegemma:2b-v1.1": "1.6GB",
+	"codegemma:7b-code": "5.0GB",
+	"codegemma:7b-instruct": "5.0GB",
+	"codegemma:7b-v1.1": "5.0GB",
+	"codegemma:2b-code-q8_0": "2.7GB",
+	"codegemma:2b-code-v1.1-q8_0": "2.7GB",
+	"codegemma:7b-code-q6_K": "7.0GB",
+	"codegemma:7b-instruct-q6_K": "7.0GB",
+	"codegemma:7b-instruct-v1.1-q6_K": "7.0GB",
+	"codegemma:7b-code-q8_0": "9.1GB",
+	"codegemma:7b-instruct-q8_0": "9.1GB",
+	"codegemma:7b-instruct-v1.1-q8_0": "9.1GB",
+	"codegemma:2b-code-fp16": "5.0GB",
+	"codegemma:2b-code-v1.1-fp16": "5.0GB",
+	"codegemma:7b-code-fp16": "17GB",
+	"codegemma:7b-instruct-fp16": "17GB",
+	"codegemma:7b-instruct-v1.1-fp16": "17GB",
+	"codellama:7b": "3.8GB",
+	"codellama:13b": "7.4GB",
+	"codellama:34b": "19GB",
+	"codellama:70b": "39GB",
+	"codellama:code": "3.8GB",
+	"codellama:instruct": "3.8GB",
+	"codellama:python": "3.8GB",
+	"codellama:7b-code": "3.8GB",
+	"codellama:7b-instruct": "3.8GB",
+	"codellama:7b-python": "3.8GB",
+	"codellama:13b-code": "7.4GB",
+	"codellama:13b-instruct": "7.4GB",
+	"codellama:13b-python": "7.4GB",
+	"codellama:34b-code": "19GB",
+	"codellama:34b-instruct": "19GB",
+	"codellama:34b-python": "19GB",
+	"codellama:70b-code": "39GB",
+	"codellama:70b-instruct": "39GB",
+	"codellama:70b-python": "39GB",
+	"codellama:7b-code-q8_0": "7.2GB",
+	"codellama:7b-instruct-q8_0": "7.2GB",
+	"codellama:7b-python-q8_0": "7.2GB",
+	"codellama:13b-code-q8_0": "14GB",
+	"codellama:13b-instruct-q8_0": "14GB",
+	"codellama:13b-python-q8_0": "14GB",
+	"codellama:34b-instruct-q6_K": "28GB",
+	"codellama:34b-python-q6_K": "28GB",
+	"codellama:34b-instruct-q8_0": "36GB",
+	"codellama:34b-python-q8_0": "36GB",
+	"codellama:70b-code-q8_0": "73GB",
+	"codellama:70b-instruct-q8_0": "73GB",
+	"codellama:70b-python-q8_0": "73GB",
+	"codellama:7b-code-fp16": "13GB",
+	"codellama:7b-instruct-fp16": "13GB",
+	"codellama:7b-python-fp16": "13GB",
+	"codellama:13b-code-fp16": "26GB",
+	"codellama:13b-instruct-fp16": "26GB",
+	"codellama:13b-python-fp16": "26GB",
+	"codellama:34b-instruct-fp16": "67GB",
+	"codellama:34b-python-fp16": "67GB",
+	"codellama:70b-code-fp16": "138GB",
+	"codellama:70b-instruct-fp16": "138GB",
+	"codellama:70b-python-fp16": "138GB",
+	"codeqwen:7b": "4.2GB",
+	"codeqwen:chat": "4.2GB",
+	"codeqwen:code": "4.2GB",
+	"codeqwen:v1.5": "4.2GB",
+	"codeqwen:v1.5-chat": "4.2GB",
+	"codeqwen:v1.5-code": "4.2GB",
+	"codeqwen:7b-chat": "4.2GB",
+	"codeqwen:7b-code": "4.2GB",
+	"codeqwen:7b-chat-v1.5-q8_0": "7.7GB",
+	"codeqwen:7b-code-v1.5-q8_0": "7.7GB",
+	"codeqwen:7b-chat-v1.5-fp16": "15GB",
+	"codeqwen:7b-code-v1.5-fp16": "15GB",
+	"codestral:22b": "13GB",
+	"codestral:v0.1": "13GB",
+	"codestral:22b-v0.1-q5_0": "15GB",
+	"codestral:22b-v0.1-q5_K_M": "16GB",
+	"codestral:22b-v0.1-q8_0": "24GB",
+	"codeup:13b": "7.4GB",
+	"codeup:13b-llama2": "7.4GB",
+	"codeup:13b-llama2-chat": "7.4GB",
+	"codeup:13b-llama2-chat-q8_0": "14GB",
+	"codeup:13b-llama2-chat-fp16": "26GB",
+	"command-a:111b": "67GB",
+	"command-a:111b-03-2025-fp16": "222GB",
+	"command-a:111b-03-2025-q8_0": "118GB",
+	"command-r:35b": "19GB",
+	"command-r:35b-08-2024-q6_K": "27GB",
+	"command-r:35b-v0.1-q6_K": "29GB",
+	"command-r:35b-08-2024-q8_0": "34GB",
+	"command-r:35b-v0.1-q8_0": "37GB",
+	"command-r:35b-08-2024-fp16": "65GB",
+	"command-r:35b-v0.1-fp16": "70GB",
+	"command-r:v0.1": "20GB",
+	"command-r-plus:104b": "59GB",
+	"command-r-plus:104b-08-2024-q8_0": "110GB",
+	"command-r-plus:104b-08-2024-fp16": "208GB",
+	"command-r7b:7b": "5.1GB",
+	"command-r7b:7b-12-2024-fp16": "16GB",
+	"command-r7b:7b-12-2024-q8_0": "8.5GB",
+	"command-r7b-arabic:7b": "5.1GB",
+	"command-r7b-arabic:7b-02-2025-fp16": "16GB",
+	"command-r7b-arabic:7b-02-2025-q8_0": "8.5GB",
+	"dbrx:132b": "74GB",
+	"dbrx:instruct": "74GB",
+	"dbrx:132b-instruct-q8_0": "140GB",
+	"dbrx:132b-instruct-fp16": "263GB",
+	"deepcoder:1.5b": "1.1GB",
+	"deepcoder:14b": "9.0GB",
+	"deepcoder:1.5b-preview-fp16": "3.6GB",
+	"deepcoder:1.5b-preview-q8_0": "1.9GB",
+	"deepcoder:14b-preview-fp16": "30GB",
+	"deepcoder:14b-preview-q8_0": "16GB",
+	"deepscaler:1.5b": "3.6GB",
+	"deepscaler:1.5b-preview-fp16b": "3.5GB",
+	"deepscaler:1.5b-preview-q4_K_Mb": "1.1GB",
+	"deepscaler:1.5b-preview-q8_0b": "1.9GB",
+	"deepseek-coder-v2:16b": "8.9GB",
+	"deepseek-coder-v2:236b": "133GB",
+	"deepseek-coder-v2:lite": "8.9GB",
+	"deepseek-coder-v2:16b-lite-base-q8_0": "17GB",
+	"deepseek-coder-v2:16b-lite-instruct-q8_0": "17GB",
+	"deepseek-coder-v2:236b-lite-base-q8_0": "251GB",
+	"deepseek-coder-v2:236b-lite-instruct-q8_0": "251GB",
+	"deepseek-coder-v2:16b-lite-base-fp16": "31GB",
+	"deepseek-coder-v2:16b-lite-instruct-fp16": "31GB",
+	"deepseek-coder-v2:236b-lite-base-fp16": "472GB",
+	"deepseek-coder-v2:236b-lite-instruct-fp16": "472GB",
+	"deepseek-llm:7b": "4.0GB",
+	"deepseek-llm:67b": "38GB",
+	"deepseek-llm:7b-base": "4.0GB",
+	"deepseek-llm:7b-chat": "4.0GB",
+	"deepseek-llm:67b-base": "38GB",
+	"deepseek-llm:67b-chat": "38GB",
+	"deepseek-llm:7b-base-q6_k": "5.7GB",
+	"deepseek-llm:7b-chat-q6_k": "5.7GB",
+	"deepseek-llm:67b-base-q6_k": "55GB",
+	//"deepseek-llm:67b-chat-q6_k": "55GB",
+	"deepseek-llm:7b-base-q8_0": "7.3GB",
+	"deepseek-llm:7b-chat-q8_0": "7.3GB",
+	"deepseek-llm:67b-base-q8_0": "72GB",
+	//"deepseek-llm:67b-chat-q8_0": "72GB",
+	"deepseek-llm:7b-base-fp16": "14GB",
+	"deepseek-llm:7b-chat-fp16": "14GB",
+	"deepseek-llm:67b-base-fp16": "135GB",
+	"deepseek-llm:67b-chat-fp16": "135GB",
+	"deepseek-r1:1.5b": "1.1GB",
+	"deepseek-r1:7b": "4.7GB",
+	"deepseek-r1:8b": "4.9GB",
+	"deepseek-r1:14b": "9.0GB",
+	"deepseek-r1:32b": "20GB",
+	"deepseek-r1:70b": "43GB",
+	"deepseek-r1:671b": "404GB",
+	"deepseek-r1:1.5b-qwen-distill-fp16": "3.6GB",
+	"deepseek-r1:1.5b-qwen-distill-q8_0": "1.9GB",
+	"deepseek-r1:14b-qwen-distill-fp16": "30GB",
+	"deepseek-r1:14b-qwen-distill-q8_0": "16GB",
+	"deepseek-r1:32b-qwen-distill-fp16": "66GB",
+	"deepseek-r1:32b-qwen-distill-q8_0": "35GB",
+	"deepseek-r1:671b-fp16": "1.3TB",
+	"deepseek-r1:671b-q8_0": "713GB",
+	"deepseek-r1:70b-llama-distill-fp16": "141GB",
+	"deepseek-r1:70b-llama-distill-q8_0": "75GB",
+	"deepseek-r1:7b-qwen-distill-fp16": "15GB",
+	"deepseek-r1:7b-qwen-distill-q8_0": "8.1GB",
+	"deepseek-r1:8b-llama-distill-fp16": "16GB",
+	"deepseek-r1:8b-llama-distill-q8_0": "8.5GB",
+	"deepseek-v2:16b": "8.9GB",
+	"deepseek-v2:236b": "133GB",
+	"deepseek-v2:lite": "8.9GB",
+	"deepseek-v2:16b-lite-chat-q6_K": "14GB",
+	"deepseek-v2:236b-chat-q6_K": "194GB",
+	"deepseek-v2:16b-lite-chat-q8_0": "17GB",
+	"deepseek-v2:236b-chat-q8_0": "251GB",
+	"deepseek-v2:16b-lite-chat-fp16": "31GB",
+	"deepseek-v2:236b-chat-fp16": "472GB",
+	"deepseek-v2.5:236b": "133GB",
+	"deepseek-v2.5:236b-q8_0": "251GB",
+	"deepseek-v3:671b": "404GB",
+	"deepseek-v3:671b-fp16": "1.3TB",
+	"deepseek-v3:671b-q8_0": "713GB",
+	"disinfozone/telos": "5.1GB",
+	"dolphin-llama3:8b": "4.7GB",
+	"dolphin-llama3:70b": "40GB",
+	"dolphin-llama3:v2.9": "4.7GB",
+	"dolphin-llama3:8b-256k": "4.7GB",
+	"dolphin-llama3:8b-256k-v2.9": "4.7GB",
+	"dolphin-llama3:8b-v2.9": "4.7GB",
+	"dolphin-llama3:70b-v2.9": "40GB",
+	"dolphin-llama3:8b-256k-v2.9-q6_K": "6.6GB",
+	"dolphin-llama3:8b-v2.9-q6_K": "6.6GB",
+	"dolphin-llama3:70b-v2.9-q6_K": "58GB",
+	"dolphin-llama3:8b-256k-v2.9-q8_0": "8.5GB",
+	"dolphin-llama3:8b-v2.9-q8_0": "8.5GB",
+	"dolphin-llama3:70b-v2.9-q8_0": "75GB",
+	"dolphin-llama3:8b-256k-v2.9-fp16": "16GB",
+	"dolphin-llama3:8b-v2.9-fp16": "16GB",
+	"dolphin-llama3:70b-v2.9-fp16": "141GB",
+	"dolphin-mistral:7b": "4.1GB",
+	"dolphin-mistral:v2": "4.1GB",
+	"dolphin-mistral:v2.1": "4.1GB",
+	"dolphin-mistral:v2.2": "4.1GB",
+	"dolphin-mistral:v2.2.1": "4.1GB",
+	"dolphin-mistral:v2.6": "4.1GB",
+	"dolphin-mistral:v2.8": "4.1GB",
+	"dolphin-mistral:7b-v2": "4.1GB",
+	"dolphin-mistral:7b-v2.1": "4.1GB",
+	"dolphin-mistral:7b-v2.2": "4.1GB",
+	"dolphin-mistral:7b-v2.2.1": "4.1GB",
+	"dolphin-mistral:7b-v2.6": "4.1GB",
+	"dolphin-mistral:7b-v2.6-dpo-laser": "4.1GB",
+	"dolphin-mistral:7b-v2.8": "4.1GB",
+	"dolphin-mistral:7b-v2-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.1-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.2-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.2.1-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.6-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.6-dpo-laser-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2.8-q8_0": "7.7GB",
+	"dolphin-mistral:7b-v2-fp16": "14GB",
+	"dolphin-mistral:7b-v2.1-fp16": "14GB",
+	"dolphin-mistral:7b-v2.2-fp16": "14GB",
+	"dolphin-mistral:7b-v2.2.1-fp16": "14GB",
+	"dolphin-mistral:7b-v2.6-fp16": "14GB",
+	"dolphin-mistral:7b-v2.6-dpo-laser-fp16": "14GB",
+	"dolphin-mistral:7b-v2.8-fp16": "14GB",
+	"dolphin-mixtral:8x7b": "26GB",
+	"dolphin-mixtral:8x22b": "80GB",
+	"dolphin-mixtral:v2.5": "26GB",
+	"dolphin-mixtral:v2.6": "26GB",
+	"dolphin-mixtral:v2.6.1": "26GB",
+	"dolphin-mixtral:v2.7": "26GB",
+	"dolphin-mixtral:8x7b-v2.5": "26GB",
+	"dolphin-mixtral:8x7b-v2.6": "26GB",
+	"dolphin-mixtral:8x7b-v2.6.1": "26GB",
+	"dolphin-mixtral:8x7b-v2.7": "26GB",
+	"dolphin-mixtral:8x22b-v2.9": "80GB",
+	"dolphin-mixtral:8x22b-v2.9-q6_K": "116GB",
+	"dolphin-mixtral:8x7b-v2.5-q8_0": "50GB",
+	"dolphin-mixtral:8x7b-v2.6-q8_0": "50GB",
+	"dolphin-mixtral:8x7b-v2.6.1-q8_0": "50GB",
+	"dolphin-mixtral:8x7b-v2.7-q8_0": "50GB",
+	"dolphin-mixtral:8x22b-v2.9-q8_0": "149GB",
+	"dolphin-mixtral:8x7b-v2.5-fp16": "93GB",
+	"dolphin-mixtral:8x7b-v2.6-fp16": "93GB",
+	"dolphin-mixtral:8x7b-v2.6.1-fp16": "93GB",
+	"dolphin-mixtral:8x7b-v2.7-fp16": "93GB",
+	"dolphin-mixtral:8x22b-v2.9-fp16": "281GB",
+	"dolphin-phi:2.7b": "1.6GB",
+	"dolphin-phi:2.7b-v2.6": "1.6GB",
+	"dolphin-phi:2.7b-v2.6-q5_0": "1.9GB",
+	"dolphin-phi:2.7b-v2.6-q8_0": "3.0GB",
+	"dolphin3:8b": "4.9GB",
+	"dolphin3:8b-llama3.1-fp16": "16GB",
+	"dolphin3:8b-llama3.1-q8_0": "8.5GB",
+	"dolphincoder:7b": "4.1GB",
+	"dolphincoder:15b": "9.1GB",
+	"dolphincoder:7b-starcoder2": "4.2GB",
+	"dolphincoder:15b-starcoder2": "9.1GB",
+	"dolphincoder:7b-starcoder2-q6_K": "6.1GB",
+	"dolphincoder:15b-starcoder2-q6_K": "13GB",
+	"dolphincoder:7b-starcoder2-q8_0": "7.9GB",
+	"dolphincoder:15b-starcoder2-q8_0": "17GB",
+	"dolphincoder:7b-starcoder2-fp16": "15GB",
+	"dolphincoder:15b-starcoder2-fp16": "32GB",
+	"duckdb-nsql:7b": "3.8GB",
+	"duckdb-nsql:7b-q8_0": "7.2GB",
+	"duckdb-nsql:7b-fp16": "13GB",
+	"ehartford/theprofessor:155b-q4_K_M": "93GB",
+	"eramax/aura_v3:Q5": "5.1GB",
+	"exaone3.5:2.4b": "1.6GB",
+	"exaone3.5:7.8b": "4.8GB",
+	"exaone3.5:32b": "19GB",
+	"exaone3.5:2.4b-instruct-q8_0": "2.8GB",
+	"exaone3.5:2.4b-instruct-fp16": "5.3GB",
+	"exaone3.5:7.8b-instruct-q8_0": "8.3GB",
+	"exaone3.5:7.8b-instruct-fp16": "16GB",
+	"exaone3.5:32b-instruct-q8_0": "8.3GB",
+	"exaone3.5:32b-instruct-fp16": "64GB",
+	"everythinglm:13b": "7.4GB",
+	"everythinglm:13b-16k": "7.4GB",
+	"everythinglm:13b-16k-q8_0": "14GB",
+	"everythinglm:13b-16k-fp16": "26GB",
+	"falcon:7b": "4.2GB",
+	"falcon:40b": "24GB",
+	"falcon:180b": "101GB",
+	"falcon:instruct": "4.2GB",
+	"falcon:text": "4.2GB",
+	"falcon:7b-instruct": "4.2GB",
+	"falcon:7b-text": "4.2GB",
+	"falcon:40b-instruct": "24GB",
+	"falcon:40b-text": "24GB",
+	"falcon:180b-instruct": "101GB",
+	"falcon:180b-text": "101GB",
+	"falcon:7b-instruct-q8_0": "7.7GB",
+	"falcon:7b-text-q8_0": "7.7GB",
+	"falcon:40b-instruct-q5_0": "29GB",
+	"falcon:40b-text-q5_0": "29GB",
+	"falcon:40b-instruct-q5_1": "32GB",
+	"falcon:40b-text-q5_1": "32GB",
+	"falcon:40b-instruct-q8_0": "44GB",
+	"falcon:40b-text-q8_0": "44GB",
+	"falcon:7b-instruct-fp16": "14GB",
+	"falcon:7b-text-fp16": "14GB",
+	"falcon:40b-instruct-fp16": "84GB",
+	"falcon:40b-text-fp16": "84GB",
+	"falcon:180b-instruct-fp16": "101GB",
+	"falcon:180b-text-fp16": "101GB",
+	"falcon2:11b": "6.4GB",
+	"falcon2:11b-q5_0": "7.7GB",
+	"falcon2:11b-q5_1": "8.4GB",
+	"falcon2:11b-q8_0": "12GB",
+	"falcon2:11b-fp16": "22GB",
+	"falcon3:1b": "1.8GB",
+	"falcon3:3b": "2.0GB",
+	"falcon3:7b": "4.6GB",
+	"falcon3:10b": "6.3GB",
+	"falcon3:1b-instruct-q8_0": "1.8GB",
+	"falcon3:1b-instruct-fp16": "3.3GB",
+	"falcon3:3b-instruct-q8_0": "3.4GB",
+	"falcon3:3b-instruct-fp16": "6.5GB",
+	"falcon3:7b-instruct-q8_0": "7.9GB",
+	"falcon3:7b-instruct-fp16": "15GB",
+	"falcon3:10b-instruct-q8_0": "11GB",
+	"falcon3:10b-instruct-fp16": "21GB",
+	"firefunction-v2:70b": "40GB",
+	"firefunction-v2:70b-q6_K": "58GB",
+	"firefunction-v2:70b-q8_0": "75GB",
+	"firefunction-v2:70b-fp16": "141GB",
+	"fixt/home-3b-v3:q4_k_m": "1.7GB",
+	"fixt/home-3b-v3:q5_k_m": "2.0GB",
+	"fixt/home-3b-v3:q8_0": "3.0GB",
+	"fixt/home-3b-v3:f16": "5.6GB",
+	"fixt/home-3b-v2:q4_k_m": "1.7GB",
+	"fixt/home-3b-v2:q5_k_m": "2.0GB",
+	"fixt/home-3b-v2:q8_0": "3.0GB",
+	"gemma:2b": "1.7GB",
+	"gemma:7b": "5.0GB",
+	"gemma:instruct": "5.0GB",
+	"gemma:text": "5.2GB",
+	"gemma:v1.1": "5.0GB",
+	"gemma:2b-instruct": "1.6GB",
+	"gemma:2b-text": "1.7GB",
+	"gemma:2b-v1.1": "1.6GB",
+	"gemma:7b-instruct": "5.0GB",
+	"gemma:7b-text": "5.2GB",
+	"gemma:7b-v1.1": "5.0GB",
+	"gemma:2b-instruct-q8_0": "2.7GB",
+	"gemma:2b-instruct-v1.1-q8_0": "2.7GB",
+	"gemma:2b-text-q8_0": "2.7GB",
+	"gemma:7b-instruct-q8_0": "9.1GB",
+	"gemma:7b-instruct-v1.1-q8_0": "9.1GB",
+	"gemma:7b-text-q8_0": "9.1GB",
+	"gemma:2b-instruct-fp16": "4.5GB",
+	"gemma:2b-instruct-v1.1-fp16": "5.0GB",
+	"gemma:2b-text-fp16": "4.5GB",
+	"gemma:7b-instruct-fp16": "17GB",
+	"gemma:7b-instruct-v1.1-fp16": "17GB",
+	"gemma:7b-text-fp16": "16GB",
+	"gemma2:2b": "1.6GB",
+	"gemma2:9b": "5.4GB",
+	"gemma2:27b": "16GB",
+	"gemma2:2b-instruct-q8_0": "2.8GB",
+	"gemma2:2b-text-q8_0": "2.8GB",
+	"gemma2:9b-instruct-q8_0": "9.8GB",
+	"gemma2:9b-text-q8_0": "9.8GB",
+	"gemma2:27b-instruct-q8_0": "29GB",
+	"gemma2:27b-text-q8_0": "29GB",
+	"gemma2:2b-instruct-fp16": "5.2GB",
+	"gemma2:2b-text-fp16": "5.2GB",
+	"gemma2:9b-instruct-fp16": "18GB",
+	"gemma2:9b-text-fp16": "18GB",
+	"gemma2:27b-instruct-fp16": "54GB",
+	"gemma2:27b-text-fp16": "54GB",
+	"gemma3:1b": "815MB",
+	"gemma3:4b": "3.3GB",
+	"gemma3:12b": "8.1GB",
+	"gemma3:27b": "17GB",
+	"gemma3:12b-it-fp16": "24GB",
+	"gemma3:12b-it-q8_0": "13GB",
+	"gemma3:1b-it-fp16": "2.0GB",
+	"gemma3:1b-it-q8_0": "1.1GB",
+	"gemma3:27b-it-fp_16": "55GB",
+	"gemma3:27b-it-q8_0": "30GB",
+	"gemma3:4b-it-fp16": "8.6GB",
+	"gemma3:4b-it-q8_0": "5.0GB",
+	"glm4:9b": "5.5GB",
+	"glm4:9b-chat-q5_1": "7.1GB",
+	"glm4:9b-text-q5_1": "7.1GB",
+	"glm4:9b-chat-q6_K": "8.3GB",
+	"glm4:9b-text-q6_K": "8.3GB",
+	"glm4:9b-chat-q8_0": "10.0GB",
+	"glm4:9b-text-q8_0": "10.0GB",
+	"glm4:9b-chat-fp16": "19GB",
+	"glm4:9b-text-fp16": "19GB",
+	"goliath:120b-q4_0": "66GB",
+	"goliath:120b-q8_0": "125GB",
+	"goliath:120b-fp16": "236GB",
+	"gpt-oss:20b": "14GB",
+	"gpt-oss:120b": "64GB",
+	"granite-code:3b": "2.0GB",
+	"granite-code:8b": "4.6GB",
+	"granite-code:20b": "12GB",
+	"granite-code:34b": "19GB",
+	"granite-code:3b-base": "2.0GB",
+	"granite-code:3b-instruct": "2.0GB",
+	"granite-code:8b-base": "4.6GB",
+	"granite-code:8b-instruct": "4.6GB",
+	"granite-code:20b-base": "12GB",
+	"granite-code:34b-base": "19GB",
+	"granite-code:3b-base-q8_0": "3.7GB",
+	"granite-code:3b-instruct-q8_0": "3.7GB",
+	"granite-code:3b-128k-instruct-q8_0": "3.7GB",
+	"granite-code:8b-base-q6_K": "6.6GB",
+	"granite-code:8b-base-q8_0": "8.6GB",
+	"granite-code:8b-instruct-q6_K": "6.6GB",
+	"granite-code:8b-instruct-q8_0": "8.6GB",
+	"granite-code:8b-instruct-128k-q4_0": "4.6GB",
+	"granite-code:8b-instruct-128k-q4_1": "5.1GB",
+	"granite-code:20b-base-q5_K_M": "15GB",
+	"granite-code:20b-base-q8_0": "21GB",
+	"granite-code:20b-instruct-8k-q6_K": "15GB",
+	"granite-code:20b-instruct-8k-q8_0": "21GB",
+	"granite-code:34b-base-q6_K": "28GB",
+	"granite-code:34b-base-q8_0": "36GB",
+	"granite-code:34b-instruct-q6_K": "28GB",
+	"granite-code:34b-instruct-q8_0": "36GB",
+	"granite-code:3b-base-fp16": "7.0GB",
+	"granite-code:3b-instruct-fp16": "7.0GB",
+	"granite-code:3b-128k-instruct-fp16": "7.0GB",
+	"granite-code:8b-base-fp16": "16GB",
+	"granite-code:8b-instruct-fp16": "16GB",
+	"granite-code:20b-base-fp16": "40GB",
+	"granite-code:20b-instruct-8k-fp16": "40GB",
+	"granite-embedding:30m": "63MB",
+	"granite-embedding:278m": "563MB",
+	"granite-embedding:30m-en": "63MB",
+	"granite-embedding:30m-en-fp16": "63MB",
+	"granite-embedding:278m-fp16": "563MB",
+	"granite3-dense:2b": "1.6GB",
+	"granite3-dense:8b": "4.9GB",
+	"granite3-dense:2b-instruct-q5_1": "2.0GB",
+	"granite3-dense:2b-instruct-q8_0": "2.8GB",
+	"granite3-dense:8b-instruct-q6_K": "6.7GB",
+	"granite3-dense:8b-instruct-q8_0": "8.7GB",
+	"granite3-dense:2b-instruct-fp16": "5.3GB",
+	"granite3-dense:8b-instruct-fp16": "16GB",
+	"granite3.1-dense:2b": "1.6GB",
+	"granite3.1-dense:8b": "5.0GB",
+	"granite3.1-dense:2b-instruct-fp16": "5.1GB",
+	"granite3.1-dense:2b-instruct-q5_K_S": "1.8GB",
+	"granite3.1-dense:2b-instruct-q6_K": "2.1GB",
+	"granite3.1-dense:2b-instruct-q8_0": "2.7GB",
+	"granite3.1-dense:8b-instruct-q6_K": "6.7GB",
+	"granite3.1-dense:8b-instruct-q8_0": "8.7GB",
+	"granite3.1-dense:8b-instruct-fp16": "16GB",
+	"granite3-guardian:2b": "2.7GB",
+	"granite3-guardian:8b": "5.8GB",
+	"granite3-guardian:2b-q8_0": "2.7GB",
+	"granite3-guardian:2b-fp16": "5.1GB",
+	"granite3-guardian:8b-q6_K": "6.7GB",
+	"granite3-guardian:8b-q8_0": "8.7GB",
+	"granite3-guardian:8b-fp16": "16GB",
+	"granite3-moe:1b": "822MB",
+	"granite3-moe:3b": "2.1GB",
+	"granite3-moe:1b-instruct-q8_0": "1.4GB",
+	"granite3-moe:3b-instruct-q8_0": "3.6GB",
+	"granite3-moe:1b-instruct-fp16": "2.7GB",
+	"granite3-moe:3b-instruct-fp16": "6.8GB",
+	"granite3.1-moe:1b": "1.4GB",
+	"granite3.1-moe:3b": "2.0GB",
+	"granite3.1-moe:1b-instruct-q5_K_S": "941MB",
+	"granite3.1-moe:1b-instruct-q6_K": "1.1GB",
+	"granite3.1-moe:1b-instruct-q8_0": "1.4GB",
+	"granite3.1-moe:1b-instruct-fp16": "2.7GB",
+	"granite3.1-moe:3b-instruct-q8_0": "3.5GB",
+	"granite3.1-moe:3b-instruct-fp16": "6.6GB",
+	"granite3.2-vision:2b": "2.4GB",
+	"granite3.2-vision:2b-fp16": "6.0GB",
+	"granite3.2-vision:2b-q8_0": "3.6GB",
+	"granite3.3:2b": "1.5GB",
+	"granite3.3:8b": "4.9GB",
+	"hemanth/chessplayer": "3.8GB",
+	"hermes3:8b": "4.7GB",
+	"hermes3:70b": "40GB",
+	"hermes3:405b": "229GB",
+	"hermes3:8b-llama3.1-q6_K": "6.6GB",
+	"hermes3:70b-llama3.1-q6_K": "58GB",
+	"hermes3:405b-llama3.1-q6_K": "333GB",
+	"hermes3:8b-llama3.1-q8_0": "8.5GB",
+	"hermes3:70b-llama3.1-q8_0": "75GB",
+	"hermes3:405b-llama3.1-q8_0": "431GB",
+	"hermes3:8b-llama3.1-fp16": "16GB",
+	"hermes3:70b-llama3.1-fp16": "141GB",
+	"hermes3:405b-llama3.1-fp16": "812GB",
+	"hookingai/monah-8b:q5_k_M": "5.7GB",
+	"hookingai/monah-8b:q6_K": "6.6GB",
+	"hookingai/monah-8b:F16": "16GB",
+	"internlm2:1m": "4.5GB",
+	"internlm2:1.8b": "1.1GB",
+	"internlm2:7b": "4.5GB",
+	"internlm2:20b": "11GB",
+	"internlm2:1.8b-chat-v2.5-q5_1": "1.4GB",
+	"internlm2:7b-chat-1m-v2.5-q5_1": "5.8GB",
+	"internlm2:7b-chat-v2.5-q5_1": "5.8GB",
+	"internlm2:20b-chat-v2.5-q5_1": "15GB",
+	"internlm2:1.8b-chat-v2.5-q6_K": "1.6GB",
+	"internlm2:7b-chat-1m-v2.5-q6_K": "6.4GB",
+	"internlm2:7b-chat-v2.5-q6_K": "6.4GB",
+	"internlm2:20b-chat-v2.5-q6_K": "16GB",
+	"internlm2:1.8b-chat-v2.5-q8_0": "2.0GB",
+	"internlm2:7b-chat-1m-v2.5-q8_0": "8.2GB",
+	"internlm2:7b-chat-v2.5-q8_0": "8.2GB",
+	"internlm2:20b-chat-v2.5-q8_0": "21GB",
+	"internlm2:1.8b-chat-v2.5-fp16": "3.8GB",
+	"internlm2:7b-chat-1m-v2.5-fp16": "15GB",
+	"internlm2:7b-chat-v2.5-fp16": "15GB",
+	"internlm2:20b-chat-v2.5-fp16": "40GB",
+	"jimscard/adult-film-screenwriter-nsfw": "4.1GB",
+	"jimscard/whiterabbit-neo:13b": "9.2GB",
+	"jimscard/whiterabbit-neo:13b-q5": "9.2GB",
+	"jimscard/whiterabbit-neo:13b-q5_K_M": "9.2GB",
+	"joefamous/grok-1:314b-q6_K": "260GB",
+	"leeplenty/lumimaid-v0.2:8b": "8.5GB",
+	"leeplenty/lumimaid-v0.2:12b": "13GB",
+	"leeplenty/lumimaid-v0.2:70b": "50GB",
+	"leeplenty/lumimaid-v0.2:123b": "130GB",
+	"llama-pro:instruct": "4.7GB",
+	"llama-pro:text": "4.7GB",
+	"llama-pro:8b-instruct-q6_K": "6.9GB",
+	"llama-pro:8b-text-q6_K": "6.9GB",
+	"llama-pro:8b-instruct-q8_0": "8.9GB",
+	"llama-pro:8b-text-q8_0": "8.9GB",
+	"llama-pro:8b-instruct-fp16": "17GB",
+	"llama-pro:8b-text-fp16": "17GB",
+	"llama2:7b": "3.8GB",
+	"llama2:13b": "7.4GB",
+	"llama2:70b": "39GB",
+	"llama2:chat": "3.8GB",
+	"llama2:text": "3.8GB",
+	"llama2:7b-chat": "3.8GB",
+	"llama2:7b-text": "3.8GB",
+	"llama2:70b-chat": "39GB",
+	"llama2:70b-text": "39GB",
+	"llama2:7b-chat-q8_0": "7.2GB",
+	"llama2:7b-text-q8_0": "7.2GB",
+	"llama2:13b-chat-q8_0": "14GB",
+	"llama2:13b-text-q8_0": "14GB",
+	"llama2:70b-chat-q6_K": "57GB",
+	"llama2:70b-text-q6_K": "57GB",
+	"llama2:70b-chat-q8_0": "73GB",
+	"llama2:70b-text-q8_0": "73GB",
+	"llama2:7b-chat-fp16": "13GB",
+	"llama2:7b-text-fp16": "13GB",
+	"llama2:13b-chat-fp16": "26GB",
+	"llama2:13b-text-fp16": "26GB",
+	"llama2:70b-chat-fp16": "138GB",
+	"llama2:70b-text-fp16": "138GB",
+	"llama2-chinese:7b": "3.8GB",
+	"llama2-chinese:13b": "7.4GB",
+	"llama2-chinese:7b-chat": "3.8GB",
+	"llama2-chinese:13b-chat": "7.4GB",
+	"llama2-chinese:7b-chat-q8_0": "7.2GB",
+	"llama2-chinese:13b-chat-q8_0": "14GB",
+	"llama2-chinese:7b-chat-fp16": "13GB",
+	"llama2-chinese:13b-chat-fp16": "26GB",
+	"llama2-uncensored:7b": "3.8GB",
+	"llama2-uncensored:70b": "39GB",
+	"llama2-uncensored:7b-chat": "3.8GB",
+	"llama2-uncensored:70b-chat": "39GB",
+	"llama2-uncensored:7b-chat-q8_0":"7.2GB",
+	"llama2-uncensored:70b-chat-q6_K":"57GB",
+	"llama2-uncensored:70b-chat-q8_0":"73GB",
+	"llama2-uncensored:7b-chat-fp16": "13GB",
+	"llama3:8b": "4.7GB",
+	"llama3:70b": "40GB",
+	"llama3:instruct": "4.7GB",
+	"llama3:text": "4.7GB",
+	"llama3:8b-text": "4.7GB",
+	"llama3:70b-instruct": "40GB",
+	"llama3:70b-text": "40GB",
+	"llama3:8b-instruct-q6_K": "6.6GB",
+	"llama3:8b-text-q6_K": "6.6GB",
+	"llama3:8b-instruct-q8_0": "8.5GB",
+	"llama3:8b-text-q8_0": "8.5GB",
+	"llama3:70b-instruct-q6_K": "58GB",
+	"llama3:70b-text-q6_K": "58GB",
+	"llama3:70b-instruct-q8_0": "75GB",
+	"llama3:70b-text-q8_0": "75GB",
+	"llama3:8b-instruct-fp16": "16GB",
+	"llama3:8b-text-fp16": "16GB",
+	"llama3:70b-instruct-fp16": "141GB",
+	"llama3:70b-text-fp16": "141GB",
+	"llama3-chatqa:8b": "4.7GB",
+	"llama3-chatqa:70b": "40GB",
+	"llama3-chatqa:8b-v1.5": "4.7GB",
+	"llama3-chatqa:70b-v1.5": "40GB",
+	"llama3-chatqa:8b-v1.5-q6_K": "6.6GB",
+	"llama3-chatqa:70b-v1.5-q6_K": "58GB",
+	"llama3-chatqa:8b-v1.5-q8_0": "8.5GB",
+	"llama3-chatqa:70b-v1.5-q8_0": "75GB",
+	"llama3-chatqa:8b-v1.5-fp16": "16GB",
+	"llama3-chatqa:70b-v1.5-fp16": "141GB",
+	"llama3-gradient:1024k": "4.7GB",
+	"llama3-gradient:8b": "4.7GB",
+	"llama3-gradient:70b": "40GB",
+	"llama3-gradient:instruct": "4.7GB",
+	"llama3-gradient:8b-instruct-1048k-q6_K": "6.6GB",
+	"llama3-gradient:70b-instruct-1048k-q6_K": "6.6GB",
+	"llama3-gradient:8b-instruct-1048k-q8_0": "8.5GB",
+	"llama3-gradient:70b-instruct-1048k-q8_0": "75GB",
+	"llama3-gradient:8b-instruct-1048k-fp16": "16GB",
+	"llama3-gradient:70b-instruct-1048k-fp16": "141GB",
+	"llama3-groq-tool-use:8b": "4.7GB",
+	"llama3-groq-tool-use:70b": "40GB",
+	"llama3-groq-tool-use:8b-q6_K": "6.6GB",
+	"llama3-groq-tool-use:70b-q6_K": "58GB",
+	"llama3-groq-tool-use:8b-q8_0": "8.5GB",
+	"llama3-groq-tool-use:70b-q8_0": "75GB",
+	"llama3-groq-tool-use:8b-fp16": "16GB",
+	"llama3-groq-tool-use:70b-fp16": "141GB",
+	"llama3.1:8b": "4.7GB",
+	"llama3.1:70b": "40GB",
+	"llama3.1:405b": "229GB",
+	"llama3.1:8b-instruct-q6_K": "6.6GB",
+	"llama3.1:8b-text-q6_K": "6.6GB",
+	"llama3.1:8b-instruct-q8_0": "8.5GB",
+	"llama3.1:8b-text-q8_0": "8.5GB",
+	"llama3.1:70b-instruct-q6_K": "58GB",
+	"llama3.1:70b-text-q6_K": "58GB",
+	"llama3.1:70b-instruct-q8_0": "75GB",
+	"llama3.1:70b-text-q8_0": "75GB",
+	"llama3.1:405b-instruct-q8_0": "431GB",
+	"llama3.1:405b-text-q8_0": "431GB",
+	"llama3.1:8b-instruct-fp16": "16GB",
+	"llama3.1:8b-text-fp16": "16GB",
+	"llama3.1:70b-instruct-fp16": "141GB",
+	"llama3.1:70b-text-fp16": "141GB",
+	"llama3.1:405b-instruct-fp16": "812GB",
+	"llama3.1:405b-text-fp16": "812GB",
+	"llama3.2-vision:11b":  "7.9GB",
+	"llama3.2-vision:90b":  "55GB",
+	"llama3.2-vision:11b-instruct-q8_0":  "12GB",
+	"llama3.2-vision:11b-instruct-fp16":  "21GB",
+	"llama3.2-vision:90b-instruct-q8_0":  "95GB",
+	"llama3.2-vision:90b-instruct-fp16":  "177GB",
+	"llama3.2:3b": "2.0GB",
+	"llama3.2:1b": "1.3GB",
+	"llama3.2:1b-instruct-q5_1": "953MB",
+	"llama3.2:1b-text-q5_1": "953MB",
+	"llama3.2:1b-instruct-q6_K": "1.0GB",
+	"llama3.2:1b-text-q6_K": "1.0GB",
+	"llama3.2:1b-instruct-q8.0": "1.3GB",
+	"llama3.2:1b-text-q8_0": "1.3GB",
+	"llama3.2:3b-instruct-q8_0": "3.4GB",
+	"llama3.2:3b-text-q8_0": "3.4GB",
+	"llama3.2:1b-instruct-fp16": "2.5GB",
+	"llama3.2:1b-text-fp16": "2.5GB",
+	"llama3.2:3b-instruct-fp16": "6.4GB",
+	"llama3.2:3b-text-fp16": "6.4GB",
+	"llama3.3:70b": "43GB",
+	"llama3.3:70b-instruct-fp16": "141GB",
+	"llama3.3:70b-instruct-q8_0": "75GB",
+	"llama3.3:70b-instruct-q6_K": "58GB",
+	"llama4:maverick": "245GB",
+	"llama4:scout": "67GB",
+	"llama4:16x17b": "67GB",
+	"llama4:128x17b": "245GB",
+	"llama4:17b-maverick-128e-instruct-q4_K_M": "245GB",
+	"llama4:17b-maverick-128e-instruct-q8_0": "428GB",
+	"llama4:17b-maverick-128e-instruct-fp16": "803GB",
+	"llama4:17b-scout-128e-instruct-q4_K_M": "67GB",
+	"llama4:17b-scout-128e-instruct-q8_0": "117GB",
+	"llama4:17b-scout-128e-instruct-fp16": "217GB",
+	"llama-guard3:1b": "1.6GB",
+	"llama-guard3:8b": "4.9GB",
+	"llama-guard3:1b-q4_1": "996MB",
+	"llama-guard3:1b-q8_0": "1.6GB",
+	"llama-guard3:8b-q6_K": "6.6GB",
+	"llama-guard3:8b-q8_0": "8.5GB",
+	"llama-guard3:1b-fp16": "3.0GB",
+	"llama-guard3:8b-fp16": "16GB",
+	"llava:7b": "4.7GB",
+	"llava:13b": "8.0GB",
+	"llava:34b": "20.0GB",
+	"llava:v1.6": "4.7GB",
+	"llava:7b-v1.6": "4.7GB",
+	"llava:13b-v1.6": "8.0GB",
+	"llava:34b-v1.6": "20.0GB",
+	"llava:7b-v1.5-q8_0": "7.8GB",
+	"llava:7b-v1.6-mistral-q6_K": "6.6GB",
+	"llava:7b-v1.6-mistral-q8_0": "8.3GB",
+	"llava:7b-v1.6-vicuna-q8_0": "7.8GB",
+	"llava:13b-v1.5-q8_0": "14GB",
+	"llava:13b-v1.6-vicuna-q8_0": "14GB",
+	"llava:34b-v1.6-q6_K": "29GB",
+	"llava:34b-v1.6-q8_0": "37GB",
+	"llava:7b-v1.5-fp16": "14GB",
+	"llava:7b-v1.6-mistral-fp16": "15GB",
+	"llava:7b-v1.6-vicuna-fp16": "14GB",
+	"llava:13b-v1.5-fp16": "27GB",
+	"llava:13b-v1.6-vicuna-fp16": "27GB",
+	"llava:34b-v1.6-fp16": "69GB",
+	"llava-llama3:8b": "5.5GB",
+	"llava-llama3:8b-v1.1-fp16": "17GB",
+	"llava-llama3:8b-v1.1-q4_0": "5.5GB",
+	"llava-phi3:3.8b": "2.9GB",
+	"llava-phi3:3.8b-mini-fp16": "8.3GB",
+	"llava-phi3:3.8b-mini-q4_0": "2.9GB",
+	"magicoder:7b": "3.8GB",
+	"magicoder:7b-s-cl-q8_0": "7.2GB",
+	"magicoder:7b-s-cl-fp16": "13GB",
+	"mannix/llamax3-8b-alpaca:q4_0": "4.7GB",
+	"mannix/llamax3-8b-alpaca:q6_K": "6.6GB",
+	"mannix/llamax3-8b-alpaca:q8_0": "8.5GB",
+	"mannix/replete-adapted-llama3-8b:iq4_xs": "4.4GB",
+	"mannix/replete-adapted-llama3-8b:iq4_nl": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_0": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_k_s": "4.7GB",
+	"mannix/replete-adapted-llama3-8b:q4_k_m": "4.9GB",
+	"mannix/replete-adapted-llama3-8b:q4_1": "5.1GB",
+	"mannix/replete-adapted-llama3-8b:q5_0": "5.6GB",
+	"mannix/replete-adapted-llama3-8b:q5_1": "6.1GB",
+	"mannix/replete-adapted-llama3-8b:q5_k_s": "6.1GB",
+	"mannix/replete-adapted-llama3-8b:q6_k": "6.6GB",
+	"mannix/replete-adapted-llama3-8b:q8_0": "8.5GB",
+	"mannix/replete-adapted-llama3-8b:fp16": "16GB",
+	"mannix/replete-coder-llama3-8b:q8_0": "8.5GB",
+	"mannix/replete-coder-llama3-8b:fp16": "16GB",
+	"mannix/smaug-qwen2-72b:q4_0": "41GB",
+	"mannix/smaug-qwen2-72b:q5_1": "55GB",
+	"mannix/smaug-qwen2-72b:q6_K": "64GB",
+	"mannix/smaug-qwen2-72b:q8_0": "77GB",
+	"marco-o1:7b": "4.7GB",
+	"marco-o1:7b-fp16": "15GB",
+	"marco-o1:7b-q8_0": "8.1GB",
+	"mathstral:7b": "4.1GB",
+	"mathstral:7b-v0.1-q8_0": "7.7GB",
+	"mathstral:7b-v0.1-fp16": "14GB",
+	"meditron:7b": "3.8GB",
+	"meditron:70b": "39GB",
+	"meditron:7b-q8_0": "7.2GB",
+	"meditron:70b-q5_1": "52GB",
+	"meditron:7b-fp16": "13GB",
+	"medllama2:7b": "3.8GB",
+	"medllama2:7b-q8_0": "7.2GB",
+	"medllama2:7b-fp16": "13GB",
+	"megadolphin:120b": "68GB",
+	"megadolphin:v2.2": "68GB",
+	"megadolphin:120b-v2.2": "68GB",
+	"megadolphin:120b-v2.2-q6_K": "99GB",
+	"megadolphin:120b-v2.2-q8_0": "128GB",
+	"megadolphin:120b-v2.2-fp16": "241GB",
+	"minicpm-v:8b": "5.5GB",
+	"minicpm-v:8b-2.6-q6_K": "7.3GB",
+	"minicpm-v:8b-2.6-q8_0": "9.1GB",
+	"minicpm-v:8b-2.6-fp16": "16GB",
+	"mistral:7b": "4.1GB",
+	"mistral:instruct": "4.1GB",
+	"mistral:text": "4.1GB",
+	"mistral:v0.1": "4.1GB",
+	"mistral:v0.2": "4.1GB",
+	"mistral:v0.3": "4.1GB",
+	"mistral:7b-instruct": "4.1GB",
+	"mistral:7b-text": "4.1GB",
+	"mistral:7b-instruct-q6_K": "5.9GB",
+	"mistral:7b-instruct-v0.2-q6_K": "5.9GB",
+	"mistral:7b-instruct-v0.3-q6_K": "5.9GB",
+	"mistral:7b-text-q6_K": "5.9GB",
+	"mistral:7b-text-v0.2-q6_K": "5.9GB",
+	"mistral:7b-instruct-q8_0": "7.7GB",
+	"mistral:7b-instruct-v0.2-q8_0": "7.7GB",
+	"mistral:7b-instruct-v0.3-q8_0": "7.7GB",
+	"mistral:7b-text-q8_0": "7.7GB",
+	"mistral:7b-text-v0.2-q8_0": "7.7GB",
+	"mistral:7b-instruct-fp16": "14GB",
+	"mistral:7b-instruct-v0.2-fp16": "14GB",
+	"mistral:7b-instruct-v0.3-fp16": "14GB",
+	"mistral:7b-text-fp16": "14GB",
+	"mistral:7b-text-v0.2-fp16": "14GB",
+	"mistral-large:123b": "73GB",
+	"mistral-large:123b-instruct-2407-q6_K": "101GB",
+	"mistral-large:123b-instruct-2407-q8_0": "130GB",
+	"mistral-large:123b-instruct-2407-fp16": "245GB",
+	"mistral-large:123b-instruct-2411-q6_K": "101GB",
+	"mistral-large:123b-instruct-2411-q8_0": "130GB",
+	"mistral-large:123b-instruct-2411-fp16": "245GB",
+	"mistral-nemo:12b": "7.1GB",
+	"mistral-nemo:12b-instruct-2407-q8_0": "13GB",
+	"mistral-nemo:12b-instruct-2407-fp16": "25GB",
+	"mistral-openorca:7b": "4.1GB",
+	"mistral-openorca:7b-q8_0": "7.7GB",
+	"mistral-openorca:7b-fp16": "14GB",
+	"mistral-small3.1:24b": "15GB",
+	"mistral-small3.1:24b-instruct-2503-fp16": "48GB",
+	"mistral-small3.1:24b-instruct-2503-q8_0": "26GB",
+	"mistral-small:22b": "13GB",
+	"mistral-small:22b-instruct-2409-q5_0": "15GB",
+	"mistral-small:22b-instruct-2409-q5_K_S": "15GB",
+	"mistral-small:22b-instruct-2409-q5_K_M": "16GB",
+	"mistral-small:22b-instruct-2409-q8_0": "24GB",
+	"mistral-small:22b-instruct-2409-fp16": "44GB",
+	"mistrallite:7b": "4.1GB",
+	"mistrallite:7b-v0.1-q8_0": "7.7GB",
+	"mistrallite:7b-v0.1-fp16": "14GB",
+	"mixtral:8x7b": "26GB",
+	"mixtral:8x22b": "80GB",
+	"mixtral:instruct": "26GB",
+	"mixtral:text": "26GB",
+	"mixtral:v0.1": "80GB",
+	"mixtral:v0.1-instruct": "80GB",
+	"mixtral:8x22b-instruct": "80GB",
+	"mixtral:8x22b-text": "80GB",
+	"mixtral:8x7b-instruct-v0.1-q8_0": "50GB",
+	"mixtral:8x7b-text-v0.1-q8_0": "50GB",
+	"mixtral:8x22b-instruct-v0.1-q6_K": "115GB",
+	"mixtral:8x22b-text-v0.1-q6_K": "115GB",
+	"mixtral:8x22b-instruct-v0.1-q8_0": "149GB",
+	"mixtral:8x22b-text-v0.1-q8_0": "149GB",
+	"mixtral:8x7b-instruct-v0.1-fp16": "93GB",
+	"mixtral:8x7b-text-v0.1-fp16": "93GB",
+	"mixtral:8x22b-instruct-v0.1-fp16": "281GB",
+	"mixtral:8x22b-text-v0.1-fp16": "281GB",
+	"monotykamary/whiterabbitneo-v1.5a:7b": "4.1GB",
+	"monotykamary/whiterabbitneo-v1.5a:7b_q4_K_M": "4.1GB",
+	"moondream:1.8b": "1.7GB",
+	"moondream:v2": "1.7GB",
+	"moondream:1.8b-v2-q5_0": "1.9GB",
+	"moondream:1.8b-v2-q5_1": "2.0GB",
+	"moondream:1.8b-v2-q8_0": "2.4GB",
+	"moondream:1.8b-v2-fp16": "3.7GB",
+	"mxbai-embed-large:335m": "670MB",
+	"mxbai-embed-large:v1": "670MB",
+	"mxbai-embed-large:335m-v1-fp16": "670MB",
+	"nemotron:70b": "43GB",
+	"nemotron:70b-instruct-q6_K": "58GB",
+	"nemotron:70b-instruct-q8_0": "75GB",
+	"nemotron:70b-instruct-fp16": "141GB",
+	"nemotron-mini:4b": "2.7GB",
+	"nemotron-mini:4b-instruct-q6_K": "3.4GB",
+	"nemotron-mini:4b-instruct-q8_0": "4.5GB",
+	"nemotron-mini:4b-instruct-fp16": "8.4GB",
+	"neural-chat:7b": "4.1GB",
+	"neural-chat:7b-v3.1": "4.1GB",
+	"neural-chat:7b-v3.2": "4.1GB",
+	"neural-chat:7b-v3.3": "4.1GB",
+	"neural-chat:7b-v3.1-q8_0": "7.7GB",
+	"neural-chat:7b-v3.2-q8_0": "7.7GB",
+	"neural-chat:7b-v3.3-q8_0": "7.7GB",
+	"neural-chat:7b-v3.1-fp16": "14GB",
+	"neural-chat:7b-v3.2-fp16": "14GB",
+	"neural-chat:7b-v3.3-fp16": "14GB",
+	"nexusraven:13b": "7.4GB",
+	"nexusraven:13b-q8_0": "14GB",
+	"nexusraven:13b-v2-q8_0": "14GB",
+	"nexusraven:13b-fp16": "26GB",
+	"nexusraven:13b-v2-fp16": "26GB",
+	"nomic-embed-text:v1.5": "274MB",
+	"nomic-embed-text:137m-v1.5-fp16": "274MB",
+	"notus:7b": "4.1GB",
+	"notus:7b-v1": "4.1GB",
+	"notus:7b-v1-q8_0": "7.7GB",
+	"notus:7b-v1-fp16": "14GB",
+	"notux:8x7b": "26GB",
+	"notux:8x7b-v1": "26GB",
+	"notux:8x7b-v1-q8_0": "50GB",
+	"notux:8x7b-v1-fp16": "93GB",
+	"nous-hermes:7b": "3.8GB",
+	"nous-hermes:13b": "7.4GB",
+	"nous-hermes:7b-llama2": "3.8GB",
+	"nous-hermes:13b-llama2": "7.4GB",
+	"nous-hermes:13b-q6_K": "11GB",
+	"nous-hermes:7b-llama2-q6_K": "5.5GB",
+	"nous-hermes:13b-llama2-q6_K": "11GB",
+	"nous-hermes:70b-llama2-q6_K": "57GB",
+	"nous-hermes:13b-q8_0": "14GB",
+	"nous-hermes:7b-llama2-q8_0": "7.2GB",
+	"nous-hermes:13b-llama2-q8_0": "14GB",
+	//"nous-hermes:70b-llama2-q8_0": "GB",
+	"nous-hermes:13b-fp16": "26GB",
+	"nous-hermes:7b-llama2-fp16": "13GB",
+	"nous-hermes:13b-llama2-fp16": "26GB",
+	"nous-hermes:70b-llama2-fp16": "138GB",
+	"nous-hermes2:10.7b": "6.1GB",
+	"nous-hermes2:34b": "19GB",
+	"nous-hermes2:10.7b-solar-q5_0": "7.4GB",
+	"nous-hermes2:10.7b-solar-q5_1": "8.1GB",
+	"nous-hermes2:10.7b-solar-q6_K": "8.8GB",
+	"nous-hermes2:34b-yi-q6_K": "28GB",
+	"nous-hermes2:10.7b-solar-q8_0": "11GB",
+	"nous-hermes2:34b-yi-q8_0": "37GB",
+	"nous-hermes2:10.7b-solar-fp16": "21GB",
+	"nous-hermes2:34b-yi-fp16": "69GB",
+	"nous-hermes2-mixtral:8x7b": "26GB",
+	"nous-hermes2-mixtral:dpo": "26GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q4_0": "26GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q4_1": "29GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q5_0": "32GB",
+	"nous-hermes2-mixtral:8x7b-dpo-q8_0": "50GB",
+	"nous-hermes2-mixtral:8x7b-dpo-fp16": "93GB",
+	"nqduc/gemsura:2b": "5.0GB",
+	"nqduc/gemsura:7b": "17.0GB",
+	"nqduc/gemsura:2b-q4_0": "1.6GB",
+	"nqduc/gemsura:2b-q8_0": "2.7GB",
+	"nqduc/gemsura:7b-q4_0": "5.0GB",
+	"nqduc/gemsura:7b-q8_0": "9.1GB",
+	"nqduc/mixsura:mixsura-q4_0": "26GB",
+	"nqduc/mixsura:mixsura-q4_1": "29GB",
+	"nqduc/mixsura:mixsura-q5_0": "32GB",
+	"nqduc/mixsura:mixsura-q5_1": "35GB",
+	"nqduc/mixsura:mixsura-q6_K": "38GB",
+	"nqduc/mixsura:mixsura-q8_0": "50GB",
+	"nqduc/mixsura:mixsura-fp16": "93GB",
+	"nqduc/mixsura-sft:mixsura-sft-fp16": "93GB",
+	"nqduc/mixsura-sft:mixsura-sft-q4_0": "26GB",
+	"nqduc/mixsura-sft:mixsura-sft-q4_1": "29GB",
+	"nqduc/mixsura-sft:mixsura-sft-q5_0": "32GB",
+	"nqduc/mixsura-sft:mixsura-sft-q5_1": "35GB",
+	"nqduc/mixsura-sft:mixsura-sft-q6_K": "38GB",
+	"nqduc/mixsura-sft:mixsura-sft-q8_0": "50GB",
+	"nuextract:3.8b": "2.2GB",
+	"nuextract:3.8-q8_0": "3.1GB",
+	"nuextract:3.8-fp16": "7.6GB",
+	"olmo2:7b": "4.5GB",
+	"olmo2:13b": "8.4GB",
+	"olmo2:7b-1124-instruct-fp16": "27GB",
+	"olmo2:7b-1124-instruct-q8_0": "15GB",
+	"olmo2:13b-1124-instruct-fp16": "15GB",
+	"olmo2:13b-1124-instruct-q8_0": "7.8GB",
+	"open-orca-platypus2:13b": "7.4GB",
+	"open-orca-platypus2:13b-q8_0": "14GB",
+	"open-orca-platypus2:13b-fp16": "26GB",
+	"openchat:7b": "4.1GB",
+	"openchat:7b-v3.5": "4.1GB",
+	"openchat:7b-v3.5-0106": "4.1GB",
+	"openchat:7b-v3.5-1210": "4.1GB",
+	"openchat:7b-v3.5-q8_0": "7.7GB",
+	"openchat:7b-v3.5-0106-q8_0": "7.7GB",
+	"openchat:7b-v3.5-1210-q8_0": "7.7GB",
+	"openchat:7b-v3.5-fp16": "14GB",
+	"openchat:7b-v3.5-0106-fp16": "14GB",
+	"openchat:7b-v3.5-1210-fp16": "14GB",
+	"opencoder:1.5b": "1.4GB",
+	"opencoder:8b": "4.7GB",
+	"opencoder:1.5b-instruct-q8_0": "2.0GB",
+	"opencoder:1.5b-instruct-fp16": "3.8GB",
+	"opencoder:8b-instruct-q8_0": "8.3GB",
+	"opencoder:8b-instruct-fp16": "16GB",
+	"openhermes:v2.5": "4.1GB",
+	"openhermes:v2": "4.1GB",
+	"openhermes:7b-v2": "4.1GB",
+	"openhermes:7b-v2.5": "4.1GB",
+	"openhermes:7b-mistral-v2-q8_0": "7.7GB",
+	"openhermes:7b-mistral-v2.5-q8_0": "7.7GB",
+	"openhermes:7b-mistral-v2-fp16": "14GB",
+	"openhermes:7b-mistral-v2.5-fp16": "14GB",
+	"openthinker:7b": "4.7GB",
+	"openthinker:32b": "20GB",
+	"openthinker:32b-fp16": "66GB",
+	"openthinker:32b-q8_0": "35GB",
+	"openthinker:7b-fp16": "15GB",
+	"openthinker:7b-q8_0": "8.1GB",
+	"orca-mini:3b": "2.0GB",
+	"orca-mini:7b": "3.8GB",
+	"orca-mini:13b": "7.4GB",
+	"orca-mini:70b": "39GB",
+	"orca-mini:7b-v3": "3.8GB",
+	"orca-mini:13b-v3": "7.4GB",
+	"orca-mini:70b-v3": "39GB",
+	"orca-mini:3b-q8_0": "3.6GB",
+	"orca-mini:7b-q8_0": "7.2GB",
+	"orca-mini:13b-q8_0": "14GB",
+	"orca-mini:7b-v2-q8_0": "7.2GB",
+	"orca-mini:7b-v3-q8_0": "7.2GB",
+	"orca-mini:13b-v2-q8_0": "14GB",
+	"orca-mini:13b-v3-q8_0": "14GB",
+	"orca-mini:70b-v3-q6_K": "57GB",
+	"orca-mini:70b-v3-q8_0": "73GB",
+	"orca-mini:3b-fp16": "6.9GB",
+	"orca-mini:7b-fp16": "13GB",
+	"orca-mini:13b-fp16": "26GB",
+	"orca-mini:7b-v2-fp16": "13GB",
+	"orca-mini:7b-v3-fp16": "13GB",
+	"orca-mini:13b-v2-fp16": "26GB",
+	"orca-mini:13b-v3-fp16": "26GB",
+	"orca-mini:70b-v3-fp16": "138GB",
+	"orca2:7b": "3.8GB",
+	"orca2:13b": "7.4GB",
+	"orca2:7b-q8_0": "7.2GB",
+	"orca2:13b-q8_0": "14GB",
+	"orca2:7b-fp16": "13GB",
+	"orca2:13b-fp16": "26GB",
+	"paraphrase-multilingual:278m": "563MB",
+	"paraphrase-multilingual:278m-mpnet-base-v2-fp16": "563MB",
+	"partai/dorna-llama3:8b-instruct-q4_0": "4.7GB",
+	"partai/dorna-llama3:8b-instruct-q5_0": "5.6GB",
+	"partai/dorna-llama3:8b-instruct-q8_0": "8.5GB",
+	"phi:2.7": "1.6GB",
+	"phi:chat": "1.6GB",
+	"phi:2.7b-chat-v2-q5_0": "1.9GB",
+	"phi:2.7b-chat-v2-q5_1": "2.1GB",
+	"phi:2.7b-chat-v2-q8_0": "2.3GB",
+	"phi:2.7b-chat-v2-fp16": "5.6GB",
+	"phi3:3.8b": "2.2GB",
+	"phi3:14b": "7.9GB",
+	"phi3:instruct": "2.2GB",
+	"phi3:medium": "7.9GB",
+	"phi3:medium-128k": "7.9GB",
+	"phi3:medium-4k": "7.9GB",
+	"phi3:mini": "2.2GB",
+	"phi3:mini-128k": "2.2GB",
+	"phi3:mini-4k": "2.2GB",
+	"phi3:3.8b-instruct": "2.2GB",
+	"phi3:14b-instruct": "7.9GB",
+	"phi3:3.8b-mini-128k-instruct-q8_0": "4.1GB",
+	"phi3:3.8b-mini-4k-instruct-q8_0": "4.1GB",
+	"phi3:14b-medium-128k-instruct-q8_0": "15GB",
+	"phi3:14b-medium-4k-instruct-q8_0": "15GB",
+	"phi3:3.8b-mini-128k-instruct-fp16": "7.6GB",
+	"phi3:3.8b-mini-4k-instruct-fp16": "7.6GB",
+	"phi3:14b-medium-128k-instruct-fp16": "28GB",
+	"phi3:14b-medium-4k-instruct-fp16": "28GB",
+	"phi3.5:3.8b": "2.2GB",
+	"phi3.5:3.8b-mini-instruct-q8_0": "4.1GB",
+	"phi3.5:3.8b-mini-instruct-fp16": "7.6GB",
+	"phi4:14b": "9.1GB",
+	"phi4:14b-fp16": "29GB",
+	"phi4:14b-q8_0": "16GB",
+	"phi4-mini:3.8b": "2.5GB",
+	"phi4-mini:3.8b-fp16": "7.7GB",
+	"phi4-mini:3.8b-q8_0": "4.1GB",
+	"phind-codellama:34b": "19GB",
+	"phind-codellama:34b-python": "19GB",
+	"phind-codellama:34b-v2": "19GB",
+	"phind-codellama:34b-q6_K": "28GB",
+	"phind-codellama:34b-python-q6_K": "28GB",
+	"phind-codellama:34b-q8_0": "36GB",
+	"phind-codellama:34b-python-q8_0": "36GB",
+	"phind-codellama:34b-fp16": "67GB",
+	"phind-codellama:34b-python-fp16": "67GB",
+	"qwen:0.5b": "395MB",
+	"qwen:1.8b": "1.1GB",
+	"qwen:4b": "2.3GB",
+	"qwen:7b": "4.5GB",
+	"qwen:14b": "8.2GB",
+	"qwen:32b": "18GB",
+	"qwen:72b": "41GB",
+	"qwen:110b": "63GB",
+	"qwen:0.5b-chat": "395MB",
+	"qwen:0.5b-text": "395MB",
+	"qwen:1.8b-chat": "1.1GB",
+	"qwen:1.8b-text": "1.1GB",
+	"qwen:4b-chat": "2.3GB",
+	"qwen:4b-text": "2.3GB",
+	"qwen:7b-chat": "4.5GB",
+	"qwen:7b-text": "4.5GB",
+	"qwen:14b-chat": "8.2GB",
+	"qwen:14b-text": "8.2GB",
+	"qwen:32b-chat": "18GB",
+	"qwen:32b-text": "18GB",
+	"qwen:72b-chat": "41GB",
+	"qwen:72b-text": "63GB",
+	"qwen:110b-chat": "63GB",
+	"qwen:7b-fp16": "15GB",
+	"qwen:0.5b-chat-v1.5-q8_0": "556MB",
+	"qwen:0.5b-text-v1.5-q8_0": "665MB",
+	"qwen:1.8b-chat-q8_0": "2.0GB",
+	"qwen:1.8b-chat-v1.5-q8_0": "2.0GB",
+	"qwen:1.8b-text-q8_0": "2.0GB",
+	"qwen:1.8b-text-v1.5-q8_0": "2.0GB",
+	"qwen:4b-chat-v1.5-q8_0": "4.2GB",
+	"qwen:4b-text-v1.5-q8_0": "4.2GB",
+	"qwen:7b-chat-q8_0": "8.2GB",
+	"qwen:7b-chat-v1.5-q8_0": "8.2GB",
+	"qwen:7b-text-v1.5-q8_0": "8.2GB",
+	"qwen:14b-chat-q8_0": "15GB",
+	"qwen:14b-chat-v1.5-q8_0": "15GB",
+	"qwen:14b-text-q8_0": "15GB",
+	"qwen:14b-text-v1.5-q8_0": "15GB",
+	"qwen:32b-chat-v1.5-q8_0": "35GB",
+	"qwen:32b-text-v1.5-q8_0": "35GB",
+	"qwen:72b-chat-q8_0": "77GB",
+	"qwen:72b-chat-v1.5-q8_0": "77GB",
+	"qwen:72b-text-q8_0": "77GB",
+	"qwen:72b-text-v1.5-q8_0": "77GB",
+	"qwen:110b-chat-v1.5-q8_0": "118GB",
+	"qwen:110b-text-v1.5-q8_0": "118GB",
+	"qwen:0.5b-chat-v1.5-fp16": "1.2GB",
+	"qwen:0.5b-text-v1.5-fp16": "1.2GB",
+	"qwen:1.8b-chat-fp16": "3.7GB",
+	"qwen:1.8b-chat-v1.5-fp16": "3.7GB",
+	"qwen:1.8b-text-fp16": "3.7GB",
+	"qwen:1.8b-text-v1.5-fp16": "3.7GB",
+	"qwen:4b-chat-v1.5-fp16": "7.9GB",
+	"qwen:4b-text-v1.5-fp16": "7.9GB",
+	"qwen:7b-chat-fp16": "15GB",
+	"qwen:7b-chat-v1.5-fp16": "15GB",
+	"qwen:7b-text-v1.5-fp16": "15GB",
+	"qwen:14b-chat-fp16": "28GB",
+	"qwen:14b-chat-v1.5-fp16": "28GB",
+	"qwen:14b-text-fp16": "28GB",
+	"qwen:14b-text-v1.5-fp16": "28GB",
+	"qwen:32b-chat-v1.5-fp16": "65GB",
+	"qwen:72b-chat-fp16": "145GB",
+	"qwen:72b-chat-v1.5-fp16": "145GB",
+	"qwen:72b-text-fp16": "145GB",
+	"qwen:72b-text-v1.5-fp16": "145GB",
+	"qwen:110b-chat-v1.5-fp16": "222GB",
+	"qwen:110b-text-v1.5-fp16": "222GB",
+	"qwen2:0.5b": "352MB",
+	"qwen2:1.5b": "935MB",
+	"qwen2:7b": "4.4GB",
+	"qwen2:72b": "41GB",
+	"qwen2:0.5b-instruct": "352MB",
+	"qwen2:1.5b-instruct": "935MB",
+	"qwen2:7b-instruct": "4.4GB",
+	"qwen2:7b-text": "4.4GB",
+	"qwen2:72b-instruct": "41GB",
+	"qwen2:72b-text": "41GB",
+	"qwen2:0.5b-instruct-q8_0": "531MB",
+	"qwen2:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2:7b-instruct-q8_0": "8.1GB",
+	"qwen2:7b-text-q8_0": "8.1GB",
+	"qwen2:72b-instruct-q8_0": "77GB",
+	"qwen2:72b-text-q8_0": "77GB",
+	"qwen2:0.5b-instruct-fp16": "994MB",
+	"qwen2:1.5b-instruct-fp16": "3.1GB",
+	"qwen2:7b-instruct-fp16": "15GB",
+	"qwen2:72b-instruct-fp16": "145GB",
+	"qwen2:72b-text-fp16": "145GB",
+	"qwen2-math:1.5b": "935MB",
+	"qwen2-math:7b": "4.4GB",
+	"qwen2-math:72b": "41GB",
+	"qwen2-math:1.5b-instruct": "935MB",
+	"qwen2-math:7b-instruct": "4.4GB",
+	"qwen2-math:72b-instruct": "41GB",
+	"qwen2-math:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2-math:7b-instruct-q6_K": "6.3GB",
+	"qwen2-math:7b-instruct-q8_0": "8.1GB",
+	"qwen2-math:72b-instruct-q6_K": "64GB",
+	"qwen2-math:72b-instruct-q8_0": "77GB",
+	"qwen2-math:1.5b-instruct-fp16": "3.1GB",
+	"qwen2-math:7b-instruct-fp16": "15GB",
+	"qwen2-math:72b-instruct-fp16": "145GB",
+	"qwen2.5:0.5b": "398MB",
+	"qwen2.5:1.5b": "986MB",
+	"qwen2.5:3b": "1.9GB",
+	"qwen2.5:7b": "4.7GB",
+	"qwen2.5:14b": "9.0GB",
+	"qwen2.5:32b": "20.0GB",
+	"qwen2.5:72b": "47.0GB",
+	"qwen2.5:0.5b-base": "398MB",
+	"qwen2.5:0.5b-instruct": "398MB",
+	"qwen2.5:1.5b-instruct": "986MB",
+	"qwen2.5:3b-instruct": "1.9GB",
+	"qwen2.5:7b-instruct": "4.7GB",
+	"qwen2.5:14b-instruct": "9.0GB",
+	"qwen2.5:32b-instruct": "20GB",
+	"qwen2.5:72b-instruct": "47GB",
+	"qwen2.5:7b-instruct-q6_K": "6.3GB",
+	"qwen2.5:32b-instruct-q6_K": "27GB",
+	"qwen2.5:72b-instruct-q6_K": "64GB",
+	"qwen2.5:0.5b-instruct-q8_0": "531MB",
+	"qwen2.5:1.5b-instruct-q8_0": "1.6GB",
+	"qwen2.5:3b-instruct-q8_0": "3.3GB",
+	"qwen2.5:7b-instruct-q8_0": "8.1GB",
+	"qwen2.5:14b-instruct-q8_0": "16GB",
+	"qwen2.5:32b-instruct-q8_0": "35GB",
+	"qwen2.5:72b-instruct-q8_0": "77GB",
+	"qwen2.5:0.5b-instruct-fp16": "994MB",
+	"qwen2.5:1.5b-instruct-fp16": "3.1GB",
+	"qwen2.5:3b-instruct-fp16": "6.2GB",
+	"qwen2.5:7b-instruct-fp16": "15GB",
+	"qwen2.5:14b-instruct-fp16": "30GB",
+	"qwen2.5:32b-instruct-fp16": "66GB",
+	"qwen2.5:72b-instruct-fp16": "145GB",
+	"qwen2.5-coder:1.5b": "986MB",
+	"qwen2.5-coder:7b": "4.7GB",
+	"qwen2.5-coder:1.5b-base": "986MB",
+	"qwen2.5-coder:1.5b-instruct": "986MB",
+	"qwen2.5-coder:7b-base": "4.7GB",
+	"qwen2.5-coder:7b-instruct": "4.7GB",
+	"qwen2.5-coder:1.5b-base-fp16": "3.1GB",
+	"qwen2.5-coder:1.5b-instruct-fp16": "3.1GB",
+	"qwen2.5-coder:7b-base-fp16": "15GB",
+	"qwen2.5-coder:7b-instruct-fp16": "15GB",
+	"qwen3:0.6b": "523MB",
+	"qwen3:1.7b": "1.4GB",
+	"qwen3:4b": "2.5GB",
+	"qwen3:8b": "5.2GB",
+	"qwen3:14b": "9.3GB",
+	"qwen3:30b": "19GB",
+	"qwen3:32b": "20GB",
+	"qwen3:235b": "142GB",
+	"qwen3:0.6b-q8_0": "832GB",
+	"qwen3:0.6b-fp16": "1.5GB",
+	"qwen3:1.7b-q8_0": "2.2GB",
+	"qwen3:1.7b-fp16": "4.1GB",
+	"qwen3:4b-instruct": "2.5GB",
+	"qwen3:4b-instruct-2507-q8_0": "4.3GB",
+	"qwen3:4b-instruct-2507-fp16": "8.1GB",
+	"qwen3:4b-q8_0": "4.4GB",
+	"qwen3:4b-fp16": "8.1GB",
+	"qwen3:8b-q8_0": "8.9GB",
+	"qwen3:8b-fp16": "16GB",
+	"qwen3:14b-q8_0": "16GB",
+	"qwen3:14b-fp16": "30GB",
+	"qwen3:30b-a3b-instruct-2507-q4_K_M": "19GB",
+	"qwen3:30b-a3b-instruct-2507-q8_0": "32GB",
+	"qwen3:30b-a3b-instruct-2507-fp16": "61GB",
+	"qwen3:30b-a3b-q8_0": "33GB",
+	"qwen3:30b-a3b-fp16": "61GB",
+	"qwen3:32b-q8_0": "35GB",
+	"qwen3:32b-fp16": "66GB",
+	"qwen3:235b-a22b-instruct-2507-q4_K_M": "142GB",
+	"qwen3:235b-a22b-instruct-2507-q8_0": "250GB",
+	"qwen3:235b-a22b-q8_0": "250GB",
+	"qwen3:235b-a22b-fp16": "470GB",
+	"qwq:32b": "20GB",
+	"qwq:32b-preview-fp16": "66GB",
+	"qwq:32b-preview-q8_0": "35GB",
+	"r1-1776:70b": "43GB",
+	"r1-1776:70b-distill-llama-fp16": "141GB",
+	"r1-1776:70b-distill-llama-q8_0": "75GB",
+	"r1-1776:671b": "404GB",
+	"r1-1776:671b-fp16": "1.3TB",
+	"r1-1776:671b-q8_0": "713GB",
+	"reader-lm:0.5b": "352MB",
+	"reader-lm:1.5b": "935MB",
+	"reader-lm:0.5b-q5_1": "419MB",
+	"reader-lm:1.5b-q5_1": "1.2GB",
+	"reader-lm:0.5b-q6_K": "506MB",
+	"reader-lm:1.5b-q6_K": "1.3GB",
+	"reader-lm:0.5b-q8_0": "531MB",
+	"reader-lm:1.5b-q8_0": "1.6GB",
+	"reader-lm:0.5b-fp16": "994MB",
+	"reader-lm:1.5b-fp16": "3.1GB",
+//	"reefer/erplegend": "4.7GB",
+	"reefer/her2": "4.7GB",
+	"reefer/minimonica": "2.1GB",
+	"reefer/monica": "4.7GB",
+//	"reefer/monicacodestral22b": "8.3GB",
+//	"reefer/monicamaxlvl": "4.7GB",
+//	"reefer/reefloaded": "4.9GB",
+//	"reefer/erphermesl3": "6.6",
+//	"reefer/reefproherm2llama3instruct": "5.7GB",
+	"reflection:70b": "40GB",
+	"reflection:70b-q6_K": "58GB",
+	"reflection:70b-q8_0": "75GB",
+	"reflection:70b-fp16": "141GB",
+	"rfc/whiterabbitneo": "7.4GB",
+	"rouge/replete-coder-qwen2-1.5b:latest": "6.2GB",
+	"rouge/replete-coder-qwen2-1.5b:Q8": "1.9GB",
+	"rouge/replete-coder-qwen2-1.5b:f16": "3.1GB",
+	"sailor2:1b": "1.1GB",
+	"sailor2:8b": "5.2GB",
+	"sailor2:20b": "12GB",
+	"sailor2:1b-chat-fp16": "2.0GB",
+	"sailor2:1b-chat-q8_0": "1.1GB",
+	"sailor2:8b-chat-fp16": "17GB",
+	"sailor2:8b-chat-q8_0": "9.1GB",
+	"sailor2:20b-chat-fp16": "38GB",
+	"sailor2:20b-chat-q8_0": "20GB",
+	"samantha-mistral:7b": "4.1GB",
+	"samantha-mistral:7b-text": "4.1GB",
+	"samantha-mistral:7b-v1.2-text": "4.1GB",
+	"samantha-mistral:7b-instruct-q8_0": "7.7GB",
+	"samantha-mistral:7b-text-q8_0": "7.7GB",
+	"samantha-mistral:7b-v1.2-text-q8_0": "7.7GB",
+	"samantha-mistral:7b-instruct-fp16": "14GB",
+	"samantha-mistral:7b-text-fp16": "14GB",
+	"samantha-mistral:7b-v1.2-text-fp16": "14GB",
+	"sammcj/smaug-mixtral-v0.1:70b-q4_k_m": "28GB",
+	"sammcj/smaug-mixtral-v0.1:8x7b-70b-q4_k_m": "28GB",
+	"savethedoctor/whiterabbitneo13bq8_0": "14GB",
+	"shieldgemma:2b": "1.7GB",
+	"shieldgemma:9b": "5.8GB",
+	"shieldgemma:27b": "17GB",
+	"shieldgemma:2b-fp16": "5.2GB",
+	"shieldgemma:9b-fp16": "18GB",
+	"shieldgemma:27b-fp16": "54GB",
+	"smallthinker:3b": "3.6GB",
+	"smallthinker:3b-preview-fp16": "6.8GB",
+	"smallthinker:3b-preview-q8_0": "3.6GB",
+	"smollm:135m": "92MB",
+	"smollm:360m": "229MB",
+	"smollm:1.7b": "991MB",
+	"smollm:135m-base-v0.2-fp16": "271MB",
+	"smollm:135m-base-v0.2-q4_0": "92MB",
+	"smollm:135m-base-v0.2-q4_1": "98MB",
+	"smollm:135m-base-v0.2-q4_K_S": "102MB",
+	"smollm:135m-base-v0.2-q4_K_M": "105MB",
+	"smollm:135m-base-v0.2-q5_0": "105MB",
+	"smollm:135m-base-v0.2-q5_1": "112MB",
+	"smollm:135m-base-v0.2-q5_K_S": "110MB",
+	"smollm:135m-base-v0.2-q5_K_M": "112MB",
+	"smollm:135m-base-v0.2-q6_K": "138MB",
+	"smollm:135m-base-v0.2-q6_0": "145MB",
+	"smollm:135m-instruct-v0.2-fp16": "271MB",
+	"smollm:135m-instruct-v0.2-q4_0": "92MB",
+	"smollm:135m-instruct-v0.2-q4_1": "98MB",
+	"smollm:135m-instruct-v0.2-q4_K_S": "102MB",
+	"smollm:135m-instruct-v0.2-q4_K_M": "105MB",
+	"smollm:135m-instruct-v0.2-q5_0": "105MB",
+	"smollm:135m-instruct-v0.2-q5_1": "112MB",
+	"smollm:135m-instruct-v0.2-q5_K_S": "110MB",
+	"smollm:135m-instruct-v0.2-q5_K_M": "112MB",
+	"smollm:135m-instruct-v0.2-q6_K": "138MB",
+	"smollm:135m-instruct-v0.2-q8_0": "145MB",
+	"smollm:360m-base-v0.2-fp16": "726MB",
+	"smollm:360m-base-v0.2-q4_0": "229MB",
+	"smollm:360m-base-v0.2-q4_1": "249MB",
+	"smollm:360m-base-v0.2-q4_K_S": "260MB",
+	"smollm:360m-base-v0.2-q4_K_M": "271MB",
+	"smollm:360m-base-v0.2-q5_0": "268MB",
+	"smollm:360m-base-v0.2-q5_1": "288MB",
+	"smollm:360m-base-v0.2-q5_K_S": "283MB",
+	"smollm:360m-base-v0.2-q5_K_M": "290MB",
+	"smollm:360m-base-v0.2-q6_K": "367MB",
+	"smollm:360m-base-v0.2-q8_K": "386MB",
+	"smollm:360m-instruct-v0.2-fp16": "726MB",
+	"smollm:360m-instruct-v0.2-q4_0": "229MB",
+	"smollm:360m-instruct-v0.2-q4_1": "249MB",
+	"smollm:360m-instruct-v0.2-q4_K_S": "260MB",
+	"smollm:360m-instruct-v0.2-q4_K_M": "271MB",
+	"smollm:360m-instruct-v0.2-q5_0": "268MB",
+	"smollm:360m-instruct-v0.2-q5_1": "288MB",
+	"smollm:360m-instruct-v0.2-q5_K_S": "283MB",
+	"smollm:360m-instruct-v0.2-q5_K_M": "290MB",
+	"smollm:360m-instruct-v0.2-q6_K": "367MB",
+	"smollm:360m-instruct-v0.2-q8_0": "386MB",
+	"smollm:1.7b-base-v0.2-fp16": "3.4GB",
+	"smollm:1.7b-base-v0.2-q4_0": "991MB",
+	"smollm:1.7b-base-v0.2-q4_1": "1.1GB",
+	"smollm:1.7b-base-v0.2-q4_K_S": "999MB",
+	"smollm:1.7b-base-v0.2-q4_K_M": "1.1GB",
+	"smollm:1.7b-base-v0.2-q5_0": "1.2GB",
+	"smollm:1.7b-base-v0.2-q5_1": "1.3GB",
+	"smollm:1.7b-base-v0.2-q5_K_S": "1.2GB",
+	"smollm:1.7b-base-v0.2-q5_K_M": "1.2GB",
+	"smollm:1.7b-base-v0.2-q6_K": "1.4GB",
+	"smollm:1.7b-base-v0.2-q8_K": "1.8GB",
+	"smollm:1.7b-instruct-v0.2-fp16": "3.4GB",
+	"smollm:1.7b-instruct-v0.2-q4_0": "991MB",
+	"smollm:1.7b-instruct-v0.2-q4_1": "1.1GB",
+	"smollm:1.7b-instruct-v0.2-q4_K_S": "999MB",
+	"smollm:1.7b-instruct-v0.2-q4_K_M": "1.1GB",
+	"smollm:1.7b-instruct-v0.2-q5_0": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q5_1": "1.3GB",
+	"smollm:1.7b-instruct-v0.2-q5_K_S": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q5_K_M": "1.2GB",
+	"smollm:1.7b-instruct-v0.2-q6_K": "1.4GB",
+	"smollm:1.7b-instruct-v0.2-q8_K": "1.8GB",
+	"snowflake-arctic-embed:22m": "46MB",
+	"snowflake-arctic-embed:33m": "67MB",
+	"snowflake-arctic-embed:110m": "219MB",
+	"snowflake-arctic-embed:137m": "274MB",
+	"snowflake-arctic-embed:335m": "669MB",
+	"snowflake-arctic-embed:l": "669MB",
+	"snowflake-arctic-embed:m": "219MB",
+	"snowflake-arctic-embed:m-long": "274MB",
+	"snowflake-arctic-embed:s": "67MB",
+	"snowflake-arctic-embed:xs": "46MB",
+	"snowflake-arctic-embed:22m-xs-fp16": "46MB",
+	"snowflake-arctic-embed:33m-s-fp16": "67MB",
+	"snowflake-arctic-embed:110m-m-fp16": "219MB",
+	"snowflake-arctic-embed:137m-m-long-fp16": "274MB",
+	"snowflake-arctic-embed:335m-l-fp16": "669MB",
+	"snowflake-arctic-embed2:568m": "1.2GB",
+	"snowflake-arctic-embed2:568m-l-fp16": "1.2GB",
+	"solar:10.7b": "6.1GB",
+	"solar:10.7b-instruct-v1-q5_0": "7.4GB",
+	"solar:10.7b-text-v1-q5_0": "7.4GB",
+	"solar:10.7b-instruct-v1-q8_0": "11GB",
+	"solar:10.7b-text-v1-q8_0": "11GB",
+	"solar:10.7b-instruct-v1-fp16": "21GB",
+	"solar:10.7b-text-v1-fp16": "21GB",
+	"solar-pro:22b": "13GB",
+	"solar-pro:preview": "13GB",
+	"solar-pro:22b-preview-instruct-q5_K_S": "15GB",
+	"solar-pro:22b-preview-instruct-q5_K_M": "16GB",
+	"solar-pro:22b-preview-instruct-q8_0": "24GB",
+	"solar-pro:22b-preview-instruct-fp16": "44GB",
+	"sparksammy/samantha": "3.8GB",
+	"sparksammy/samantha-3.1": "4.7GB",
+	"sparksammy/samantha-eggplant": "11GB",
+	"sparksammy/samantha-v3-uncensored": "4.7GB",
+	"sparksammy/tinysam-goog": "1.7GB",
+	"sparksammy/tinysam-msft": "2.3GB",
+	"sqlcoder:7b": "4.1GB",
+	"sqlcoder:15b": "9GB",
+	"sqlcoder:7b-q8_0": "7.7GB",
+	"sqlcoder:15b-q6_K": "13GB",
+	"sqlcoder:70b-alpha-q6_K": "57GB",
+	"sqlcoder:7b-fp16": "14GB",
+	"sqlcoder:15b-fp16": "32GB",
+	"sqlcoder:70b-alpha-fp16": "138GB",
+	"stable-beluga:7b": "3.8GB",
+	"stable-beluga:13b": "7.4GB",
+	"stable-beluga:70b": "39GB",
+	"stable-beluga:7b-q8_0": "7.2GB",
+	"stable-beluga:13b-q8_0": "14GB",
+	"stable-beluga:70b-q6_K": "57GB",
+	"stable-beluga:70b-q8_0": "73GB",
+	"stable-beluga:7b-fp16": "13GB",
+	"stable-beluga:13b-fp16": "26GB",
+	"stable-beluga:70b-fp16": "138GB",
+	"stable-code:3b": "1.6GB",
+	"stable-code:code": "1.6GB",
+	"stable-code:instruct": "1.6GB",
+	"stable-code:3b-code": "1.6GB",
+	"stable-code:3b-instruct": "1.6GB",
+	"stable-code:3b-code-q5_0": "1.9GB",
+	"stable-code:3b-instruct-q5_0": "1.9GB",
+	"stable-code:3b-code-q5_1": "2.1GB",
+	"stable-code:3b-instruct-q5_1": "2.1GB",
+	"stable-code:3b-code-q6_K": "2.3GB",
+	"stable-code:3b-instruct-q6_K": "2.3GB",
+	"stable-code:3b-code-q8_0": "3.0GB",
+	"stable-code:3b-instruct-q8_0": "3.0GB",
+	"stable-code:3b-code-fp16": "5.6GB",
+	"stable-code:3b-instruct-fp16": "5.6GB",
+	"stablelm-zephyr:3b": "1.6GB",
+	"stablelm-zephyr:3b-q5_0": "1.9GB",
+	"stablelm-zephyr:3b-q5_1": "2.1GB",
+	"stablelm-zephyr:3b-q8_0": "3.0GB",
+	"stablelm-zephyr:3b-fp16": "5.6GB",
+	"stablelm2:1.6b": "983MB",
+	"stablelm2:12b": "7.0GB",
+	"stablelm2:chat": "983MB",
+	"stablelm2:zephyr": "983MB",
+	"stablelm2:1.6b-chat": "983MB",
+	"stablelm2:1.6b-zephyr": "983MB",
+	"stablelm2:12b-chat": "7.0GB",
+	"stablelm2:12b-zephyr": "7.0GB",
+	"stablelm2:1.6b-q8_0": "1.8GB",
+	"stablelm2:12b-q8_0": "13GB",
+	"stablelm2:1.6b-chat-q8_0": "1.8GB",
+	"stablelm2:1.6b-zephyr-q8_0": "1.8GB",
+	"stablelm2:12b-chat-q8_0": "13GB",
+	"stablelm2:1.6b-fp16": "3.3GB",
+	"stablelm2:12b-fp16": "24GB",
+	"stablelm2:1.6b-chat-fp16": "3.3GB",
+	"stablelm2:1.6b-zephyr-fp16": "3.3GB",
+	"stablelm2:12b-chat-fp16": "24GB",
+	"starcoder:1b": "726MB",
+	"starcoder:3b": "1.8GB",
+	"starcoder:7b": "4.3GB",
+	"starcoder:15b": "9.0GB",
+	"starcoder:1b-base": "726MB",
+	"starcoder:3b-base": "1.8GB",
+	"starcoder:7b-base": "4.3GB",
+	"starcoder:15b-base": "9.0GB",
+	"starcoder:15b-plus": "9.0GB",
+	"starcoder:15b-q6_K": "13GB",
+	"starcoder:15b-q8_0": "17GB",
+	"starcoder:1b-base-q8_0": "1.3GB",
+	"starcoder:3b-base-q8_0": "3.4GB",
+	"starcoder:7b-base-q8_0": "8GB",
+	"starcoder:15b-base-q6_K": "13GB",
+	"starcoder:15b-plus-q6_K": "13GB",
+	"starcoder:15b-base-q8_0": "17GB",
+	"starcoder:15b-plus-q8_0": "17GB",
+	"starcoder:15b-fp16": "32GB",
+	"starcoder:1b-base-fp16": "2.5GB",
+	"starcoder:3b-base-fp16": "6.4GB",
+	"starcoder:7b-base-fp16": "15GB",
+	"starcoder:15b-base-fp16": "32GB",
+	"starcoder:15b-plus-fp16": "32GB",
+	"starcoder2:3b": "1.7GB",
+	"starcoder2:7b": "4.0GB",
+	"starcoder2:15b": "9.1GB",
+	"starcoder2:instruct": "9.1GB",
+	"starcoder2:15b-instruct": "9.1GB",
+	"starcoder2:3b-q8_0": "3.2GB",
+	"starcoder2:7b-q8_0": "7.6GB",
+	"starcoder2:15b-q6_K": "13GB",
+	"starcoder2:15b-q8_0": "17GB",
+	"starcoder2:15b-instruct-v0.1-q6_K": "13GB",
+	"starcoder2:15b-instruct-v0.1-q8_0": "17GB",
+	"starcoder2:15b-instruct-v0.1-fp16": "32GB",
+	"starling-lm:7b": "4.1GB",
+	"starling-lm:alpha": "4.1GB",
+	"starling-lm:beta": "4.1GB",
+	"starling-lm:7b-alpha": "4.1GB",
+	"starling-lm:7b-beta": "4.1GB",
+	"starling-lm:7b-alpha-q8_0": "7.7GB",
+	"starling-lm:7b-beta-q8_0": "7.7GB",
+	"starling-lm:7b-alpha-fp16": "14GB",
+	"starling-lm:7b-beta-fp16": "14GB",
+	"themanofrod/travel-agent": "1.7GB",
+	"tinydolphin:1.1b": "637MB",
+	"tinydolphin:v2.8": "637MB",
+	"tinydolphin:1.1b-v2.8-fp16": "2.2GB",
+	"tinydolphin:1.1b-v2.8-q4_0": "637MB",
+	"tinydolphin:1.1b-v2.8-q4_1": "701MB",
+	"tinydolphin:1.1b-v2.8-q4_K_S": "640MB",
+	"tinydolphin:1.1b-v2.8-q4_K_M": "668MB",
+	"tinydolphin:1.1b-v2.8-q5_0": "766MB",
+	"tinydolphin:1.1b-v2.8-q5_1": "831MB",
+	"tinydolphin:1.1b-v2.8-q5_K_S": "766MB",
+	"tinydolphin:1.1b-v2.8-q5_K_M": "782MB",
+	"tinydolphin:1.1b-v2.8-q6_K": "903MB",
+	"tinydolphin:1.1b-v2.8-q8_0": "1.2GB",
+	"tinyllama:1.1b": "638MB",
+	"tinyllama:chat": "638MB",
+	"tinyllama:v0.6": "638MB",
+	"tinyllama:v1": "638MB",
+	"tinyllama:1.1b-chat": "638MB",
+	"tinyllama:1.1b-chat-v0.6-q4_0": "638MB",
+	"tinyllama:1.1b-chat-v0.6-q4_1": "702MB",
+	"tinyllama:1.1b-chat-v0.6-q4_K_S": "644MB",
+	"tinyllama:1.1b-chat-v0.6-q4_K_M": "669MB",
+	"tinyllama:1.1b-chat-v0.6-q5_0": "767MB",
+	"tinyllama:1.1b-chat-v0.6-q5_1": "832MB",
+	"tinyllama:1.1b-chat-v0.6-q5_K_S": "767MB",
+	"tinyllama:1.1b-chat-v0.6-q5_K_M": "783MB",
+	"tinyllama:1.1b-chat-v0.6-q6_K": "904MB",
+	"tinyllama:1.1b-chat-v0.6-q8_0": "1.2GB",
+	"tinyllama:1.1b-chat-v1-fp16": "2.2GB",
+	"tinyllama:1.1b-chat-v1-q4_0": "638MB",
+	"tinyllama:1.1b-chat-v1-q4_1": "702MB",
+	"tinyllama:1.1b-chat-v1-q4_K_S": "644MB",
+	"tinyllama:1.1b-chat-v1-q4_K_M": "669MB",
+	"tinyllama:1.1b-chat-v1-q5_0": "767MB",
+	"tinyllama:1.1b-chat-v1-q5_1": "832MB",
+	"tinyllama:1.1b-chat-v1-q5_K_S": "767MB",
+	"tinyllama:1.1b-chat-v1-q5_K_M": "783MB",
+	"tinyllama:1.1b-chat-v1-q6_K": "904MB",
+	"tinyllama:1.1b-chat-v1-q8_0": "1.2GB",
+	"tulu3:8b": "4.9GB",
+	"tulu3:70b": "43GB",
+	"tulu3:70b-q8_0": "75GB",
+	"tulu3:70b-fp16": "141GB",
+	"tulu3:8b-q8_0": "8.5GB",
+	"tulu3:8b-fp16": "16GB",
+	"vicuna:7b": "3.8GB",
+	"vicuna:13b": "7.4GB",
+	"vicuna:33b": "18GB",
+	"vicuna:7b-16k": "3.8GB",
+	"vicuna:13b-16k": "7.4GB",
+	"vicuna:33b-16k": "18GB",
+	"vicuna:7b-q6_K": "5.5GB",
+	"vicuna:13b-q6_K": "11GB",
+	"vicuna:33b-q6_K": "27GB",
+	"vicuna:7b-v1.5-q6_K": "5.5GB",
+	"vicuna:7b-v1.5-16k-q6_K": "5.5GB",
+	"vicuna:13b-16k-q6_K": "11GB",
+	"vicuna:13b-v1.5-16k-q6_K": "11GB",
+	"vicuna:7b-q8_0": "7.2GB",
+	"vicuna:13b-q8_0": "14GB",
+	"vicuna:33b-q8_0": "35GB",
+	"vicuna:7b-v1.5-q8_0": "7.2GB",
+	"vicuna:7b-v1.5-16k-q8_0": "7.2GB",
+	"vicuna:13b-16k-q8_0": "14GB",
+	"vicuna:13b-v1.5-16k-q8_0": "14GB",
+	"vicuna:7b-fp16": "13GB",
+	"vicuna:13b-fp16": "26GB",
+	"vicuna:33b-fp16": "65GB",
+	"vicuna:7b-v1.5-fp16": "13GB",
+	"vicuna:7b-v1.5-16k-fp16": "13GB",
+	"vicuna:13b-16k-fp16": "26GB",
+	"vicuna:13b-v1.5-16k-fp16": "26GB",
+	"wizard-math:7b": "4.1GB",
+	"wizard-math:13b": "7.4GB",
+	"wizard-math:70b": "39GB",
+	"wizard-math:7b-q6_K": "5.5GB",
+	"wizard-math:13b-q6_K": "11GB",
+	"wizard-math:70b-q6_K": "57GB",
+	"wizard-math:7b-v1.1-q6_K": "5.9GB",
+	"wizard-math:7b-q8_0": "7.2GB",
+	"wizard-math:13b-q8_0": "14GB",
+	"wizard-math:70b-q8_0": "73GB",
+	"wizard-math:7b-v1.1-q8_0": "7.7GB",
+	"wizard-math:7b-fp16": "13GB",
+	"wizard-math:13b-fp16": "26GB",
+	"wizard-math:70b-fp16": "138GB",
+	"wizard-math:7b-v1.1-fp16": "14GB",
+	"wizard-vicuna:13b": "7.4GB",
+	"wizard-vicuna:13b-q8_0": "14GB",
+	"wizard-vicuna:13b-fp16": "26GB",
+	"wizard-vicuna-uncensored:7b": "3.8GB",
+	"wizard-vicuna-uncensored:13b": "7.4GB",
+	"wizard-vicuna-uncensored:30b": "18GB",
+	"wizard-vicuna-uncensored:7b-q8_0": "7.2GB",
+	"wizard-vicuna-uncensored:13b-q8_0": "14GB",
+	"wizard-vicuna-uncensored:30b-q6_K": "27GB",
+	"wizard-vicuna-uncensored:30b-q8_0": "35GB",
+	"wizard-vicuna-uncensored:7b-fp16": "13GB",
+	"wizard-vicuna-uncensored:13b-fp16": "26GB",
+	"wizard-vicuna-uncensored:30b-fp16": "65GB",
+	"wizardcoder:33b": "19GB",
+	"wizardcoder:python": "3.8GB",
+	"wizardcoder:7b-python": "3.8GB",
+	"wizardcoder:13b-python": "7.4GB",
+	"wizardcoder:33b-v1.1": "19GB",
+	"wizardcoder:33b-python": "19GB",
+	"wizardcoder:7b-python-q6_K": "5.5GB",
+	"wizardcoder:13b-python-q6_K": "11GB",
+	"wizardcoder:33b-v1.1-q6_K": "27GB",
+	"wizardcoder:34b-python-q6_K": "28GB",
+	"wizardcoder:7b-python-q8_0": "7.2GB",
+	"wizardcoder:13b-python-q8_0": "14GB",
+	"wizardcoder:33b-v1.1-q8_0": "35GB",
+	"wizardcoder:34b-python-q8_0": "36GB",
+	"wizardcoder:7b-python-fp16": "13GB",
+	"wizardcoder:13b-python-fp16": "26GB",
+	"wizardcoder:33b-v1.1-fp16": "67GB",
+	"wizardcoder:34b-python-fp16": "67GB",
+	"wizardlm-uncensored:13b": "7.4GB",
+	"wizardlm-uncensored:13b-llama2": "7.4GB",
+	"wizardlm-uncensored:13b-llama2-q8_0": "14GB",
+	"wizardlm-uncensored:13b-llama2-fp16": "26GB",
+	"wizardlm:7b-q4_0": "3.8GB",
+	"wizardlm:13b-q4_0": "7.4GB",
+	"wizardlm:30b-q4_0": "18GB",
+	"wizardlm:13b-llama2-q4_0": "39GB",
+	"wizardlm:7b-q6_K": "5.5GB",
+	"wizardlm:13b-q6_K": "11GB",
+	"wizardlm:30b-q6_K": "27GB",
+	"wizardlm:13b-llama2-q6_K": "57GB",
+	"wizardlm:7b-q8_0": "7.2GB",
+	"wizardlm:13b-q8_0": "14GB",
+	"wizardlm:30b-q8_0": "35GB",
+	"wizardlm:13b-llama2-q8_0": "73GB",
+	"wizardlm:7b-fp16": "13GB",
+	"wizardlm:13b-fp16": "26GB",
+	"wizardlm:30b-fp16": "65GB",
+	"wizardlm:13b-llama2-fp16": "26GB",
+	"wizardlm2:7b": "4.1GB",
+	"wizardlm2:8x22b": "80GB",
+	"wizardlm2:7b-q8_0": "7.7GB",
+	"wizardlm2:7b-fp16": "14GB",
+	"wizardlm2:8x22b-q8_0": "149GB",
+	"wizardlm2:8x22b-fp16": "281GB",
+	"xwinlm:7b": "3.8GB",
+	"xwinlm:13b": "7.4GB",
+	"xwinlm:7b-v0.1": "3.8GB",
+	"xwinlm:7b-v0.2": "3.8GB",
+	"xwinlm:13b-v0.1": "7.4GB",
+	"xwinlm:13b-v0.2": "7.4GB",
+	"xwinlm:70b-v0.1": "39GB",
+	"xwinlm:7b-v0.1-q6_K": "5.5GB",
+	"xwinlm:7b-v0.2-q6_K": "5.5GB",
+	"xwinlm:13b-v0.1-q6_K": "11GB",
+	"xwinlm:13b-v0.2-q6_K": "11GB",
+	"xwinlm:70b-v0.1-q6_K": "57GB",
+	"xwinlm:7b-v0.1-q8_0": "7.2GB",
+	"xwinlm:7b-v0.2-q8_0": "7.2GB",
+	"xwinlm:13b-v0.1-q8_0": "14GB",
+	"xwinlm:13b-v0.2-q8_0": "14GB",
+	"xwinlm:70b-v0.1-q8_0": "73GB",
+	"xwinlm:7b-v0.1-fp16": "13GB",
+	"xwinlm:7b-v0.2-fp16": "13GB",
+	"xwinlm:13b-v0.1-fp16": "26GB",
+	"xwinlm:13b-v0.2-fp16": "26GB",
+	"xwinlm:70b-v0.1-fp16": "138GB",
+	"yarn-llama2:7b": "3.8GB",
+	"yarn-llama2:13b": "7.4GB",
+	"yarn-llama2:7b-128k": "3.8GB",
+	"yarn-llama2:7b-64k": "3.8GB",
+	"yarn-llama2:13b-128k": "7.4GB",
+	"yarn-llama2:13b-64k": "7.4GB",
+	"yarn-llama2:7b-128k-q8_0": "7.2GB",
+	"yarn-llama2:7b-64k-q8_0": "7.2GB",
+	"yarn-llama2:13b-128k-q8_0": "14GB",
+	"yarn-llama2:13b-64k-q8_0": "14GB",
+	"yarn-llama2:7b-128k-fp16": "13GB",
+	"yarn-llama2:7b-64k-fp16": "13GB",
+	"yarn-llama2:13b-128k-fp16": "26GB",
+	"yarn-llama2:13b-64k-fp16": "26GB",
+	"yarn-mistral:7b": "4.1GB",
+	"yarn-mistral:7b-128k": "4.1GB",
+	"yarn-mistral:7b-64k": "4.1GB",
+	"yarn-mistral:7b-128k-q8_0": "7.7GB",
+	"yarn-mistral:7b-64k-q8_0": "7.7GB",
+	"yarn-mistral:7b-128k-fp16": "14GB",
+	//"yarn-mistral:7b-64k-fp16": "GB",
+	"yi:6b": "3.5GB",
+	"yi:9b": "5.0GB",
+	"yi:34b": "19GB",
+	"yi:v1.5": "3.5GB",
+	"yi:6b-200k": "3.5GB",
+	"yi:6b-chat": "3.5GB",
+	"yi:6b-v1.5": "3.5GB",
+	"yi:9b-chat": "5.0GB",
+	"yi:9b-v1.5": "5.0GB",
+	"yi:34b-chat": "19GB",
+	"yi:34b-v1.5": "19GB",
+	"yi:6b-q6_K": "5.0GB",
+	"yi:6b-200k-q6_K": "5.0GB",
+	"yi:6b-chat-q6_K": "5.0GB",
+	"yi:6b-chat-v1.5-q6_K": "5.0GB",
+	"yi:6b-v1.5-q6_K": "5.0GB",
+	"yi:9b-chat-q6_K": "7.2GB",
+	"yi:9b-v1.5-q6_K": "7.2GB",
+	"yi:34b-chat-q6_K": "28GB",
+	"yi:34b-chat-v1.5-q6_K": "28GB",
+	"yi:34b-v1.5-q6_K": "28GB",
+	"yi:6b-q8_0": "6.4GB",
+	"yi:6b-200k-q8_0": "6.4GB",
+	"yi:6b-chat-q8_0": "6.4GB",
+	"yi:6b-chat-v1.5-q8_0": "6.4GB",
+	"yi:6b-v1.5-q8_0": "6.4GB",
+	"yi:9b-chat-q8_0": "9.4GB",
+	"yi:9b-v1.5-q8_0": "9.4GB",
+	"yi:34b-chat-q8_0": "37GB",
+	"yi:34b-chat-v1.5-q8_0": "37GB",
+	"yi:34b-v1.5-q8_0": "37GB",
+	"yi:6b-fp16": "12GB",
+	"yi:6b-200k-fp16": "12GB",
+	"yi:6b-chat-fp16": "12GB",
+	"yi:6b-chat-v1.5-fp16": "12GB",
+	"yi:6b-v1.5-fp16": "12GB",
+	"yi:9b-chat-fp16": "18GB",
+	"yi:9b-v1.5-fp16": "18GB",
+	"yi:34b-chat-fp16": "69GB",
+	"yi:34b-chat-v1.5-fp16": "69GB",
+	"yi:34b-v1.5-fp16": "69GB",
+	"yi-coder:1.5b": "886MB",
+	"yi-coder:9b": "5.0GB",
+	"yi-coder:1.5b-base": "866MB",
+	"yi-coder:1.5b-chat": "866MB",
+	"yi-coder:9b-base": "5.0GB",
+	"yi-coder:9b-chat": "5.0GB",
+	"yi-coder:1.5b-base-q8_0": "1.6GB",
+	"yi-coder:1.5b-chat-q8_0": "1.6GB",
+	"yi-coder:9b-base-q6_K": "7.2GB",
+	"yi-coder:9b-chat-q6_K": "7.2GB",
+	"yi-coder:9b-base-q8_0": "9.4GB",
+	"yi-coder:9b-chat-q8_0": "9.4GB",
+	"yi-coder:1.5b-base-fp16": "3.0GB",
+	"yi-coder:1.5b-chat-fp16": "3.0GB",
+	"yi-coder:9b-base-fp16": "18GB",
+	"yi-coder:9b-chat-fp16": "18GB",
+	"zephyr:7b": "4.1GB",
+	"zephyr:141b": "80GB",
+	"zephyr:7b-alpha": "4.1GB",
+	"zephyr:7b-beta": "4.1GB",
+	"zephyr:141b-v0.1": "80GB",
+	"zephyr:7b-alpha-q8_0": "7.7GB",
+	"zephyr:7b-beta-q8_0": "7.7GB",
+	"zephyr:141b-v0.1-q8_0": "149GB",
+	"zephyr:7b-alpha-fp16": "14GB",
+	"zephyr:7b-beta-fp16": "14GB",
+	"zephyr:141b-v0.1-fp16": "281GB",
+}
+
+// oteodoro:  added section
+var whitelist = map[string]int{
+	"adens/quran-guide": 1,
+	"agcobra/liberated-qwen1.5-72b": 1,
+	"akx/viking-7b": 1,
+	"alfred": 1,
+	"ALIENTELLIGENCE/christiancounselor": 1,
+	"ALIENTELLIGENCE/crisisintervention": 1,
+	"ALIENTELLIGENCE/doomsdayurvivalist": 1,
+	"ALIENTELLIGENCE/enriquecastillorincon": 1,
+	"ALIENTELLIGENCE/gamemasterroleplaying": 1,
+	"ALIENTELLIGENCE/holybible": 1,
+	"ALIENTELLIGENCE/mentalwellness": 1,
+	"ALIENTELLIGENCE/prayerline": 1,
+	"ALIENTELLIGENCE/pcarchitect": 1,
+	"ALIENTELLIGENCE/sarah": 1,
+	"ALIENTELLIGENCE/sarahv2": 1,
+	"ALIENTELLIGENCE/whiterabbit": 1,
+	"ALIENTELLIGENCE/whiterabbitv2": 1,
+	"all-minilm": 1,
+	"Artalius/lixi": 1,
+	"artifish/mlewd-v2.4": 1,
+	"athene-v2": 1,
+	"aya": 1,
+	"aya-expanse": 1,
+	"bakllava": 1,
+	"bespoke-minicheck": 1,
+	"bge-large": 1,
+	"bge-m3": 1,
+	"benevolentjoker/belial": 1,
+	"benevolentjoker/bethanygpt": 1,
+	"benevolentjoker/nsfwmonika": 1,
+	"benevolentjoker/nsfwvanessa": 1,
+	"benevolentjoker/satan": 1,
+	"canadiangamer/neena": 1,
+	"canadiangamer/priya": 1,
+	"captainkyd/whiterabbitneo7b": 1,
+	"chatgph/70b-instruct": 1,
+	"chatgph/gph-main": 1,
+	"chatgph/medix-ph": 1,
+	"codebooga": 1,
+	"codegeex4": 1,
+	"codegemma": 1,
+	"codellama": 1,
+	"codeqwen": 1,
+	"codestral": 1,
+	"codeup": 1,
+	"command-a": 1,
+	"command-r": 1,
+	"command-r-plus": 1,
+	"command-r7b": 1,
+	"command-r7b-arabic": 1,
+	"dbrx": 1,
+	"disinfozone/telos": 1,
+	"deepcoder": 1,
+	"deepscaler": 1,
+	"deepseek-coder": 1,
+	"deepseek-coder-v2": 1,
+	"deepseek-llm": 1,
+	"deepseek-r1": 1,
+	"deepseek-v2": 1,
+	"deepseek-v2.5": 1,
+	"deepseek-v3": 1,
+	"dolphin-llama3": 1,
+	"dolphin-mistral": 1,
+	"dolphin-mixtral": 1,
+	"dolphin-phi": 1,
+	"dolphin3": 1,
+	"dolphincoder": 1,
+	"duckdb-nsql": 1,
+	"ehartford/theprofessor": 1,
+	"eramax/aura_v3": 1,
+	"exaone3.5": 1,
+	"everythinglm": 1,
+	"falcon": 1,
+	"falcon2": 1,
+	"falcon3": 1,
+	"firefunction-v2": 1,
+	"fixt/home-3b-v3": 1,
+	"fixt/home-3b-v2": 1,
+	"goliath": 1,
+	"gpt-oss": 1,
+	"granite-code": 1,
+	"granite-embedding": 1,
+	"granite3-dense": 1,
+	"granite3.1-dense": 1,
+	"granite3-guardian": 1,
+	"granite3-moe": 1,
+	"granite3.1-moe": 1,
+	"granite3.2-vision": 1,
+	"granite3.3": 1,
+	"hemanth/chessplayer": 1,
+	"hermes3": 1,
+	"hookingai/monah-8b": 1,
+	"internlm2": 1,
+	"jimscard/adult-film-screenwriter-nsfw": 1,
+	"jimscard/whiterabbit-neo": 1,
+	"joefamous/grok-1": 1,
+	"leeplenty/lumimaid-v0.2": 1,
+	"llama-guard3": 1,
+	"llama-pro": 1,
+	"llama2": 1,
+	"llama2-chinese": 1,
+	"llama2-uncensored": 1,
+	"llama3": 1,
+	"llama3-chatqa": 1,
+	"llama3-gradient": 1,
+	"llama3-groq-tool-use": 1,
+	"llama3.1": 1,
+	"llama3.2": 1,
+	"llama3.2-vision": 1,
+	"llama3.3": 1,
+	"llama4": 1,
+	"llava": 1,
+	"llava-llama3": 1,
+	"llava-phi3": 1,
+	"gemma": 1,
+	"gemma2": 1,
+	"gemma3": 1,
+	"glm4": 1,
+	"magicoder": 1,
+	"mannix/llamax3-8b-alpaca": 1,
+	"mannix/replete-adapted-llama3-8b": 1,
+	"mannix/replete-coder-llama3-8b": 1,
+	"mannix/smaug-qwen2-72b": 1,
+	"marco-o1": 1,
+	"mathstral": 1,
+	"meditron": 1,
+	"medllama2": 1,
+	"megadolphin": 1,
+	"minicpm-v": 1,
+	"mistral": 1,
+	"mistral-large": 1,
+	"mistral-nemo": 1,
+	"mistral-openorca": 1,
+	"mistral-small3.1": 1,
+	"mistral-small": 1,
+	"mistrallite": 1,
+	"mixtral": 1,
+	"moondream": 1,
+	"nqduc/gemsura": 1,
+	"nqduc/mixsura": 1,
+	"nqduc/mixsura-sft": 1,
+	"monotykamary/whiterabbitneo-v1.5a": 1,
+	"mxbai-embed-large": 1,
+	"nemotron": 1,
+	"nemotron-mini": 1,
+	"neural-chat": 1,
+	"nexusraven": 1,
+	"nomic-embed-text": 1,
+	"notus": 1,
+	"notux": 1,
+	"nous-hermes": 1,
+	"nous-hermes2": 1,
+	"nous-hermes2-mixtral": 1,
+	"nuextract": 1,
+	"olmo2": 1,
+	"open-orca-platypus2": 1,
+	"openchat": 1,
+	"opencoder": 1,
+	"openhermes": 1,
+	"openthinker": 1,
+	"orca-mini": 1,
+	"orca2": 1,
+	"paraphrase-multilingual": 1,
+	"partai/dorna-llama3": 1,
+	"phi": 1,
+	"phi3": 1,
+	"phi3.5": 1,
+	"phi4": 1,
+	"phi4-mini": 1,
+	"phind-codellama": 1,
+	"qwen": 1,
+	"qwen2": 1,
+	"qwen2-math": 1,
+	"qwen2.5": 1,
+	"qwen2.5-coder": 1,
+	"qwen3": 1,
+	"qwq": 1,
+	"r1-1776": 1,
+	"reader-lm": 1,
+	"reefer/her2": 1,
+	"reefer/minimonica": 1,
+	"reefer/monica": 1,
+	"reflection": 1,
+	"rfc/whiterabbitneo": 1,
+	"rouge/replete-coder-qwen2-1.5b": 1,
+	"sailor2": 1,
+	"samantha-mistral": 1,
+	"sammcj/smaug-mixtral-v0.1": 1,
+	"savethedoctor/whiterabbitneo13bq8_0": 1,
+	"shieldgemma": 1,
+	"smallthinker": 1,
+	"smollm": 1,
+	"snowflake-arctic-embed": 1,
+	"snowflake-arctic-embed2": 1,
+	"solar": 1,
+	"solar-pro": 1,
+	"sparksammy/samantha": 1,
+	"sparksammy/samantha-3.1": 1,
+	"sparksammy/samantha-eggplant": 1,
+	"sparksammy/samantha-v3-uncensored": 1,
+	"sparksammy/tinysam-goog": 1,
+	"sparksammy/tinysam-msft": 1,
+	"sqlcoder": 1,
+	"stable-beluga": 1,
+	"stable-code": 1,
+	"stablelm-zephyr": 1,
+	"stablelm2": 1,
+	"starcoder": 1,
+	"starcoder2": 1,
+	"starling-lm": 1,
+	"themanofrod/travel-agent": 1,
+	"tinydolphin": 1,
+	"tinyllama": 1,
+	"tulu3": 1,
+	"vicuna": 1,
+	"wizard-math": 1,
+	"wizard-vicuna": 1,
+	"wizard-vicuna-uncensored": 1,
+	"wizardcoder": 1,
+	"wizardlm": 1,
+	"wizardlm-uncensored": 1,
+	"wizardlm2": 1,
+	"xwinlm": 1,
+	"yarn-llama2": 1,
+	"yarn-mistral": 1,
+	"yi": 1,
+	"yi-coder": 1,
+	"zephyr": 1,
+}
+
+// oteodoro:  added --tags
+var tagsList = map[string]string{
+	// Quality control:
+	// It is preferred to drop languages or capabilities if they are below 70% score
+	// If without : variant, it assumes :latest.  The latest should again follow 70% score.
+	//
+	// Example:
+	// llama3.1 is the same as llama:3.1:3b and can list instruction-following because it is at or above 70% score.
+	// llama3.1:1b should not list instruction-following because it is 59.5% score.
+	//
+	// 70% is chosen because it a Grade C from grade school which is a passing grade.
+	"adens/quran-guide": "quran muslim islam allah",
+	"agcobra/liberated-qwen1.5-72b": "uncensored safety-off multilingual general-knowledge math-word-problems arabic french vietnamese korean japanese spanish indonesian portuguese russian",
+	"akx/viking-7b": "multilingual finnish english swedish danish norwegian icelandic coding code-generator",
+	"alfred": "chat comprehensive-response i-dont-know",
+	"ALIENTELLIGENCE/christiancounselor": "christian christianity protestant catholic eastern-orthodox western-church eastern-church theologist counselor philosopher spirituality mental-health marriage",
+	"ALIENTELLIGENCE/crisisintervention": "psychotherapist counselor mental-health male",
+	"ALIENTELLIGENCE/doomsdayurvivalist": "emergency catastrophies natural-disasters survival-skills multilingual",
+	"ALIENTELLIGENCE/enriquecastillorincon": "ufo chat ufo-investigator",
+	"ALIENTELLIGENCE/gamemasterroleplaying": "game-master game-design storyteller quest-maker game-mechanics gaming-industry",
+	"ALIENTELLIGENCE/mentalwellness": "mental-wellness mindfulness emotional-support safe-space",
+	"ALIENTELLIGENCE/pcarchitect": "computer-technician pc-build build-computer",
+	"ALIENTELLIGENCE/prayerline": "jesus jesus-of-nazareth prayer-line christian",
+	"ALIENTELLIGENCE/sarah": "ai-girlfriend girlfriend emojis",
+	"ALIENTELLIGENCE/sarahv2": "ai-girlfriend girlfriend emojis",
+	"ALIENTELLIGENCE/whiterabbit": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"ALIENTELLIGENCE/whiterabbitv2": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"all-minilm": "embedding",
+	"Artalius/lixi": "writer developer companion code-optimization fun-facts idea-generator wordsmith cloud-developer coding coding-assistant computer-science anime manga erotica nsfw japanese-alignment japanese-pop-culture uncensored gamer gamer-girl ai-girlfriend girlfriend funny",
+	"artifish/mlewd-v2.4": "nsfw adult-content",
+	"athene-v2": "chat coding code-completion math-word-problems log-extraction general-knowledge",
+	"aya": "multilingual arabic chinese czech dutch english french german greek hebrew hindi indonesian italian japanese korean persian polish portuguese romanian russian spanish turkish ukrainian vietnamese",
+	"aya-expanse": "text-generator tool-use qa multilingual arabic chinese-simplified chinese-traditional czech dutch english french german greek hebrew hebrew hindi indonesian italian japanese korean persian polish portuguese romanian russian spanish turkish ukrainian vietnamese",
+	"bakllava": "image-deconstruction image-describe image-to-text image-summary ocr optical-character-recognition",
+	"benevolentjoker/bethanygpt": "nsfw adult-content multiple-personalities",
+	"benevolentjoker/belial": "devil fiction dark-personality",
+	"benevolentjoker/nsfwmonika": "nsfw adult-content adult-fiction ai-girlfriend girlfriend",
+	"benevolentjoker/nsfwvanessa": "nsfw adult-content ai-girlfriend girlfriend",
+	"benevolentjoker/satan": "satan satanism devil occult qa religion",
+	"bespoke-minicheck": "fact-checking",
+	"canadiangamer/neena": "uncensored nsfw muscular adult-content",
+	"canadiangamer/priya": "ai-girlfriend girlfriend muscular india indian nsfw adult-content",
+	"bge-large": "embedding vector-database",
+	"bge-m3": "embedding multilingual low-memory-footprint",
+	"captainkyd/whiterabbitneo7b": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"chatgph/70b-instruct": "software-engineering system-optimization techonology filipino humor philippines pinoy coding code-review philippine-alignment tagalog cebuano illocano hiligayon cloud-developer",
+	"chatgph/gph-main": "software-engineering system-optimization technology filipino humor philippines pinoy tagalog illocano philippine-alignment",
+	"chatgph/medix-ph": "medical assistant healtcare philippines filipino",
+	"codebooga": "coding python",
+	"codegeex4": "coding code-generation code-completion",
+	"codegemma": "coding autocomplete coding-assistant fim fill-in-the-middle",
+	"codellama": "coding code-generation code-completion code-review unit-test-generator python fim fill-in-the-middle",
+	"codeqwen": "coding code-generation fixing-bugs",
+	"codestral": "coding code-generation solving-basic-programming-problems fim fill-in-the-middle unit-test-generator python",
+	"codeup": "coding code-generation",
+	"command-a": "conversational chatbot rag tool-use coding multilingual english french spanish italian german portuguese japanese korean arabic chinese russian polish turkish vietnamese dutch czech indonesian ukrainian romanian greek hindi hebrew persian",
+	"command-r": "rag tool-use english french spanish italian german brazilian portuguese japanese korean chinese arabic",
+	"command-r-plus": "rag tool-use enterprise english french spanish italian german brazilian portuguese japanese korean chinese arabic",
+	"command-r7b": "tool-use ai-applications for-gpus for-edge-devices reasoning qa coding rag  multilingual english french spanish italian german portuguese japanese korean arabic chinese russian polish turkish vietnamese dutch czech indonesian ukrainian romanian greek hindi hebrew persian",
+	"command-r7b-arabic": "rag middle-east northern-africa arabic instruction-following high-level-reasoning chain-of-thought multi-step-reasoning",
+	"dbrx": "coding code-generation math-word-problems general-purpose common-sense",
+	"deepcoder": "code-reasoning finetuned-deepseek-r1-distilled-qwen code-generation coding",
+	"deepscaler": "math-word-problems calculus statistics fine-tuned-deepseek-r1-distilled-qwen",
+	"deepseek-coder": "coding english chinese code-completion fim fill-in-the-middle python",
+	"deepseek-coder-v2": "coding code-completion code-insertion code-generator",
+	"deepseek-llm": "bilingual common-sense basic-reasoning trivia chinese english general-knowledge china-alignment china-bias",
+	"deepseek-r1": "math-word-problems graduate-level-stem general-knowledge calculus statistics china-alignment china-bias china-censorship",
+	"deepseek-v2": "bilinugual chinese english common-sense reasoning general-knowledge trivia math-word-problems china-alignment china-bias",
+	"deepseek-v2:236b": "bilinugual chinese english common-sense reasoning general-knowledge trivia math-word-problems china-alignment china-bias",
+	"deepseek-v2.5": "chat coding code-generator python common-sense reasoning instruction-following general-knowledge trivia math-word-problems chinese china-alignment china-bias",
+	"deepseek-v3": "general-knowledge trivia common-sense reasoning instruction-following coding code-generation python math-word-problems college-level-math graduate-level-stem stem calculus statistics chinese multilingual china-alignment china-bias",
+	"disinfozone/telos": "continental-philosophy philosophy conspiracy conspiracies creative-tasking funny wit witty",
+	"dolphin-llama3": "uncensored coding function-calling chat fine-tunable-alignment",
+	"dolphin-mistral": "uncensored coding function-calling chat fine-tunable-alignment",
+	"dolphin-mixtral": "uncensored coding chat function-calling fine-tunable-alignment game-design humor prank-suggestions confessions",
+	"dolphin-phi": "uncensored coding fine-tunable-alignment",
+	"dolphin3": "general-purpose coding math function-calling assistant",
+	"dolphincoder": "uncensored coding coding-assistant",
+	"duckdb-nsql": "coding sql",
+	"ehartford/theprofessor": "brainstorming research reasoning science medical math computer-science physics cosmology professor theoretical-explanations",
+	"eramax/aura_v3": "nsfw erotica roleplay",
+	"exaone3.5": "coding code-generation general-knowledge math-word-problems common-sense multilingual english korean",
+	"everythinglm": "uncensored detailed-replies story-telling",
+	"falcon": "llm-research",
+	"falcon2": "llm-research",
+	"falcon3": "science math coding",
+	"firefunction-v2": "chat instruction-following function-calling parsing",
+	"fixt/home-3b-v3": "home-assistant smart-home function-calling multilingual english german spanish french",
+	"fixt/home-3b-v2": "home-assistant smart-home function-calling",
+	"goliath": "detailed-response roleplay detailed-roleplay",
+	"gpt-oss": "reasoning function-calling fine-tuneable web-browsing python structure-output local-chat agentic-tasks general-knowledge graduate-level-reasoning",
+	"granite-code": "coding code-generation fixing-bugs documentation assistant fine-tunable",
+	"granite-embedding": "embeddings english",
+	"granite-embedding:30m": "embeddings english",
+	"granite-embedding:278m": "embeddings multilingual",
+	"granite3-dense": "summaries text-classification text-extraction qa rag code-related function-calling tool-use code-generation translation bug-fixing multilingual english german french japanese portuguese arabic czech italian korean dutch chinese simplified-chinese",
+	"granite3.1-dense": "tool-use rag summaries text-classification text-extraction qa code-related function-calling multilingual long-context english german spanish french japanese portuguese arabic czech italian korean dutch simplified-chinese",
+	"granite3-guardian": "security jailbreak-detection content-moderation guardrails nsfw-detection rag",
+	"granite3-moe": "low-latency summaries text-classification text-extraction qa rag code-related function-calling multilingual english german french japanese portuguese arabic czech italian korean dutch chinese simplified-chinese",
+	"granite3.1-moe": "low-latency long-context summaries text-classification text-extraction qa rag code-related function-calling multilingual english german spanish french japanese portuguese arabic czech italian korean dutch simplified-chinese",
+	"granite3.2-vision": "content-extraction vision-language-model documents tables charts plots diagrams document-understanding ocr optical-character-recognition document-qa",
+	"granite3.3": "reasoning instruction-following fill-in-the-middle coding summaries text-classification text-extraction qa rag long-context document-qa business business-apps multilingual english german spanish french japanese portuguese arabic czech italian korean dutch chinese",
+	"hemanth/chessplayer": "chess chess-player white-player ai-moves-first",
+	"hermes3": "roleplaying abstract-reasoning common-sense function-calling structured-output assistant code-generation",
+	"hookingai/monah-8b": "online-dating hook-up llm-trainer nsfw adult-content uncensored",
+	"internlm2": "tool-use word-math-problems",
+	"jimscard/adult-film-screenwriter-nsfw": "nsfw adult-content",
+	"jimscard/whiterabbit-neo": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"joefamous/grok-1": "chatbot general-knowledge",
+	"leeplenty/lumimaid-v0.2": "nsfw adult-content",
+	"llama-guard3": "content-moderation",
+	"llama-pro": "coding math common-sense",
+	"llama2": "multilingual chat",
+	"llama2-chinese": "chinese chat chinese-alignment chinese-bias",
+	"llama2-uncensored": "chat llm-criticism llm-testing creative-writing humor research",
+	"llama3": "chat math-word-problems",
+	"llama3:text": "abstract-reasoning",
+	"llama3:70b-text": "abstract-reasoning general-knowledge",
+	"llama3:70b-instruct": "chat math-word-problems coding code-completion python general-knowledge typescript",
+	"llama3-chatqa": "chat rag qa answering-questions",
+	"llama3-gradient": "assistant",
+	"llama3-groq-tool-use": "function-calling tool-use",
+	"llama3.1": "multilingual chat translation summaries coding coding-assistant general-knowledge",
+	"llama3.2": "multilingual chat instruction-following summaries english german french italian portuguese hindi spanish thai",
+	"llama3.2-vision": "multilingual chat instruction-following summaries vision ocr optical-character-recognition english english-only-vision german french italian portuguese hindi spanish thai",
+	"llama3.3": "general-knowledge instruction-following code-generation math-word-problems college-level-math calculus statistics tool-use multilingual english german french italian portuguese hindi spanish thai multilingual-commercial multilingual-research",
+	"llava": "ocr optical-character-recognition image-to-text chat chatbot ocr optical-character-recognition",
+	"llava-llama3": "image-to-text ocr optical-character-recognition",
+	"llava-phi3": "image-to-text ocr optical-character-recognition",
+	"gemma": "text-generation qa summaries common-sense programming-tutor answering-questions",
+	"gemma2": "chat content-generation summaries grammar-correction language-tutor trivia multilingual math-word-problems reasoning",
+	"gemma3": "chat content-generation summaries grammar-correction language-tutor trivia multilingual math-word-problems reasoning qa easy-reasoning physical-common-sense",
+	"gemma3:4b": "chat content-generation summaries grammar-correction language-tutor trivia multilingual math-word-problems reasoning qa document-qa easy-reasoning physical-common-sense yes-no-questions",
+	"gemma3:12b": "chat content-generation summaries grammar-correction language-tutor trivia multilingual math-word-problems reasoning qa document-qa easy-reasoning math-word-problems trivia physical-common-sense yes-no-questions",
+	"gemma3:27b": "chat content-generation summaries grammar-correction language-tutor trivia multilingual math-word-problems reasoning qa document-qa easy-reasoning challenging-reasoning math-word-problems triva physical-common-sense yes-no-questions multilingual-math chart-reasoning",
+	"glm4": "math-word-problems coding multilingual",
+	"glm4:9b-chat-q5_1": "math-word-problems coding chat function-calling comprehensive-response multilingual",
+	"glm4:9b-chat-q6_K": "math-word-problems coding chat function-calling comprehensive-response multilingual",
+	"glm4:9b-chat-q8_0": "math-word-problems coding chat function-calling comprehensive-response multilingual",
+	"glm4:9b-chat-fp16": "math-word-problems coding chat function-calling comprehensive-response multilingual",
+	"magicoder": "coding code-generation open-source-coding",
+	"mannix/llamax3-8b-alpaca": "multilingual intruction-following akrikaans amharic arabic armenian assamese asturian azerbaijani belarusian bengali bosnian bulgarian burmese catalan cebuano chinese simplified-chinese traditional-chinese croatian czech danish dutch english estonian filipino finnish french fulah galician ganda georgian german greek gujarati hausa hebrew hindi hungarian icelandic igbo indonesian irish italian japanese javanese kabuverdianu kamba kannada kazakh khmer korean kyrgyz lao latvian lingala lithuanian luo luxembourgish macedonian malay malayalam maltese maori marathi mongolian nepali northern sotho norwegian nyanja occitan oriya oromo pashto persian polish portuguese punjabi romanian russian serbian shona sindhi slovak slovenian somali sorani kurdish spanish swahili swedish tajik tamil telugu thai turkish ukrainian umbundu urdu uzbek vietnamese welsh wolof xhosa yoruba zulu",
+	"mannix/replete-adapted-llama3-8b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention low-end-hardware",
+	"mannix/replete-coder-llama3-8b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention",
+	"marco-o1": "open-ended-resolution open-ended-problem-solving chain-of-thought math-word-problems salesperson stem-standard-answers math physics coding",
+	"mathstral": "math-word-problems",
+	"meditron": "medical diseases health-information medical-exam qa",
+	"medllama2": "medical qa",
+	"megadolphin": "uncensored common-sense empathy advice detailed-reponse fine-tunable-alignment nsfw-content detailed-roleplay",
+	"minicpm-v": "text-to-speech ocr optical-character-recognition code-screenshot-bugfixes how-to-generator translating-screenshots translation",
+	"mistral": "multilingual function-calling fine-tuneable made-in-france european",
+	"mistral-large": "multilingual french german spanish italian dutch portuguese russian japanese chinese coding code-generation solving-basic-programming-problems math-word-problems function-calling json",
+	"mistral-nemo": "multilingual english french german spanish italian portuguese chinese korean arabic hindi common-sense trivia function-calling",
+	"mistral-openorca": "common-sense",
+	"mistral-small3.1": "translation summaries vision long-context multilingual english french german spanish italian chinese japanese korean portuguese dutch polish function-calling",
+	"mistral-small": "translation summaries multilingual english french german spanish italian chinese japanese korean portuguese dutch polish function-calling",
+	"mistrallite": "answering-long-questions qa common-sense",
+	"mixtral": "multilingual english french italian german spanish coding code-generation common-sense solving-basic-programming-problems math-word-problems trivia fine-tuneable",
+	"moondream": "picture-to-text qa image-deconstruction whats-that identify-in-picture",
+	"monotykamary/whiterabbitneo-v1.5a": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"mxbai-embed-large": "embeddings",
+	"nemotron": "training-data-generator llm-creation",
+	"nemotron-mini": "roleplay rag qa function-calling",
+	"neural-chat": "chat chatbot common-sense",
+	"nexusraven": "coding documentation python functional-programming",
+	"nomic-embed-text": "embedding",
+	"notus": "common-sense chat",
+	"notux": "multilingual english spanish italian german french common-sense general-knowledge",
+	"nous-hermes": "general-use creative-text instruction-following",
+	"nous-hermes2": "science coding code-assistant code-generator",
+	"nous-hermes2-mixtral": "fantasy-poems text-to-code-visualization coding code-generator code-assistant",
+	"nqduc/gemsura": "vietnamese vietnam-alignment vietnam-bias english text-generator qa summary classification translation coding code-generator reasoning",
+	"nqduc/mixsura": "vietnamese vietnam-alignment vietnam-bias english text-generator qa summary classification translation coding code-generator reasoning",
+	"nqduc/mixsura-sft": "vietnamese vietnam-alignment vietnam-bias english text-generator qa summary classification translation coding code-generator reasoning",
+	"nuextract": "structured-data-generation",
+	"olmo2": "common-sense reasoning trivia fully-open-model",
+	"open-orca-platypus2": "chat coding code-generation text-generation common-sense",
+	"openchat": "math-word-problems",
+	"opencoder": "coding code-generation multilingual chinese english",
+	"openhermes": "chat cooking-recipes coding-by-example college-level-response",
+	"openthinker": "math-word-problems calculus statistics fully-open-sourced deepseek-r1-distilled",
+	"openthinker:32b": "math-word-problems calculus statistics fully-open-sourced deepseek-r1-distilled",
+	"openthinker:7b": "math-word-problems calculus statistics fully-open-sourced deepseek-r1-distilled",
+	"orca-mini": "general-purpose writing-letters",
+	"orca2": "assistant summaries abstract-reasoning",
+	"paraphrase-multilingual": "embedding clustering semantic-search",
+	"partai/dorna-llama3": "persian assistant",
+	"phi": "chat street-directions coding code-generator code-competion text-completion qa answering-questions",
+	"phi3": "common-sense trivia english math logic math-word-problems solving-basic-programming-problems",
+	"phi3.5": "coding math logic teacher fact-check chat multilingual arabic chinese czech danish dutch english finnish french german hebrew hungarian italian japanese korean norwegian polish portuguese russian spanish swedish thai turkish ukrainian",
+	"phi4": "general-knowledge reasoning logic",
+	"phi4-mini": "abstract-reasoning qa math-word-problems physical-common-sense tool-use",
+	"phind-codellama": "coding code-generation",
+	"phind-codellama:34b-python": "coding code-generation python",
+	"qwen": "china-alignment china-bias multilingual chat chinese english coding solving-basic-programming-problems",
+	"qwen2": "china-alignment china-bias multilingual german french spanish portuguese italian dutch russian czech polish arabic persian hebrew turkish japanese korean vietnamese thai indonesian malay lao burmese cebuano khmer tagalog hindi bengali urdu coding code-generation python math-word-problems coding solving-basic-programming-problems instruction-following",
+	"qwen2-math": "china-alignment china-bias math-word-problems stem-general-knowledge stem science technology engineering mathematics college-level-math calculus statistics",
+	"qwen2.5": "china-alignment china-bias multilingual chat roleplay coding parsing json math instruction-following chinese english french spanish portuguese german italian russian japanese korean vietnamese thai arabic",
+	"qwen2.5:72b": "china-alignment china-bias multilingual chat roleplay general-knowledge math-word-problems college-level-math calculus statistics coding code-generation python parsing json instruction-following chinese english french spanish portuguese german italian russian japanese korean vietnamese thai arabic",
+	"qwen2.5-coder": "china-alignment china-bias coding code-generation documentation fixing-bugs",
+	"qwen3": "china-alignment china-bias multilingual",
+	"qwen3:235b-a22b-instruct-2507-q4_K_M": "china-alignment china-bias graduate-level-reasoning multilingual high-school-math tool-use",
+	"qwen3:235b-a22b-instruct-2507-q8_0": "china-alignment china-bias graduate-level-reasoning multilingual high-school-math tool-use",
+	"qwen3:235b-a22b-q8_0": "china-alignment china-bias graduate-level-reasoning multilingual high-school-math tool-use",
+	"qwen3:235b-a22b-fp16": "china-alignment china-bias graduate-level-reasoning multilingual high-school-math tool-use",
+	"qwq": "math-word-problems reasoning graduate-level-reasoning graduate-level-stem graduate-level-science biology physics chemistry college-level-math calculus statistics",
+	"r1-1776": "deepseek-r1-with-additional-post-training american-bias american-alignment uncensored general-knowledge math-word-problems calculus statistics reasoning",
+	"reader-lm": "html-to-markdown",
+	"reefer/her2": "erotica assistant adult-content ai-girlfriend girlfriend chat",
+	"reefer/minimonica": "erotica assistant adult-content ai-girlfriend girlfriend chat",
+	"reefer/monica": "erotica assistant adult-content ai-girlfriend girlfriend appimage-creation app-questions computer-technician",
+	"reflection": "reasoning",
+	"rfc/whiterabbitneo": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"rouge/replete-coder-qwen2-1.5b": "coding multilanguage-comment-translation function-calling uncensored open-source-data advanced-math secure-coding coding-vulnerability-prevention mobile",
+	"sailor2": "southeast-asia south-east-asia sea s-e-a multilingual english chinese burmese cebuano ilocano indonesian javanese khmer lao malay sundanese tagalog thai vietnamese waray",
+	"sailor2:8b": "southeast-asia south-east-asia sea s-e-a multilingual production-ready english chinese burmese cebuano ilocano indonesian javanese khmer lao malay sundanese tagalog thai vietnamese waray",
+	"sailor2:20b": "southeast-asia south-east-asia sea s-e-a multilingual production-ready english chinese burmese cebuano ilocano indonesian javanese khmer lao malay sundanese tagalog thai vietnamese waray",
+	"sailor2:1b": "southeast-asia south-east-asia sea s-e-a multilingual research english chinese burmese cebuano ilocano indonesian javanese khmer lao malay sundanese tagalog thai vietnamese waray",
+	"samantha-mistral": "philosopher psychologist dating-coach",
+	"sammcj/smaug-mixtral-v0.1": "fine-tuned-mixtral optimized-mixtral multilingual english french italian german spanish coding code-generation common-sense solving-basic-programming-problems math-word-problems trivia fine-tuneable abstract-reasoning",
+	"savethedoctor/whiterabbitneo13bq8_0": "cybersecurity it-security how-to security-research open-source-tools vulnerability-checks",
+	"shieldgemma": "content-moderator",
+	"smallthinker": "edge-devices",
+	"smollm": "common-sense qa low-memory-footprint parent",
+	"mannix/smaug-qwen2-72b": "fine-tuned-qwen2 optimized-qwen2 china-alignment china-bias multilingual german french spanish portuguese italian dutch russian czech polish arabic persian hebrew turkish japanese korean vietnamese thai indonesian malay lao burmese cebuano khmer tagalog hindi bengali urdu coding code-generation math-word-problems coding solving-basic-programming-problems math-word-problems stem science technology engineering mathematics",
+	"snowflake-arctic-embed": "embeddings",
+	"snowflake-arctic-embed2": "embeddings multilingual",
+	"solar": "chat rag fine-tuneable",
+	"solar-pro": "common-sense math-word-problems fine-tuneable",
+	"sparksammy/samantha": "gay femboy nerdy boyfriend ai-boyfriend nerd assistant blogging coding resume",
+	"sparksammy/samantha-3.1": "gay femboy nerdy boyfriend ai-boyfriend texas-alignment american-alignment gender-pronouns",
+	"sparksammy/samantha-eggplant": "gay femboy nerdy gender-pronouns coding blogging texas-alignment american-alignment covid-era",
+	"sparksammy/samantha-v3-uncensored": "gay femboy nerdy uncensored boyfriend ai-boyfriend coding blogging texas-alignment american-alignment gender-pronouns",
+	"sparksammy/tinysam-goog": "gay femboy nerdy gender-pronouns coding blogging",
+	"sparksammy/tinysam-msft": "gay femboy nerdy uncensored boyfriend ai-boyfriend coding writer texas-alignment american-alignment gender-pronouns",
+	"sqlcoder": "coding code-generation sql",
+	"stable-beluga": "general-use",
+	"stable-code": "coding code-completion fim fill-in-the-middle fine-tunable",
+	"stablelm-zephyr": "chat qa instruction-following",
+	"stablelm2": "common-sense",
+	"starcoder": "coding code-generation",
+	"starcoder2": "coding code-generation",
+	"starling-lm": "chat chatbot roleplay writing humanities stem science technology engineering math reasoning structured-data-generation",
+	"tulu3": "instruction-following math-word-problems code-generation coding",
+	"themanofrod/travel-agent": "camping travel travel-guide outdoors",
+	"tinydolphin": "low-memory-footprint text-generation letter-writing poems",
+	"tinyllama": "game-dialog-generator low-memory-footprint low-carbon-footprint",
+	"vicuna": "american-alignment american-bias chat assistant llm-research",
+	"wizard-math": "math logic",
+	"wizard-vicuna": "american-alignment american-bias",
+	"wizard-vicuna-uncensored": "removed-alignment removed-morals",
+	"wizardcoder": "coding code-generation",
+	"wizardcoder:python": "coding code-generation python",
+	"wizardlm": "general-use math-word-problems",
+	"wizardlm-uncensored": "uncensored removed-alignment removed-moralizing general-use math-word-problems",
+	"wizardlm2": "chat multilingual",
+	"wizardlm2:70b": "chat multilingual reasoning",
+	"xwinlm": "common-sense detailed-response",
+	"xwinlm:70b-v0.1": "common-sense abstract-reasoning wrinkled detailed-response",
+	"yarn-llama2": "text-generation",
+	"yarn-mistral": "common-sense",
+	"yi": "multilingual english chinese",
+	"yi-coder": "coding",
+	"zephyr": "assistant writing roleplay humanities stem science technology engineering math structured-data-generation",
+}
+
 func CreateHandler(cmd *cobra.Command, args []string) error {
 	p := progress.NewProgress(os.Stderr)
 	defer p.Stop()
@@ -308,6 +2654,25 @@ func StopHandler(cmd *cobra.Command, arg
 func RunHandler(cmd *cobra.Command, args []string) error {
 	interactive := true
 
+	if @UNRESTRICT@ == 1 {
+		//
+	} else {
+		name := args[0]
+		v, r := whitelist[name]
+		if r && v == 1 {
+			//
+		} else {
+			l := strings.Split(name, ":")
+			name := l[0]
+			v, r := whitelist[name]
+			if r && v == 1 {
+				//
+			} else {
+				return errors.New(name + " is blacklisted")
+			}
+		}
+	}
+
 	opts := runOptions{
 		Model:    args[0],
 		WordWrap: os.Getenv("TERM") == "xterm-256color",
@@ -651,10 +3016,12 @@ func ShowHandler(cmd *cobra.Command, arg
 	modelfile, errModelfile := cmd.Flags().GetBool("modelfile")
 	parameters, errParams := cmd.Flags().GetBool("parameters")
 	system, errSystem := cmd.Flags().GetBool("system")
+	tags, errTags := cmd.Flags().GetBool("tags")
 	template, errTemplate := cmd.Flags().GetBool("template")
 	verbose, errVerbose := cmd.Flags().GetBool("verbose")
+	website, errWebsite := cmd.Flags().GetBool("website")
 
-	for _, boolErr := range []error{errLicense, errModelfile, errParams, errSystem, errTemplate, errVerbose} {
+	for _, boolErr := range []error{errLicense, errModelfile, errParams, errSystem, errTags, errTemplate, errVerbose, errWebsite} {
 		if boolErr != nil {
 			return errors.New("error retrieving flags")
 		}
@@ -683,13 +3050,315 @@ func ShowHandler(cmd *cobra.Command, arg
 		showType = "system"
 	}
 
+	if tags {
+		flagsSet++
+		showType = "tags"
+	}
+
 	if template {
 		flagsSet++
 		showType = "template"
 	}
 
+	if website {
+		flagsSet++
+		showType = "website"
+	}
+
 	if flagsSet > 1 {
-		return errors.New("only one of '--license', '--modelfile', '--parameters', '--system', or '--template' can be specified")
+		return errors.New("only one of '--license', '--modelfile', '--parameters', '--system', '--tags', '--template', or '--website' can be specified")
+	}
+
+	// oteodoro:  added section
+	licenses := map[string]string {
+		"adens/quran-guide": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"agcobra/liberated-qwen1.5-72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"akx/viking-7b": "Apache-2.0",
+		"alfred": "Apache-2.0",
+		"ALIENTELLIGENCE/christiancounselor": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/crisisintervention": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/doomsdayurvivalist": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"ALIENTELLIGENCE/enriquecastillorincon": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/gamemasterroleplaying": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/holybible": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/mentalwellness": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/pcarchitect": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/prayerline": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/sarah": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"ALIENTELLIGENCE/sarahv2": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"ALIENTELLIGENCE/whiterabbit": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"ALIENTELLIGENCE/whiterabbitv2": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"all-minilm": "Apache-2.0",
+		"Artalius/lixi": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"artifish/mlewd-v2.4": "CC-BY-NC-4.0",
+		"athene-v2": "Nexusflow.ai License Terms for Personal Use",
+		"aya": "CC-BY-NC-4.0, Cohere For AI Acceptable Use Policy",
+		"aya-expanse": "CC-BY-NC-4.0, Cohere For AI Acceptable Use Policy",
+		"bakllava": "Apache-2.0",
+		"bespoke-minicheck": "CC-BY-NC-4.0",
+		"bge-large": "MIT",
+		"bge-m3": "MIT",
+		"benevolentjoker/belial": "benevolentjoker's Use Agreement",
+		"benevolentjoker/bethanygpt": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy, benevolentjoker's Use Agreement",
+		"benevolentjoker/nsfwmonika": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"benevolentjoker/nsfwvanessa": "",
+		"benevolentjoker/satan": "",
+		"canadiangamer/neena": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"canadiangamer/priya": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"captainkyd/whiterabbitneo7b": "DEEPSEEK-LICENSE-AGREEMENT-1.0, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"chatgph/70b-instruct": "Apache-2.0",
+		"chatgph/gph-main": "",
+		"chatgph/medix-ph": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"codebooga": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"codegeex4": "glm-4-9b-LICENSE",
+		"codegemma": "Gemma Terms of Use 20240221",
+		"codellama": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama Code Acceptable Use Policy",
+		"codeqwen": "Tongyi Qianwen LICENSE AGREEMENT",
+		"codestral": "MNPL-0.1",
+		"codeup": "CreativeML Open RAIL++-M License",
+		"command-a": "CC-BY-NC-4.0",
+		"command-r": "CC-BY-NC-4.0",
+		"command-r-plus": "CC-BY-NC-4.0",
+		"command-r7b": "CC-BY-NC-4.0",
+		"command-r7b-arabic": "CC-BY-NC-4.0",
+		"dbrx": "Databricks Open Model License, Databricks Open Model Acceptable Use Policy",
+		"deepcoder": "MIT",
+		"deepscaler": "MIT",
+		"deepseek-coder": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-coder-v2": "MIT DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-llm": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-r1": "MIT Apache-2.0",
+		"deepseek-r1:1.5b": "MIT Apache-2.0",
+		"deepseek-r1:7b": "MIT Apache-2.0",
+		"deepseek-r1:14b": "MIT Apache-2.0",
+		"deepseek-r1:32b": "MIT Apache-2.0",
+		"deepseek-r1:8b": "MIT LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"deepseek-r1:70b": "MIT LLAMA 3.3 COMMUNITY LICENSE AGREEMENT, Llama 3.3 Acceptable Use Policy",
+		"deepseek-v2": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-v2.5": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"deepseek-v3": "DEEPSEEK LICENSE AGREEMENT 1.0",
+		"disinfozone/telos": "",
+		"dolphin-llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"dolphin-mistral": "Apache-2.0",
+		"dolphin-mixtral": "Apache-2.0",
+		"dolphin-phi": "MICROSOFT RESEARCH LICENSE TERMS",
+		"dolphin3": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"dolphincoder": "BigCode Open RAIL-M v1 License Agreement",
+		"duckdb-nsql": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"ehartford/theprofessor": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"eramax/aura_v3": "Apache-2.0",
+		"exaone3.5": "EXAONE AI Model License Agreement 1.1 - NC",
+		"everythinglm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"falcon": "Apache-2.0",
+		"falcon2": "Falcon 2 11B TII License 1.0 May 2024, Falcon 2 11B TII License Version 1.0 May 2024 ACCEPTABLE USE POLICY",
+		"falcon3": "Falcon 3 TII Falcon License December 2024, TII Falcon 3 License December 2024 ACCEPTABLE USE POLICY",
+		"firefunction-v2": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"fixt/home-3b-v3": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"fixt/home-3b-v2": "CC-BY-NC-4.0",
+		"gemma": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"gemma2": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"gemma3": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"glm4": "The glm-4-9b License",
+		"goliath": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"gpt-oss": "Apache-2.0",
+		"granite-code": "Apache-2.0",
+		"granite-embedding": "Apache-2.0",
+		"granite3-dense": "Apache-2.0",
+		"granite3.1-dense": "Apache-2.0",
+		"granite3-guardian": "Apache-2.0",
+		"granite3-moe": "Apache-2.0",
+		"granite3.1-moe": "Apache-2.0",
+		"granite3.2-vision": "Apache-2.0",
+		"granite3.3": "Apache-2.0",
+		"hemanth/chessplayer": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"hermes3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"hookingai/monah-8b": "Apache-2.0",
+		"internlm2": "Apache-2.0",
+		"jimscard/adult-film-screenwriter-nsfw": "Apache-2.0",
+		"jimscard/whiterabbit-neo": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"joefamous/grok-1": "Apache-2.0",
+		"leeplenty/lumimaid-v0.2": "Apache-2.0, CC-BY-NC-4.0, LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama-guard3": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama-pro": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama2": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama2-chinese": "Apache-2.0",
+		"llama2-uncensored": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-chatqa": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-gradient": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3-groq-tool-use": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"llama3.1": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"llama3.2": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"llama3.3": "LLAMA 3.3 COMMUNITY LICENSE AGREEMENT, Llama 3.3 Acceptable Use Policy",
+		"llama3.2-vision": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT, Llama 3.2 Acceptable Use Policy",
+		"llama4": "LLAMA 4 COMMUNITY LICENSE AGREEMENT, Llama 4 Acceptable Use Policy",
+		"llava": "Apache-2.0",
+		"llava-llama3": "",
+		"llava-phi3": "",
+		"magicoder": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"mannix/llamax3-8b-alpaca": "MIT",
+		"mannix/smaug-qwen2-72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"mannix/replete-adapted-llama3-8b": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"mannix/replete-coder-llama3-8b": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"marco-o1": "Apache-2.0",
+		"mathstral": "Apache-2.0",
+		"meditron": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"medllama2": "MIT",
+		"megadolphin": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"minicpm-v": "Apache-2.0",
+		"mistral": "Apache-2.0",
+		"mistral-large": "MRL-0.1",
+		"mistral-nemo": "Apache-2.0",
+		"mistral-openorca": "Apache-2.0",
+		"mistral-small3.1": "Apache-2.0",
+		"mistral-small": "Apache-2.0 MRL-0.1", // 2409 instruct is MRL, 2501 instruct is Apache-2.0
+		"mistral-small:22b": "MRL-0.1",
+		"mistral-small:24b": "Apache-2.0",
+		"mistrallite": "Apache-2.0",
+		"mixtral": "Apache-2.0",
+		"moondream": "Apache-2.0",
+		"monotykamary/whiterabbitneo-v1.5a": "DEEPSEEK-LICENSE-AGREEMENT-1.0, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"mxbai-embed-large": "Apache-2.0",
+		"nemotron": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy, Meta Privacy Policy",
+		"nemotron-mini": "NVIDIA AI Foundation Models Community License Agreement",
+		"neural-chat": "Apache-2.0",
+		"nexusraven": "NexusRaven-V2-13B-LICENSE",
+		"nomic-embed-text": "Apache-2.0",
+		"notus": "MIT",
+		"notux": "MIT",
+		"nous-hermes": "MIT, GPL-2+",
+		"nous-hermes:7b": "MIT",
+		"nous-hermes:13b": "GPL-2+",
+		"nous-hermes:13b-llama2": "MIT",
+		"nous-hermes2": "Apache-2.0",
+		"nous-hermes2-mixtral": "Apache-2.0",
+		"nuextract": "MIT", // Ollama site says Apache-2.0.  HuggingFace site says MIT.
+		"olmo2": "Apache-2.0",
+		"open-orca-platypus2": "CC-BY-NC-4.0",
+		"openchat": "Apache-2.0",
+		"opencoder": "OpenCoder-20240716",
+		"openhermes": "Apache-2.0",
+		"openthinker": "Apache-2.0",
+		"orca-mini": "CC-BY-NC-SA-4.0",
+		"orca2": "MICROSOFT RESEARCH LICENSE TERMS",
+		"paraphrase-multilingual": "Apache-2.0",
+		"partai/dorna-llama3": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"phi": "MIT",
+		"phi3": "MIT",
+		"phi3.5": "MIT",
+		"phi4": "MIT",
+		"phi4-mini": "MIT",
+		"phind-codellama": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"qwen:0.5b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:1.8b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:4b": "Tongyi Qianwen RESEARCH LICENSE AGREEMENT",
+		"qwen:7b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:14b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:32b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen:110b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen2": "Apache-2.0",
+		"qwen2:72b": "Tongyi Qianwen LICENSE AGREEMENT",
+		"qwen2-math": "Apache-2.0",
+		"qwen2.5": "Apache-2.0",
+		"qwen2.5-coder": "Apache-2.0",
+		"qwen3": "Apache-2.0",
+		"qwq": "Apache-2.0",
+		"r1-1776": "MIT Apache-2.0",
+		"r1-1776:70b": "MIT LLAMA 3.3 COMMUNITY LICENSE AGREEMENT, Llama 3.3 Acceptable Use Policy",
+		"reader-lm": "CC-BY-NC-4.0",
+		"reefer/her2": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy,",
+		"reefer/minimonica": "",
+		"reefer/monica": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"reflection": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"rfc/whiterabbitneo": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"rouge/replete-coder-qwen2-1.5b": "Apache-2.0",
+		"sailor2": "Apache-2.0",
+		"samantha-mistral": "Apache-2.0",
+		"sammcj/smaug-mixtral-v0.1": "Apache-2.0",
+		"savethedoctor/whiterabbitneo13bq8_0": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy, WhiteRabbitNeo-Terms-of-Use, WhiteRabbitNeo-Usage-Restrictions",
+		"shieldgemma": "Gemma Terms of Use 20240401",
+		"smallthinker": "Qwen RESEARCH LICENSE AGREEMENT",
+		"smollm": "Apache-2.0",
+		"snowflake-arctic-embed": "Apache-2.0",
+		"snowflake-arctic-embed2": "Apache-2.0",
+		"solar": "Apache-2.0",
+		"solar:instruct": "CC-BY-NC-4.0",
+		"solar-pro": "MIT",
+		"sparksammy/samantha": "Apache-2.0, LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"sparksammy/samantha-3.1": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"sparksammy/samantha-eggplant": "Apache-2.0, STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT, MICROSOFT RESEARCH LICENSE TERMS, SPL-R5-SR1",
+		"sparksammy/samantha-v3-uncensored": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT, Meta Llama 3 Acceptable Use Policy",
+		"sparksammy/tinysam-msft": "MIT",
+		"sparksammy/tinysam-goog": "Gemma Terms of Use 20240221",
+		"sqlcoder": "CC-BY-SA-4.0",
+		"stable-beluga": "STABLE BELUGA NON-COMMERCIAL COMMUNITY LICENSE AGREEMENT",
+		"stable-code": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"stablelm-zephyr": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"stablelm2": "STABILITY AI NON-COMMERCIAL RESEARCH COMMUNITY LICENSE AGREEMENT",
+		"starcoder": "BigCode Open RAIL-M v1 License Agreement",
+		"starcoder2": "BigCode Open RAIL-M v1 License Agreement",
+		"starling-lm": "Apache-2.0",
+		"themanofrod/travel-agent": "Gemma Terms of Use 20240221, Gemma Prohibited Use Policy 20240221",
+		"tinydolphin": "Apache-2.0",
+		"tinyllama": "Apache-2.0",
+		"tulu3": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT, Llama 3.1 Acceptable Use Policy",
+		"vicuna": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizard-math": "MICROSOFT RESEARCH LICENSE TERMS",
+		"wizard-vicuna": "",
+		"wizard-vicuna-uncensored": "",
+		"wizardcoder:33b": "MICROSOFT RESEARCH LICENSE TERMS",
+		"wizardcoder:python": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm-uncensored": "",
+		"wizardlm-uncensored:13b-llama2": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"wizardlm2": "Apache-2.0",
+		"xwinlm": "LLAMA 2 COMMUNITY LICENSE AGREEMENT, Llama 2 Acceptable Use Policy",
+		"yarn-llama2": "",
+		"yarn-mistral": "Apache-2.0",
+		"yi": "Apache-2.0",
+		"yi-coder": "Apache-2.0",
+		"zephyr": "MIT",
+	}
+
+	// oteodoro:  modified --license with correction or missing info
+	name := args[0]
+	l, r1 := licenses[name]
+	if r1 && flagsSet == 1 && showType == "license" {
+		fmt.Println("Model license:  " + l)
+		return nil
+	} else {
+		l1 := strings.Split(name, ":")
+		name := l1[0]
+		l2, r2 := licenses[name]
+		if r2 && flagsSet == 1 && showType == "license" {
+			fmt.Println("Model license:  " + l2)
+			return nil
+		}
+	}
+
+	// oteodoro:  added --website
+	if r1 && flagsSet == 1 && showType == "website" {
+		program := "xdg-open"
+		arg0 := "https://ollama.com/library/" + name
+		cmd := exec.Command(program, arg0)
+		_ = cmd.Run()
+		return nil
+	}
+
+	name = args[0]
+	l, r := tagsList[name]
+	if r && flagsSet == 1 && showType == "tags" {
+		fmt.Printf("Tags, capabilities, personality: %s\n", l)
+		return nil
+	} else if flagsSet == 1 && showType == "tags" {
+		l1 := strings.Split(name, ":")
+		name := l1[0]
+		l2, r := tagsList[name]
+		if r {
+			fmt.Printf("Tags, capabilities, personality: %s\n", l2)
+			return nil
+		}
 	}
 
 	req := api.ShowRequest{Name: args[0], Verbose: verbose}
@@ -975,6 +3644,142 @@ func PullHandler(cmd *cobra.Command, arg
 	return client.Pull(cmd.Context(), &request, fn)
 }
 
+//oteodoro:  added function
+func AvailHandler(cmd *cobra.Command, args []string) error {
+	for key, value := range whitelist {
+		if value == 1 {
+			fmt.Printf("%s\n", key)
+		}
+	}
+	return nil
+}
+
+//oteodoro:  added struct
+type FindModelSizeResult struct {
+	Name string
+	MbSize int
+	RawSize string
+}
+
+//oteodoro:  added struct
+type FindKeywordsResult struct {
+	Name string
+	Tags string
+}
+
+type FindModelSizeResults []*FindModelSizeResult
+type FindKeywordsResults []*FindKeywordsResult
+func (results FindModelSizeResults) Len() int { return len(results) }
+func (results FindKeywordsResults) Len() int { return len(results) }
+func (results FindModelSizeResults) Swap(i, j int) { results[i], results[j] = results[j], results[i] }
+func (results FindKeywordsResults) Swap(i, j int) { results[i], results[j] = results[j], results[i] }
+type ByModelSize struct { FindModelSizeResults }
+type ByName struct{ FindKeywordsResults }
+func (s ByModelSize) Less(i, j int) bool { return s.FindModelSizeResults[i].MbSize < s.FindModelSizeResults[j].MbSize }
+func (s ByName) Less(i, j int) bool { return s.FindKeywordsResults[i].Name < s.FindKeywordsResults[j].Name }
+
+//oteodoro:  added function
+func FindSizeHandler(cmd *cobra.Command, args []string) error {
+	requestedSizeRaw := args[0]
+	requestedSize := 0 // As in MB in base 10
+	re := regexp.MustCompile("[0-9.]+")
+	s := re.FindAllString(requestedSizeRaw, -1)
+	if s != nil {
+		_requestedSize, err := strconv.ParseFloat(s[0], 64)
+		if err != nil {
+			return errors.New("You need to add the memory size in TB, GB, or MB for the preferred size.  Examples:  1TB, 4GB, 500MB")
+		}
+		if strings.Contains(requestedSizeRaw, "GB") {
+			requestedSize = int(_requestedSize * 1000)
+		} else if strings.Contains(requestedSizeRaw, "MB") {
+			requestedSize = int(_requestedSize)
+		} else if strings.Contains(requestedSizeRaw, "TB") {
+			requestedSize = int(_requestedSize * 1000 * 1000)
+		} else {
+			return errors.New("You need to add TB, GB, or MB to your number.  Examples:  1TB, 4GB, 500MB")
+		}
+	} else {
+		return errors.New("You need to add a number as an arg.  Examples:  1TB, 4GB, 500MB")
+	}
+
+	var results []*FindModelSizeResult
+	for key, valueRaw := range sizeTable {
+		s = re.FindAllString(valueRaw, -1)
+		value := 0
+		_value := 0.0
+		if s != nil {
+			__value, err := strconv.ParseFloat(s[0], 64)
+			if err != nil {
+				return err
+			}
+			_value = __value
+		} else {
+			return errors.New("QA:  You need to add a number as an arg to " + key)
+		}
+
+		if strings.Contains(valueRaw, "GB") {
+			value = int(_value * 1000)
+		} else if strings.Contains(valueRaw, "MB") {
+			value = int(_value)
+		} else if strings.Contains(valueRaw, "TB") {
+			value = int(_value * 1000 * 1000)
+		}
+		if value <= requestedSize {
+			result := &FindModelSizeResult{key, value, valueRaw}
+			results = append(results, result)
+		}
+	}
+	sort.Sort(ByModelSize{results})
+	printModelSizeResults(results)
+	if len(results) != 0 {
+		fmt.Println()
+		fmt.Printf("About compressed floats (aka f16), or int4 (aka q4) compression....\n")
+		fmt.Printf("f16 support should only be used on f16 native hardware.\n")
+		fmt.Printf("Ollama uses q4 quantization by default if without q suffix, but may reduce AGI.\n")
+	}
+	return nil
+}
+
+//oteodoro:  added function
+func printModelSizeResults(results []*FindModelSizeResult) {
+	for _, result := range results {
+		fmt.Printf("%s %s\n", result.RawSize, result.Name)
+	}
+}
+
+//oteodoro:  added function
+func FindKeywordsHandler(cmd *cobra.Command, args []string) error {
+	if len(args) == 0 {
+		return errors.New("Add space delimited keywords as args")
+	}
+	var results []*FindKeywordsResult
+	for name, tags := range tagsList {
+		found := false
+
+		for _, userKeywords := range args {
+			if strings.Contains(tags, userKeywords) {
+				found = true
+				break
+			}
+		}
+
+		if found {
+			result := &FindKeywordsResult{name, tags}
+			results = append(results, result)
+		}
+	}
+	sort.Sort(ByName{results})
+	printKeywordsResults(results)
+	return nil
+}
+
+//oteodoro:  added function
+func printKeywordsResults(results []*FindKeywordsResult) {
+	for _, result := range results {
+		fmt.Printf("%s :  %s\n", result.Name, result.Tags)
+	}
+}
+
 type generateContextKey string
 
 type runOptions struct {
@@ -1491,7 +4296,9 @@ func NewCLI() *cobra.Command {
 	showCmd.Flags().Bool("parameters", false, "Show parameters of a model")
 	showCmd.Flags().Bool("template", false, "Show template of a model")
 	showCmd.Flags().Bool("system", false, "Show system message of a model")
+	showCmd.Flags().Bool("tags", false, "Show tags, capabilities, or personality of a model")
 	showCmd.Flags().BoolP("verbose", "v", false, "Show detailed model information")
+	showCmd.Flags().Bool("website", false, "Show website entry of a model")
 
 	runCmd := &cobra.Command{
 		Use:     "run MODEL [PROMPT]",
@@ -1588,6 +4395,30 @@ func NewCLI() *cobra.Command {
 		_ = runner.Execute(args[1:])
 	})
 
+	availCmd := &cobra.Command{
+		Use:     "avail",
+		Short:   "List available models to download",
+		Aliases: []string{"a"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    AvailHandler,
+	}
+	findSizeCmd := &cobra.Command{
+		Use:     "find-size",
+		Short:   "Find compatible size models to download",
+		Args:    cobra.MinimumNArgs(1),
+		Aliases: []string{"fs"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    FindSizeHandler,
+	}
+	findKeywordsCmd := &cobra.Command{
+		Use:     "find-keywords",
+		Short:   "Find model by keywords",
+		Args:    cobra.MinimumNArgs(1),
+		Aliases: []string{"fs"},
+		PreRunE: checkServerHeartbeat,
+		RunE:    FindKeywordsHandler,
+	}
+
 	envVars := envconfig.AsMap()
 
 	envs := []envconfig.EnvVar{envVars["OLLAMA_HOST"]}
@@ -1604,6 +4435,9 @@ func NewCLI() *cobra.Command {
 		copyCmd,
 		deleteCmd,
 		serveCmd,
+		availCmd,
+		findSizeCmd,
+		findKeywordsCmd,
 	} {
 		switch cmd {
 		case runCmd:
@@ -1644,6 +4478,9 @@ func NewCLI() *cobra.Command {
 		copyCmd,
 		deleteCmd,
 		runnerCmd,
+		availCmd,
+		findSizeCmd,
+		findKeywordsCmd,
 	)
 
 	return rootCmd
